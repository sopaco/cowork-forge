# Core Workflows

## 1. Workflow Overview

Cowork Forge is an AI-powered software development system that automates the entire software development lifecycle through an iterative, multi-agent workflow. The system's core value proposition is to reduce manual effort in requirement elicitation, architecture design, code generation, and documentation, enabling faster MVP delivery with consistent quality.

### Core Execution Paths

The system operates through three primary execution paths:

1. **Project Initialization**: Creates a new project with foundational artifacts
2. **Development Iteration**: Executes a complete development cycle through sequential pipeline stages
3. **Change Request Analysis**: Analyzes modifications to existing projects and initiates targeted development

Each path follows a consistent pattern: user input → AI analysis → artifact generation → human-in-the-loop validation → persistence → state update.

### Key Process Nodes

The system's workflow revolves around seven critical process nodes:

1. **Idea Capture**: Transforms user input into structured requirements
2. **PRD Generation**: Creates formal Product Requirements Documents
3. **Design Specification**: Generates technical architecture documentation
4. **Implementation Planning**: Breaks down design into executable tasks
5. **Code Generation**: Produces actual source code artifacts
6. **Quality Assurance**: Validates code against requirements and best practices
7. **Delivery**: Packages and delivers completed artifacts with comprehensive documentation

### Process Coordination Mechanisms

The system employs a sophisticated coordination framework:

- **Pipeline Executor**: Central controller that orchestrates stage execution, manages workspace inheritance, and handles retry logic
- **Stage Trait**: Uniform interface for all pipeline stages, enabling plug-and-play extensibility
- **Interactive Backend**: Abstracts UI concerns, allowing CLI and GUI implementations to share the same core logic
- **Tool Support Domain**: Provides secure, session-scoped tools for AI agents to interact with the system's state, file system, and external services
- **Event Bus**: Publish-subscribe system for real-time communication between pipeline components and UI

## 2. Main Workflows

### Core Business Process Details

#### Development Iteration Process

The primary workflow executes a complete development cycle through seven sequential stages:

1. **Idea Stage**: Captures user input and generates an `idea.md` document with problem statement, target users, core features, success criteria, and constraints.
2. **PRD Stage**: Converts the idea into a formal Product Requirements Document with user stories, functional/non-functional requirements, UI/UX specifications, and data/API requirements.
3. **Design Stage**: Transforms the PRD into a technical design document with architecture overview, component design, data models, API specifications, technology stack recommendations, security considerations, and deployment architecture.
4. **Plan Stage**: Creates an implementation plan with task breakdown, file structure, implementation order, key algorithms, testing strategy, risk mitigation, and definition of done.
5. **Coding Stage**: Generates source code files based on the implementation plan using a two-phase approach: first generating a file structure, then generating code for each file.
6. **Check Stage**: Performs automated quality assurance by analyzing generated code against requirements using LLM-powered review, producing a `check_report.md` with PASS/FAIL verdict.
7. **Delivery Stage**: Generates a comprehensive `delivery_report.md` summarizing the iteration and copies all generated code files to the project root directory.

Each stage follows a consistent pattern: load configuration → load previous artifacts → generate content using LLM → write artifact to filesystem → provide feedback to user.

#### Key Technical Process Descriptions

**Idea Stage Implementation**: The system uses a prompt engineering approach where the LLM is instructed to generate a structured markdown document with specific sections. The prompt includes the user's original request as context and generates content with metadata headers identifying the iteration number and title.

**PRD Stage Implementation**: The PRD stage builds upon the idea document, adding formal requirements engineering. The LLM is instructed to generate user stories in the format "As a [user], I want [feature] so that [benefit]" and to distinguish between functional and non-functional requirements. The system validates that the generated document contains all required sections before saving.

**Design Stage Implementation**: This stage transforms requirements into technical specifications. The LLM is instructed to create architecture diagrams (in text form), component responsibilities, data models, API endpoints, and technology stack recommendations. The system enforces architectural simplicity by discouraging microservices, caching, and queues unless explicitly required.

**Coding Stage Implementation**: The coding stage employs a sophisticated two-phase generation process:
1. **Structure Analysis**: First, the LLM generates a complete file structure listing all files to create with their paths and descriptions
2. **Code Generation**: For each identified file, the LLM generates complete, functional code with tailored prompts that include the file path, description, and project context

The system includes robust parsing logic to handle various LLM response formats and fallback strategies (e.g., if file list parsing fails, it falls back to generating a single main.rs file).

**Quality Assurance Implementation**: The Check Stage performs lightweight quality validation using a prompt that asks the LLM to review code against seven dimensions: overall assessment, code quality, functionality, error handling, security, performance, and recommendations. The system searches for "PASS" or "APPROVED" keywords in the response to determine verdict, but the pipeline continues regardless of the outcome, following a fail-safe design philosophy.

**Delivery Implementation**: The Delivery Stage aggregates all artifacts from previous stages and uses an LLM to generate a professional delivery report following PR description conventions. It then recursively copies all generated code files from the workspace to the project root while excluding system artifacts like `.git`, `node_modules`, and `target` directories.

#### Process Execution Order and Dependencies

The development iteration process follows a strict sequential dependency chain:

```
Idea → PRD → Design → Plan → Coding → Check → Delivery
```

Each stage depends on the output of the previous stage:
- PRD requires the Idea document as context
- Design requires the PRD document as input
- Plan requires the Design document as input
- Coding requires the Plan document as input
- Check requires the generated code and Plan document
- Delivery requires all previous artifacts

The system implements a "fail-fast" approach where if any stage fails to generate its artifact, the entire iteration fails. However, the Check Stage is designed as a non-blocking quality gate - it reports issues but allows the pipeline to proceed.

#### Input/Output Data Flows

**Input Data Flows**:
- **User Input**: Natural language description of desired functionality (provided via CLI or GUI)
- **Project Context**: Project metadata (tech stack, language, type) from `project.json`
- **Previous Artifacts**: Markdown documents from prior stages (idea.md, prd.md, design.md, plan.md)
- **Configuration**: LLM settings from `config.toml` or environment variables

**Output Data Flows**:
- **Artifacts**: Markdown documents (idea.md, prd.md, design.md, plan.md, check_report.md, delivery_report.md)
- **Code Files**: Source code files generated in the workspace directory
- **Summary Files**: `.generated_files.txt` listing all generated files with line counts
- **State Updates**: Updated `iteration.json` and `project.json` files with status and artifact paths

The data flows are unidirectional and sequential, with each stage consuming the output of the previous stage and producing output for the next stage.

## 3. Flow Coordination and Control

### Multi-Module Coordination Mechanisms

The system employs a sophisticated multi-module coordination architecture based on the Strategy and Observer patterns:

**Pipeline Executor (Controller)**: The `IterationExecutor` acts as the central controller that coordinates all workflow execution. It:
- Loads project and iteration context from persistence
- Prepares workspace with inheritance logic (full, partial, or none)
- Executes stages in sequence using the Stage trait interface
- Manages retry logic (up to 3 attempts per stage)
- Handles feedback loops (up to 5 revisions per stage)
- Updates project state after successful completion

**Stage Trait (Strategy Pattern)**: All pipeline stages implement the `Stage` trait, which defines a uniform interface:
```rust
pub trait Stage: Send + Sync {
    fn name(&self) -> &str;
    fn description(&self) -> &str;
    async fn execute(&self, ctx: &PipelineContext, interaction: Arc<dyn InteractiveBackend>) -> StageResult;
    async fn execute_with_feedback(&self, ctx: &PipelineContext, interaction: Arc<dyn InteractiveBackend>, feedback: &str) -> StageResult;
}
```

This allows the executor to treat all stages uniformly, regardless of their specific implementation, enabling easy extension with new stages.

**Interactive Backend (Strategy Pattern)**: The `InteractiveBackend` trait abstracts user interaction, allowing different UI implementations (CLI and Tauri GUI) to provide the same interface:
```rust
pub trait InteractiveBackend {
    async fn show_message(&self, level: MessageLevel, content: String);
    async fn request_input(&self, prompt: &str, options: Vec<InputOption>, initial_content: Option<String>) -> Result<InputResponse>;
    async fn show_progress(&self, task_id: String, progress: ProgressInfo);
    fn event_bus(&self) -> Arc<EventBus>;
}
```

This enables the core engine to work with different UI backends without modification.

**Tool Support Domain (Dependency Injection)**: AI agents interact with the system through a set of tools that implement the `Tool` trait. These tools are injected into the agent execution context, providing secure access to system capabilities:
- File operations (`ListFilesTool`, `ReadFileTool`, `WriteFileTool`)
- Data operations (`CreateRequirementTool`, `AddFeatureTool`, `CreateTaskTool`)
- Control operations (`ProvideFeedbackTool`, `RequestHumanReviewTool`)
- Artifact operations (`SavePrdDocTool`, `SaveDesignDocTool`)

### State Management and Synchronization

The system implements a robust state management system centered around two core entities:

**Project State**: Managed by the `Project` entity and `ProjectStore`:
- Contains project metadata (name, tech stack, language)
- Tracks iteration history and current iteration
- Automatically updates `updated_at` timestamp on any modification
- Uses immutable ID generation (`proj-{timestamp}`)

**Iteration State**: Managed by the `Iteration` entity and `IterationStore`:
- Tracks five-stage lifecycle: idea → prd → design → plan → delivery
- Maintains status: Draft, Running, Paused, Completed, Failed
- Records completed stages and current stage
- Supports inheritance modes: None, Full, Partial
- Automatically generates unique IDs (`iter-{iteration_number}-{timestamp}`)

State synchronization is achieved through:
1. **File-based Persistence**: All state is persisted as JSON files in the `.cowork-v2` directory
2. **Atomic Writes**: File operations use `fs::write` for atomic updates
3. **Timestamp Tracking**: All entities include `created_at` and `updated_at` fields
4. **Versioned Artifacts**: Each iteration has its own isolated workspace and artifact directory

### Data Passing and Sharing

Data flows between components through a combination of direct passing and shared storage:

**Direct Passing**: 
- `PipelineContext` carries project, iteration, and workspace path between stages
- Stage execution methods receive context as parameters
- LLM prompts are constructed by combining context with previous artifacts

**Shared Storage**:
- **Project Store**: Persists `project.json` with project metadata and iteration history
- **Iteration Store**: Persists `iteration.json` with iteration state and artifact paths
- **Artifact Directory**: Stores markdown documents (idea.md, prd.md, design.md, etc.)
- **Workspace Directory**: Stores generated code files
- **Memory Store**: Persists project-level decisions and session-level insights

The system uses a hierarchical storage structure:
```
.cowork-v2/
├── project.json
├── sessions/
│   ├── <iteration_id>/
│   │   ├── artifacts/
│   │   │   ├── idea.md
│   │   │   ├── prd.md
│   │   │   ├── design.md
│   │   │   ├── plan.md
│   │   │   ├── check_report.md
│   │   │   └── delivery_report.md
│   │   ├── workspace/
│   │   │   ├── src/
│   │   │   │   └── main.rs
│   │   │   └── ...
│   │   └── iteration.json
└── ...
```

### Execution Control and Scheduling

The system implements a sophisticated execution control mechanism:

**Stage Execution Control**:
- **Sequential Execution**: Stages execute in fixed order (Idea → PRD → Design → Plan → Coding → Check → Delivery)
- **Critical Stage Detection**: The `is_critical_stage()` function identifies stages requiring human confirmation (Idea, PRD, Design, Plan, Coding)
- **Human-in-the-Loop (HITL)**: At critical stages, the system pauses and requests user feedback via `request_input()`
- **Retry Logic**: Each stage can be retried up to 3 times with feedback
- **Revision Loop**: Users can request revisions up to 5 times per stage

**Scheduling Mechanism**:
- **Automatic Scheduling**: The `IterationExecutor` automatically schedules stages based on iteration status
- **Resume Capability**: Users can resume paused iterations from any stage using `resume_stage` parameter
- **Inheritance-Based Scheduling**: For evolution iterations, the system determines the starting stage based on change scope analysis:
  ```rust
  fn analyze_change_scope(description: &str) -> String {
      if description.contains("architecture") || description.contains("重构") { "idea" }
      else if description.contains("requirement") || description.contains("需求") { "prd" }
      else if description.contains("design") || description.contains("设计") { "design" }
      else { "plan" }
  }
  ```

**Concurrency Control**:
- **Global Rate Limiter**: Limits LLM API calls to 1 concurrent request with 2-second delays between requests
- **Session Isolation**: Each iteration has its own workspace and artifact directory
- **Thread-Safe Operations**: Uses `Arc` for shared ownership and `Mutex` for critical sections

## 4. Exception Handling and Recovery

### Error Detection and Handling

The system implements comprehensive error detection and handling at multiple levels:

**LLM Interaction Errors**:
- LLM client creation failures (invalid API key, unreachable endpoint)
- Generation failures (timeout, token limit exceeded)
- Streaming errors during content generation
- Response parsing failures (empty or malformed responses)

**File System Errors**:
- Directory creation failures
- File read/write permission errors
- Path validation failures (security violations)
- Disk space exhaustion

**Data Validation Errors**:
- Missing required parameters in tool calls
- Invalid JSON schema in tool inputs
- Corrupted persistence files
- Inconsistent state between project and iteration

**Error Handling Implementation**:
```rust
// Example from CodingStage
let mut stream = match llm.generate_content(request, false).await {
    Ok(resp) => resp,
    Err(e) => {
        return StageResult::Failed(format!("LLM generation failed: {}", e));
    }
};
```

All errors are captured and converted to `StageResult::Failed(String)` with descriptive messages. The system uses `anyhow::Result` for context-rich error propagation throughout the codebase.

### Exception Recovery Mechanisms

The system implements multiple recovery mechanisms:

**Retry Logic**:
- Each stage can be retried up to 3 times automatically
- Retry counter is reset on successful execution
- Failed attempts are logged with error details

**Human-in-the-Loop Recovery**:
- When an agent encounters an error, it can invoke `RequestHumanReviewTool` to escalate to human intervention
- Users can provide feedback during HITL interactions, which is used to regenerate artifacts
- The system supports iterative refinement with up to 5 revisions per stage

**Fallback Strategies**:
- **Code Generation Fallback**: If file list parsing fails during coding, the system falls back to generating a single `main.rs` file
- **Artifact Fallback**: If a required artifact (e.g., PRD) doesn't exist, the system falls back to using the iteration description
- **Configuration Fallback**: LLM configuration loads from `config.toml` → executable directory → environment variables

**Graceful Degradation**:
- Quality checks (Check Stage) are non-blocking - the pipeline continues even if quality issues are detected
- The system continues processing even if individual file generations fail during coding
- Missing files are handled gracefully with appropriate error messages

### Fault Tolerance Strategy Design

The system employs a multi-layered fault tolerance strategy:

**1. Isolation**:
- Each iteration has its own isolated workspace and artifact directory
- Session-scoped tools prevent cross-session contamination
- File system operations are constrained to the current working directory

**2. Redundancy**:
- All artifacts are persisted to disk immediately after generation
- Project and iteration state is saved after each major operation
- Configuration has multiple fallback sources

**3. Monitoring**:
- Event Bus publishes `EngineEvent` for all significant operations
- Progress tracking provides real-time feedback on long-running operations
- Error messages include context (iteration ID, stage name, timestamp)

**4. Recovery Points**:
- Each stage creates a persistent artifact as a recovery point
- The system can resume from any stage using the `resume_stage` parameter
- Iteration state is saved after each stage completion

### Failure Retry and Degradation

**Retry Strategy**:
- **Maximum Attempts**: 3 retries per stage
- **Backoff**: No exponential backoff - fixed delay between retries
- **Reset Condition**: Retry counter resets on successful execution
- **User Override**: Users can manually abort or provide guidance before retry

**Degradation Strategy**:
- **Code Generation**: If LLM fails to generate file structure, falls back to single file generation
- **Artifact Loading**: If PRD/design/plan files are missing, uses iteration description as fallback
- **Configuration**: If config file is missing, falls back to environment variables
- **Storage**: If persistence fails, system continues with in-memory state (though this is not recommended)

**Failure Impact Analysis**:
- **Stage Failure**: Only the current stage fails; previous stages remain intact
- **Iteration Failure**: The iteration is marked as Failed, but project state remains unchanged
- **System Failure**: The `.cowork-v2` directory preserves all artifacts, allowing manual recovery

## 5. Key Process Implementation

### Core Algorithm Processes

**Change Scope Analysis Algorithm**:
```rust
fn analyze_change_scope(description: &str) -> String {
    let desc_lower = description.to_lowercase();
    
    // Architecture changes (start from idea)
    let arch_keywords = ["架构", "architecture", "重构", "rewrite", "重新设计", "redesign"];
    for kw in &arch_keywords {
        if desc_lower.contains(kw) { return "idea".to_string(); }
    }
    
    // Requirement changes (start from prd)
    let req_keywords = ["需求", "requirement", "功能", "feature", "添加", "add"];
    for kw in &req_keywords {
        if desc_lower.contains(kw) { return "prd".to_string(); }
    }
    
    // Design changes (start from design)
    let design_keywords = ["设计", "design", "数据库", "database", "接口", "api"];
    for kw in &design_keywords {
        if desc_lower.contains(kw) { return "design".to_string(); }
    }
    
    // Default: code changes only (start from plan)
    "plan".to_string()
}
```

This algorithm enables intelligent inheritance by automatically determining the appropriate starting stage for evolution iterations based on semantic analysis of the change description keywords.

**File Structure Generation Algorithm**:
```rust
fn parse_file_list(structure_text: &str) -> Vec<String> {
    let mut files = Vec::new();
    
    // Look for FILES: section
    if let Some(start) = structure_text.find("FILES:") {
        let rest = &structure_text[start + 6..];
        
        // Parse lines starting with - 
        for line in rest.lines() {
            if let Some(path) = line.strip_prefix("- ") {
                if let Some(file_path) = path.split(':').next() {
                    files.push(file_path.trim().to_string());
                }
            }
        }
    }
    
    // Fallback: extract from code blocks
    if files.is_empty() {
        // Extract from ``` files block
        let re = regex::Regex::new(r"```(?:\w+)?\n(.*?)(?:\n```|$)").unwrap();
        for cap in re.captures_iter(structure_text) {
            for line in cap[1].lines() {
                if let Some(file_path) = line.strip_prefix("- ") {
                    files.push(file_path.trim().to_string());
                }
            }
        }
    }
    
    files
}
```

This algorithm handles non-deterministic LLM outputs by supporting multiple formats (bullet points, code blocks) and provides fallback strategies.

### Data Processing Pipelines

**Artifact Generation Pipeline**:
```
User Input → Idea Stage → PRD Stage → Design Stage → Plan Stage → Coding Stage → Check Stage → Delivery Stage
```

Each stage processes data through a consistent pipeline:
1. **Load Configuration**: Retrieve LLM settings from config file or environment
2. **Load Context**: Retrieve previous artifacts (if available)
3. **Construct Prompt**: Combine context with stage-specific instructions
4. **Generate Content**: Call LLM with streaming response
5. **Extract Content**: Parse LLM response (handle streaming, code blocks)
6. **Validate Output**: Check for required sections, format, completeness
7. **Persist Artifact**: Write to filesystem with metadata headers
8. **Provide Feedback**: Notify user of completion

**Memory Context Pipeline**:
```
LLM Agent Request → QueryMemoryIndexTool → LoadMemoryDetailTool → Inject into Prompt → Generate Output → Update Memory Context
```

This pipeline enables context-aware AI assistance by retrieving historical decisions and patterns from both project-level and session-level memory stores.

### Business Rule Execution

**Simplicity Enforcement Rules**:
1. **Architecture Simplicity**: 
   - Prefer monolithic architectures over microservices
   - Use SQLite/JSON over complex databases
   - Use built-in tools over external dependencies
   - Limit components to 2-4 maximum

2. **Requirements Filtering**:
   - Reject non-core requirements (performance, testing, CI/CD, monitoring)
   - Focus on minimum viable product (MVP) quality gate
   - Require explicit user request for non-core features

3. **Code Generation Rules**:
   - No over-engineering
   - No premature optimization
   - No tests unless explicitly required
   - No servers or long-running processes

**Inheritance Rules**:
1. **None**: Fresh start (genesis iteration)
2. **Full**: Copy all code from base iteration
3. **Partial**: Copy only artifacts and configuration files (not generated code)

**Quality Gate Rules**:
1. **Check Stage**: 
   - Validate feature coverage
   - Verify task dependencies
   - Check file existence
   - Do NOT check tests, linting, detailed code quality, performance

### Technical Implementation Details

**LLM Integration**:
- Uses `adk-rust` OpenAIClient with custom base URL
- Implements global rate limiter with semaphore (max 1 concurrent request)
- Enforces 2-second delay between requests (<30 calls/minute)
- Supports multiple LLM providers via `LlmProvider` trait

**File System Security**:
```rust
fn validate_path_security(path: &str) -> Result<PathBuf, String> {
    // Rule 1: Reject absolute paths
    if path_obj.is_absolute() { return Err("Absolute paths not allowed"); }
    
    // Rule 2: Reject parent directory access (..)
    if path.contains("..") { return Err("Parent directory access not allowed"); }
    
    // Rule 3: Canonicalize and verify within current directory
    let full_path = current_dir.join(path);
    let canonical_path = full_path.canonicalize()?;
    let normalized_current_dir = current_dir.canonicalize()?;
    
    if !canonical_path.starts_with(&normalized_current_dir) {
        return Err("Path escapes current directory");
    }
    
    Ok(canonical_path)
}
```

This security model prevents directory traversal attacks and ensures agents cannot access files outside their designated workspace.

**State Management**:
- All state is persisted as JSON files in `.cowork-v2` directory
- Uses `serde` for serialization/deserialization
- Implements `Default` trait for idempotent read operations
- Uses `chrono::Utc::now()` for timestamp generation

**Concurrency Model**:
- Fully asynchronous using `async/await`
- Uses `tokio` for async runtime
- Uses `Arc` for shared ownership
- Uses `Mutex` for critical sections
- Uses `broadcast` channels for event bus

**Error Handling**:
- Uses `anyhow::Result` for context-rich error propagation
- Converts storage errors to `AdkError::Tool` variants
- Provides descriptive error messages with context
- Implements graceful degradation for non-critical failures

The system's technical implementation demonstrates a mature, production-ready architecture that balances automation with human oversight, leveraging AI for repetitive tasks while maintaining human control over critical decisions.