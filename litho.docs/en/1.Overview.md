# System Context Overview

## 1. Project Introduction

**Project Name**: Cowork Forge  
**Generation Time**: 2026-02-07 02:00:07 (UTC)  
**Timestamp**: 1770429607

Cowork Forge is an AI-powered, end-to-end software development system designed to automate the full lifecycle of software delivery—from initial idea conception to production-ready code and comprehensive documentation. Leveraging multi-agent collaboration and large language models (LLMs), Cowork Forge eliminates manual, repetitive tasks in requirement elicitation, architectural design, code generation, and delivery artifact creation, enabling teams to deliver minimum viable products (MVPs) up to 5x faster while maintaining consistent quality and traceability.

The system operates as a **domain-driven, pipeline-centric engine** that orchestrates a sequence of seven structured development stages: *Idea → PRD → Design → Plan → Coding → Check → Delivery*. Each stage is executed by specialized AI agents that interact with the system through a well-defined tool interface, enabling context-aware, iterative, and human-in-the-loop (HITL) collaboration. All state, artifacts, and decisions are persisted in a session-scoped `.cowork` directory, ensuring full traceability, isolation, and reproducibility across development cycles.

Cowork Forge is not a cloud service or SaaS platform—it is a **local-first, CLI and GUI-driven application** that runs entirely on the developer’s machine. It integrates with external LLM APIs (e.g., OpenAI, Anthropic, or any OpenAI-compatible endpoint) for generative capabilities but maintains full control over data, workflows, and security boundaries. The system is built in Rust for performance, safety, and modularity, with a clean separation between core business logic, infrastructure, and interaction layers.

**Core Business Value**:  
> *Reduces manual effort in software development by automating requirement elicitation, architecture design, code generation, and documentation, enabling faster MVP delivery with consistent quality.*

This value is realized through:
- **Automated PRD generation** from natural language prompts
- **Architecture design** informed by project memory and best practices
- **Code generation** aligned with design and requirements
- **Self-documenting delivery reports** with traceability to source artifacts
- **Change request analysis** that automatically assesses impact before execution

Cowork Forge empowers teams to shift from *writing code* to *directing intelligence*, transforming software development from a labor-intensive craft into a disciplined, repeatable, and auditable engineering process.

---

## 2. Target Users

Cowork Forge serves three primary user roles, each with distinct needs and interaction patterns:

### 2.1 Software Developers
**Description**: Developers seeking to accelerate repetitive tasks such as writing specifications, designing systems, and generating boilerplate or complex code.  
**Usage Scenarios**:
- Initiates a new project via `cowork init` and provides a high-level idea (e.g., “Build a REST API for user authentication”).
- Observes AI-generated PRD, design diagrams, and code files, then reviews and edits them via integrated external editors (e.g., VSCode).
- Uses `cowork continue` to refine or extend an existing iteration after receiving feedback.
- Leverages memory tools to reuse past architectural decisions (e.g., “How did we handle JWT refresh tokens in Project X?”).

**Key Needs**:
- Automated requirement gathering from natural language
- AI-assisted architecture design with justification
- Code generation that adheres to project patterns and standards
- Automated delivery documentation to reduce manual README/CHANGELOG writing

### 2.2 Product Managers
**Description**: Non-technical or partially technical stakeholders responsible for defining product scope and ensuring traceability from idea to implementation.  
**Usage Scenarios**:
- Provides a product vision in plain language (“Users should be able to reset passwords via email”).
- Reviews automatically generated PRDs and delivery reports to validate alignment with business goals.
- Uses the system’s traceability features to confirm that all requested features were implemented and documented.
- Requests modifications via `cowork modify` and receives structured change impact analysis before execution.

**Key Needs**:
- Automated PRD generation without manual writing
- Clear traceability from feature request → implementation → documentation
- Consistent, professional delivery reports for stakeholder reviews
- Assurance that AI-generated outputs reflect business intent accurately

### 2.3 Engineering Leads
**Description**: Technical leaders overseeing multiple projects or teams, focused on process standardization, quality assurance, and auditability.  
**Usage Scenarios**:
- Enforces team-wide adoption of Cowork Forge to standardize development workflows.
- Reviews iteration histories and memory artifacts to ensure architectural consistency across projects.
- Uses the system’s audit trail (stored in `.cowork`) to verify compliance with coding standards and design principles.
- Monitors LLM usage patterns and rate limits to ensure sustainable and cost-effective operations.

**Key Needs**:
- Enforced simplicity and consistency in architecture across teams
- Automated quality checks and validation of generated code
- Complete audit trails of all changes, decisions, and iterations
- Standardized workflows that reduce onboarding time and cognitive load

> **Note**: All user roles interact with the system through either the **CLI** (`cowork init`, `cowork run`, `cowork modify`) or the **Tauri-based GUI**, both of which share the same core engine. This ensures consistent behavior and eliminates context-switching between interfaces.

---

## 3. System Boundaries

Cowork Forge defines a clear and intentional system boundary that separates its core autonomous functionality from external infrastructure and services. This boundary ensures security, maintainability, and focus on the AI-assisted development workflow.

### 3.1 Included Components

The following components are **explicitly included** within the Cowork Forge system boundary:

| Component | Description |
|---------|-------------|
| **CLI Interface** | Terminal-based command-line interface (`cowork init`, `cowork run`, etc.) with UTF-8, emoji, and multi-mode input support. |
| **GUI Interface (Tauri)** | Desktop application built with Tauri + frontend framework (future-ready); currently outputs to console but designed for full GUI integration. |
| **Core Domain Models** | `Project`, `Iteration`, and `Memory` entities that encapsulate business state, lifecycle, and historical context. |
| **Pipeline Executor & Stages** | Orchestrates the 7-stage workflow (Idea → Delivery); each stage is a stateful agent with structured prompts and tool dependencies. |
| **LLM Configuration & Rate Limiting** | Manages API endpoint configuration (via `config.toml` or env vars) and enforces global/concurrent request limits to avoid quota exhaustion. |
| **File System Persistence (.cowork)** | Session-scoped storage hierarchy under `.cowork/` directory containing project state, artifacts, logs, and memory. All data is local and isolated. |
| **Human-in-the-Loop (HITL) Tools** | Tools that spawn external editors (e.g., VSCode) for user review/edit of documents and code files; captures feedback and resumes workflow. |
| **Change Request Analysis** | Systematic analysis of user-initiated modifications, generating structured ChangeRequest artifacts that guide subsequent iterations. |

### 3.2 Excluded Components

The following components are **explicitly excluded** from the system boundary:

| Component | Reason for Exclusion |
|---------|----------------------|
| **Cloud Deployment Infrastructure** | Cowork Forge does not deploy, provision, or manage servers, containers, or cloud resources (e.g., AWS, GCP, Azure). |
| **CI/CD Pipelines** | No integration with GitHub Actions, GitLab CI, Jenkins, etc. Output is generated locally; integration is left to the user’s existing pipeline. |
| **Testing Frameworks** | Does not generate unit/integration tests or execute test suites. May generate test stubs, but execution is external. |
| **Database Servers (e.g., PostgreSQL)** | Does not provision, configure, or manage databases. May generate schema definitions or ORM models, but persistence is user-managed. |
| **External Authentication Systems** | No login, SSO, OAuth, or user account management. Runs locally with no identity layer. |
| **Mobile or Web Client Applications (beyond Tauri)** | The Tauri GUI is the only supported UI; no mobile apps, web dashboards, or remote APIs are part of the system. |

> **Architectural Principle**: Cowork Forge is a **local development assistant**, not a full DevOps platform. Its scope is strictly bounded to the *development workflow*, not the *delivery pipeline*. This focus enables deep specialization in AI-assisted development without bloating the system with unrelated infrastructure concerns.

---

## 4. External System Interactions

Cowork Forge interacts with two external systems, both of which lie outside its boundary but are critical to its operation.

### 4.1 LLM API (OpenAI-compatible)

- **Description**: An external large language model service (e.g., OpenAI GPT-4, Anthropic Claude, or self-hosted LLM via Ollama, vLLM, or Hugging Face endpoints) that provides generative AI capabilities for requirement drafting, design synthesis, code generation, and documentation.
- **Interaction Type**: HTTP(S) REST API calls
- **Configuration**: Endpoint, model name, API key, and timeout are loaded from `config.toml` or environment variables (`COWORK_LLM_ENDPOINT`, `COWORK_API_KEY`, etc.).
- **Dependency Analysis**:
  - **Critical**: The system cannot function without an accessible LLM endpoint.
  - **Loose Coupling**: The LLM client is abstracted behind a `LlmClient` trait; switching providers requires only a new implementation.
  - **Rate Control**: A global rate limiter (semaphore + delay) enforces compliance with API quotas to prevent throttling or billing spikes.
  - **Security**: No sensitive data is sent beyond the configured endpoint; all prompts are structured and sanitized. No user code is uploaded unless explicitly saved to the workspace.

### 4.2 External Editor (e.g., VSCode)

- **Description**: A local code editor or text editor (e.g., VSCode, Sublime Text, Vim) launched by the system to enable human-in-the-loop (HITL) review and editing of generated documents and code files.
- **Interaction Type**: Process spawn (`std::process::Command`)
- **Dependency Analysis**:
  - **Optional but Essential for HITL**: The system can operate without an external editor (e.g., in headless CI), but full usability requires it.
  - **Configuration**: Editor path is resolved via `COWORK_EDITOR` env var or system default (e.g., `code` for VSCode).
  - **Workflow Integration**: When a stage (e.g., PRD, Design, Coding) requires human input, the system:
    1. Saves the artifact to disk (e.g., `.cowork/sessions/<id>/artifacts/prd.md`)
    2. Spawns the editor with the file path
    3. Waits for the process to exit
    4. Reloads the modified file and resumes pipeline execution
  - **No Network Dependency**: Interaction is purely local and synchronous; no remote API or WebSocket connection is used.

> **Key Insight**: Both external systems are **stateless and replaceable**. The LLM can be swapped (e.g., from OpenAI to Mistral), and the editor can be changed (e.g., from VSCode to Neovim) without modifying core logic—demonstrating strong adherence to the Dependency Inversion Principle.

---

## 5. System Context Diagram

```mermaid
graph TD
    A[Software Developer] -->|Uses CLI or Tauri GUI| B(Cowork Forge)
    C[Product Manager] -->|Uses CLI or Tauri GUI| B
    D[Engineering Lead] -->|Uses CLI or Tauri GUI| B

    B -->|HTTP(S) API calls| E[LLM API<br>(OpenAI-compatible)]
    B -->|Spawn process| F[External Editor<br>(e.g., VSCode)]

    style A fill:#f9f,stroke:#333
    style C fill:#f9f,stroke:#333
    style D fill:#f9f,stroke:#333
    style E fill:#bbf,stroke:#333
    style F fill:#bbf,stroke:#333
    style B fill:#cfc,stroke:#333

    subgraph "Cowork Forge (System Boundary)"
        direction TB
        B
        B --> G[CLI Interface]
        B --> H[Tauri GUI]
        B --> I[Pipeline Executor]
        B --> J[Project Management]
        B --> K[Iteration Management]
        B --> L[Memory Domain]
        B --> M[Tool Support]
        B --> N[LLM Infrastructure]
        B --> O[Storage Domain]
        B --> P[Interaction Domain]

        I --> Q[Stage: Idea]
        I --> R[Stage: PRD]
        I --> S[Stage: Design]
        I --> T[Stage: Plan]
        I --> U[Stage: Coding]
        I --> V[Stage: Check]
        I --> W[Stage: Delivery]

        M --> X[File Tools]
        M --> Y[Data Tools]
        M --> Z[Control Tools]
        M --> AA[Artifact Tools]
        M --> AB[HITL Tools]
        M --> AC[Memory Tools]
        M --> AD[Modify Tools]

        N --> AE[LLM Config]
        N --> AF[Rate Limiter]

        O --> AG[.cowork/]
        O --> AH[sessions/<id>/]
        O --> AI[artifacts/]
        O --> AJ[state/]
        O --> AK[logs/]

        P --> AL[InteractiveBackend]
        P --> AM[EventBus]

        AE --> E
        AF --> E
        AB --> F
        AD --> F
    end

    classDef system fill:#cfc,stroke:#333;
    classDef external fill:#bbf,stroke:#333;
    classDef user fill:#f9f,stroke:#333;

    class B system
    class E,F external
    class A,C,D user
```

### Key Interaction Flows

1. **User → Cowork Forge**:  
   A user initiates a workflow via CLI (`cowork init`) or GUI (“New Project”). The system loads the `InteractiveBackend` to capture input and display progress.

2. **Cowork Forge → LLM API**:  
   During pipeline execution (e.g., `PRDStage`), the system invokes an LLM agent via `RateLimitedLlm::generate_content`, passing structured prompts and retrieved memory context. Responses are parsed into structured artifacts.

3. **Cowork Forge → External Editor**:  
   After generating `design.md`, the system calls `ReviewAndEditFileTool::execute`, which spawns the configured editor. Upon user save and exit, the file is reloaded and the pipeline resumes.

4. **Cowork Forge → Storage**:  
   All artifacts (PRD, code, reports) and state (Project, Iteration) are persisted to `.cowork/sessions/<uuid>/` using `SessionStorage` and `ProjectStore`. No external databases are used.

5. **Pipeline → Tools → Storage**:  
   Every AI agent interaction (e.g., saving a requirement) goes through a `Tool` (e.g., `CreateRequirementTool`), which validates paths and writes to the local `.cowork` structure via `Storage Domain`.

### Architecture Decisions

- **Local-First Design**: All data resides on the developer’s machine. No cloud dependency ensures privacy, compliance, and offline usability.
- **Tool-Based Agent Interaction**: LLM agents cannot directly manipulate files or state—they must use a predefined set of tools. This enforces safety, auditability, and testability.
- **Session Isolation**: Each iteration runs in a unique `.cowork/sessions/<id>` directory, enabling safe experimentation and rollback.
- **Unified Backend**: CLI and GUI share `InteractiveBackend`, ensuring identical behavior and reducing maintenance overhead.
- **Event-Driven Communication**: `EventBus` decouples pipeline stages from UI, enabling real-time progress updates without tight coupling.

---

## 6. Technical Architecture Overview

### 6.1 Main Technology Stack

| Layer | Technology | Rationale |
|-------|------------|-----------|
| **Core Language** | Rust | Memory safety, concurrency, performance, and zero-cost abstractions ideal for CLI/GUI tools and long-running workflows. |
| **GUI Framework** | Tauri (Rust + WebView) | Enables native desktop experience with web UI flexibility; shares core logic with CLI. |
| **LLM Integration** | OpenAI-compatible HTTP API | Standardized interface allows compatibility with multiple providers (OpenAI, Anthropic, local models). |
| **Persistence** | JSON files + hierarchical filesystem | Simple, human-readable, version-control friendly. Avoids database complexity. |
| **Concurrency** | Tokio (async runtime) | Enables non-blocking I/O for LLM calls, file operations, and event bus. |
| **Eventing** | tokio::broadcast | Lightweight pub/sub for real-time UI updates (e.g., “Stage X completed”). |
| **Configuration** | `config.toml` + env vars | Flexible, environment-aware, and deployable via standard DevOps practices. |
| **Tooling** | ADK-style Tool Interface | Each tool implements `Tool` trait, enabling LLM agents to discover and invoke capabilities safely. |

### 6.2 Architecture Patterns

- **Domain-Driven Design (DDD)**: Core domains (`Project`, `Iteration`, `Memory`, `Pipeline`) encapsulate business logic. Infrastructure (Storage, LLM, Interaction) is separated.
- **Clean Architecture**: Layers are strictly ordered:  
  `User Interface → Interaction Domain → Pipeline Domain → Core Domains → Tool Support → Storage → External Systems`
- **Pipeline Pattern**: The 7-stage workflow is implemented as a state machine with explicit transitions, retry logic, and feedback loops.
- **Tool-Based Agent Control**: LLM agents are “blind” to system internals—they interact only via a controlled set of tools, preventing unsafe operations.
- **Session Isolation**: Each project iteration is sandboxed in its own `.cowork/sessions/<id>` directory, enabling parallel development and safe rollback.
- **Event-Driven UI**: The `EventBus` allows the GUI to subscribe to pipeline events (e.g., `StageStarted`, `AgentCompleted`) without direct coupling.

### 6.3 Key Design Decisions

| Decision | Rationale | Impact |
|--------|-----------|--------|
| **No external database** | Avoids complexity, licensing, and deployment overhead. JSON files are sufficient for local, session-scoped state. | Enables zero-configuration setup; artifacts are version-control friendly. |
| **HITL via external editor** | Leverages existing, powerful editors (VSCode) instead of reinventing a code editor. | Maximizes developer productivity; reduces UI maintenance burden. |
| **Rate limiting at client level** | Prevents accidental API overuse and billing surprises. | Ensures sustainable, predictable usage even in high-frequency workflows. |
| **Memory as first-class citizen** | Decisions and patterns are stored and retrieved contextually, enabling AI to “learn” from past projects. | Drives consistency, reduces repetition, and improves output quality over time. |
| **Single engine, dual interfaces** | CLI and GUI share `InteractiveBackend` and core logic. | Reduces duplication, ensures feature parity, and accelerates development. |
| **All artifacts are markdown** | Human-readable, diff-friendly, and compatible with documentation tools. | Enables manual inspection, version control, and integration with Confluence, Notion, etc. |

### 6.4 Future-Proofing & Extensibility

- **LLM Provider Agnosticism**: The `LlmClient` trait allows easy swapping of providers (e.g., add Mistral, Llama 3, or Gemini).
- **Tool Extensibility**: New tools can be added without modifying core logic—enabling community plugins (e.g., `GenerateDockerfileTool`, `RunUnitTestTool`).
- **Pipeline Stage Customization**: New stages (e.g., “SecurityReview”, “PerformanceTest”) can be inserted into the workflow via configuration.
- **Storage Backend Pluggability**: While JSON is default, the `Storage Domain` interface could be extended to support SQLite or Git-based persistence.

---

## Conclusion

Cowork Forge represents a paradigm shift in software development: from manual, error-prone craftsmanship to AI-augmented, repeatable engineering. By focusing exclusively on the *development workflow* and leveraging local-first, tool-based, and memory-aware AI collaboration, it delivers unparalleled value to developers, product managers, and engineering leads.

Its C4 SystemContext reveals a tightly bounded, highly cohesive system with clear external dependencies and a robust, extensible architecture. The separation of concerns, emphasis on safety through tooling, and session-based isolation ensure that Cowork Forge remains reliable, secure, and maintainable—even as AI capabilities evolve.

This system is not just a productivity tool—it is a **new standard for how software is built**.