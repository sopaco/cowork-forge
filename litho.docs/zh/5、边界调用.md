# System Boundary Interface Documentation

This document describes the system's external invocation interfaces, including CLI commands, API endpoints, configuration parameters, and other boundary mechanisms.

## Command Line Interface (CLI)

### cowork new

**Description**: 创建新项目。根据用户提供的创意描述初始化新项目目录结构，创建会话记录，执行完整的AI驱动开发流程（需求分析→系统设计→任务规划→代码实现→质量检查→项目交付）

**Source File**: `crates/cowork-cli/src/main.rs`

**Arguments**:

- `idea` (String): required - 项目创意/描述（用引号包裹包含空格的描述）

**Options**:

- `verbose, v`(boolean): optional - 输出详细日志，包括ADK内部调试信息 (default: `false`)
- `config, c`(filepath): optional - 配置文件路径，默认为当前目录下的config.toml
- `stream, s`(boolean): optional - 启用LLM流式输出，实时显示AI思考过程 (default: `false`)

**Usage Examples**:

```bash
cowork new "创建一个小学数学智能试卷生成系统"
```

```bash
cowork new "开发一个个人博客网站，支持Markdown"
```

### cowork resume

**Description**: 从断点恢复现有项目。继续上一次成功或进行中的会话，支持指定基准会话ID或自动选择最新会话。用于处理中断的工作流程或继续已完成阶段的后续开发

**Source File**: `crates/cowork-cli/src/main.rs`

**Options**:

- `verbose, v`(boolean): optional - 是否输出详细日志 (default: `false`)
- `config, c`(filepath): optional - 配置文件路径
- `stream, s`(boolean): optional - 是否启用流式输出 (default: `false`)
- `base, b`(string): optional - 指定的基准会话ID（可选）。如省略，默认使用最新成功会话；如无成功会话，尝试使用最新进行中会话

**Usage Examples**:

```bash
cowork resume
```

```bash
cowork resume --base session-1703123456
```

```bash
cowork resume -b session-1703123456
```

### cowork revert

**Description**: 从指定阶段重新开始项目。允许用户回退到需求(PRD)、设计(Design)、规划(Plan)、编码(Coding)、检查(Check)或交付(Delivery)阶段重新执行。支持auto模式自动识别问题阶段

**Source File**: `crates/cowork-cli/src/main.rs`

**Options**:

- `verbose, v`(boolean): optional - 是否输出详细日志 (default: `false`)
- `config, c`(filepath): optional - 配置文件路径
- `stream, s`(boolean): optional - 是否启用流式输出 (default: `false`)
- `from, f`(string): required - 重启起点阶段，可选值：prd, design, plan, coding, check, delivery, auto

**Usage Examples**:

```bash
cowork revert --from design
```

```bash
cowork revert -f prd
```

```bash
cowork revert --from auto
```

### cowork modify

**Description**: 对现有项目进行增量修改。基于之前的成功会话创建变更请求，执行修改流程，自动检测文件变更（增删改）并生成补丁元数据。用于功能迭代、缺陷修复或需求调整

**Source File**: `crates/cowork-cli/src/main.rs`

**Arguments**:

- `idea` (string): required - 变更需求描述

**Options**:

- `verbose, v`(boolean): optional - 是否输出详细日志 (default: `false`)
- `config, c`(filepath): optional - 配置文件路径
- `stream, s`(boolean): optional - 是否启用流式输出 (default: `false`)
- `base, b`(string): optional - 基准会话ID（默认为最新成功会话）

**Usage Examples**:

```bash
cowork modify "添加用户登录功能"
```

```bash
cowork modify "修复数据库连接池问题" --base session-1703123456
```

### cowork status

**Description**: 显示项目当前状态。包括项目元数据、会话历史、最新会话的工件生成情况（需求文档、功能列表、设计文档、任务进度等）。可选择显示所有会话详情

**Source File**: `crates/cowork-cli/src/main.rs`

**Options**:

- `verbose, v`(boolean): optional - 是否输出详细日志 (default: `false`)
- `config, c`(filepath): optional - 配置文件路径
- `stream, s`(boolean): optional - 是否启用流式输出 (default: `false`)
- `sessions, s`(boolean): optional - 显示所有会话的详细列表 (default: `false`)

**Usage Examples**:

```bash
cowork status
```

```bash
cowork status --sessions
```

### cowork init

**Description**: 在当前目录初始化配置文件。创建默认的config.toml模板文件，包含LLM API连接参数配置（api_base_url, api_key, model_name）。如文件已存在则报错

**Source File**: `crates/cowork-cli/src/main.rs`

**Options**:

- `verbose, v`(boolean): optional - 是否输出详细日志 (default: `false`)
- `config, c`(filepath): optional - 配置文件路径
- `stream, s`(boolean): optional - 是否启用流式输出 (default: `false`)

**Usage Examples**:

```bash
cowork init
```

## Integration Suggestions

### Shell/CLI集成

CLI工具集成指南：作为命令行工具，Cowork Forge通过Shell调用集成到开发工作流。支持通过配置文件或环境变量配置LLM连接，可与CI/CD流水线、脚本或IDE任务系统集成。

**Example Code**:

```
#!/bin/bash
# 初始化项目配置
cowork init

# 编辑配置文件填入API密钥
sed -i 's/your-api-key-here/actual-api-key/' config.toml

# 创建新项目（带流式输出和详细日志）
cowork new "智能待办事项应用" --verbose --stream

# 检查项目状态
cowork status

# 增量修改（添加功能）
cowork modify "添加分类标签功能"

# 如果需要回退到设计阶段
cowork revert --from design
```

**Best Practices**:

- 首次使用前运行 'cowork init' 创建配置文件，编辑设置LLM API端点和密钥
- 使用支持OpenAI API格式的LLM服务端（如vLLM、Ollama、LiteLLM等），配置兼容的api_base_url
- 项目会话数据存储在.cowork目录，确保该目录不被删除或提交到版本控制（添加.gitignore）
- 使用 --stream 标志获取实时AI输出便于调试，生产环境可关闭以减少输出噪音
- 复杂项目分阶段执行，必要时使用 'revert' 回退到指定阶段重新生成
- 定期使用 'status --sessions' 查看会话历史，及时清理失败的会话记录

### 配置管理集成

LLM服务配置集成：系统通过OpenAI兼容协议与LLM服务端通信。需配置有效的API端点、密钥和模型名称。支持本地部署(vLLM/Ollama)和云端API(OpenAI/DeepSeek等)。

**Example Code**:

```
# config.toml 配置示例
[llm]
api_base_url = "http://localhost:8000/v1"
api_key = "sk-xxx"
model_name = "gpt-4"

# Docker Compose 集成示例
version: '3.8'
services:
  cowork-forge:
    image: cowork-forge:latest
    environment:
      - LLM_API_BASE_URL=http://vllm:8000/v1
      - LLM_API_KEY=local-key
      - LLM_MODEL_NAME=Qwen-7B
    volumes:
      - ./workspace:/workspace
    working_dir: /workspace
```

**Best Practices**:

- 优先使用config.toml文件进行生产环境配置，便于版本控制和备份
- 开发/测试环境可使用环境变量(LLM_API_BASE_URL, LLM_API_KEY, LLM_MODEL_NAME)实现快速切换
- 确保API密钥安全，config.toml应加入.gitignore，使用环境变量注入敏感信息
- 对于OpenAI兼容服务，api_base_url需包含/v1路径后缀（如 http://localhost:8000/v1）
- 启用速率限制（内置2秒延迟）防止超出LLM服务商配额限制


---

**Analysis Confidence**: 9.5/10
