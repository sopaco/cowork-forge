# Project Analysis Summary Report (Full Version)

Generation Time: 2026-01-29 06:45:09 UTC

## Execution Timing Statistics

- **Total Execution Time**: 1175.83 seconds
- **Preprocessing Phase**: 0.88 seconds (0.1%)
- **Research Phase**: 460.11 seconds (39.1%)
- **Document Generation Phase**: 714.84 seconds (60.8%)
- **Output Phase**: 0.00 seconds (0.0%)
- **Summary Generation Time**: 0.000 seconds

## Cache Performance Statistics and Savings

### Performance Metrics
- **Cache Hit Rate**: 76.7%
- **Total Operations**: 86
- **Cache Hits**: 66 times
- **Cache Misses**: 20 times
- **Cache Writes**: 21 times

### Savings
- **Inference Time Saved**: 326.7 seconds
- **Tokens Saved**: 109131 input + 42700 output = 151831 total
- **Estimated Cost Savings**: $0.0780
- **Performance Improvement**: 76.7%
- **Efficiency Improvement Ratio**: 0.3x (saved time / actual execution time)

## Core Research Data Summary

Complete content of four types of research materials according to Prompt template data integration rules:

### System Context Research Report
Provides core objectives, user roles, and system boundary information for the project.

```json
{
  "business_value": "é€šè¿‡AIæ™ºèƒ½ä½“è‡ªåŠ¨åŒ–å®Œæˆè½¯ä»¶å¼€å‘ä¸­é‡å¤æ€§ã€æµç¨‹åŒ–çš„å·¥ä½œï¼ˆå¦‚éœ€æ±‚åˆ†æã€æ¶æ„è®¾è®¡ã€ä»»åŠ¡è§„åˆ’ã€ä»£ç å®ç°ä¸äº¤ä»˜éªŒè¯ï¼‰ï¼Œæ˜¾è‘—é™ä½å¼€å‘è€…çš„è®¤çŸ¥è´Ÿè·ä¸æ‰‹åŠ¨æ“ä½œæˆæœ¬ã€‚ç³»ç»Ÿå¼ºè°ƒâ€˜æœ€å°å¯è¡Œæ¶æ„â€™åŸåˆ™ï¼Œå¼ºåˆ¶æ‹’ç»è¿‡åº¦è®¾è®¡ï¼Œæå‡å¼€å‘æ•ˆç‡ä¸ä»£ç è´¨é‡ä¸€è‡´æ€§ã€‚æ”¯æŒå¢é‡ä¿®æ”¹ä¸å†å²å›æº¯ï¼Œä½¿å›¢é˜Ÿèƒ½ä»¥è½»é‡çº§æ–¹å¼å¿«é€Ÿè¿­ä»£äº§å“åŸå‹æˆ–å°å‹é¡¹ç›®ï¼Œç‰¹åˆ«é€‚ç”¨äºåˆåˆ›å›¢é˜Ÿã€ç‹¬ç«‹å¼€å‘è€…å’Œæ•æ·å¼€å‘åœºæ™¯ã€‚",
  "confidence_score": 0.95,
  "external_systems": [
    {
      "description": "ä½œä¸ºåº•å±‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœåŠ¡æä¾›æ–¹ï¼Œè´Ÿè´£æ‰§è¡Œæ™ºèƒ½ä½“çš„æ¨ç†ä¸ç”Ÿæˆä»»åŠ¡ã€‚ç³»ç»Ÿé€šè¿‡è‡ªå®šä¹‰é…ç½®è¿æ¥OpenAIå…¼å®¹çš„APIç«¯ç‚¹ï¼Œæ”¯æŒæ¨¡å‹å‚æ•°ä¸é€Ÿç‡é™åˆ¶æ§åˆ¶ã€‚",
      "interaction_type": "APIè°ƒç”¨",
      "name": "OpenAI API"
    },
    {
      "description": "ä½œä¸ºæŒä¹…åŒ–å­˜å‚¨ä»‹è´¨ï¼Œç”¨äºä¿å­˜æ‰€æœ‰å¼€å‘ä¼šè¯æ•°æ®ã€é¡¹ç›®æ–‡ä»¶ã€ç»“æ„åŒ–æ–‡æ¡£ï¼ˆJSON/Markdownï¼‰ä¸ä¸­é—´äº§ç‰©ã€‚ç³»ç»Ÿä¸¥æ ¼é™åˆ¶æ“ä½œèŒƒå›´åœ¨é¡¹ç›®æ ¹ç›®å½•å†…ï¼Œé˜²æ­¢è¶Šæƒè®¿é—®ã€‚",
      "interaction_type": "æ–‡ä»¶è¯»å†™",
      "name": "æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ"
    },
    {
      "description": "ä½œä¸ºäººæœºäº¤äº’çš„ä¸»è¦æ¥å£ï¼Œç”¨æˆ·é€šè¿‡å‘½ä»¤è¡Œè¾“å…¥æŒ‡ä»¤å¯åŠ¨é¡¹ç›®ã€æä¾›åé¦ˆã€ç¼–è¾‘å†…å®¹æˆ–ä¸­æ–­æµç¨‹ã€‚ç³»ç»Ÿé€šè¿‡äº¤äº’å¼å·¥å…·ï¼ˆå¦‚ReviewAndEditContentToolï¼‰å®ç°ä¸ç”¨æˆ·çš„åŒå‘æ²Ÿé€šã€‚",
      "interaction_type": "å‘½ä»¤è¡Œäº¤äº’",
      "name": "ç”¨æˆ·ç»ˆç«¯ï¼ˆCLIï¼‰"
    }
  ],
  "project_description": "Cowork Forge æ˜¯ä¸€ä¸ªåŸºäºAIçš„è½¯ä»¶å¼€å‘ç¼–æ’ç³»ç»Ÿï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œæµç¨‹ï¼ˆIdea â†’ PRD â†’ Design â†’ Plan â†’ Coding â†’ Check â†’ Deliveryï¼‰è‡ªåŠ¨åŒ–å®Œæˆä»éœ€æ±‚æ„æ€åˆ°ä»£ç äº¤ä»˜çš„å®Œæ•´è½¯ä»¶å¼€å‘å‘¨æœŸã€‚ç³»ç»Ÿé‡‡ç”¨äººç±»å‚ä¸å¾ªç¯ï¼ˆHITLï¼‰æœºåˆ¶ï¼Œåœ¨å…³é”®èŠ‚ç‚¹å¼•å…¥äººå·¥å®¡æ ¸ä¸å¹²é¢„ï¼Œç¡®ä¿å¼€å‘è¿‡ç¨‹ç¬¦åˆç®€æ´æ€§åŸåˆ™å¹¶é¿å…è¿‡åº¦å·¥ç¨‹åŒ–ã€‚æ ¸å¿ƒç”±Rustè¯­è¨€æ„å»ºï¼Œé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼ŒåŒ…å«CLIå…¥å£ã€æ ¸å¿ƒæ™ºèƒ½ä½“å¼•æ“ã€å·¥å…·é›†ä¸æŒä¹…åŒ–å­˜å‚¨ï¼Œæ”¯æŒé¡¹ç›®åˆ›å»ºã€é˜¶æ®µæ¢å¤ã€å¢é‡ä¿®æ”¹ä¸äº¤ä»˜æŠ¥å‘Šç”Ÿæˆã€‚",
  "project_name": "Cowork Forge",
  "project_type": "CLITool",
  "system_boundary": {
    "excluded_components": [
      "Webå‰ç«¯ç•Œé¢",
      "ç§»åŠ¨åº”ç”¨",
      "äº‘æœåŠ¡éƒ¨ç½²ç³»ç»Ÿ",
      "CI/CDæµæ°´çº¿ï¼ˆå¦‚GitHub Actionsï¼‰",
      "æ•°æ®åº“æœåŠ¡ï¼ˆå¦‚PostgreSQLã€MongoDBï¼‰",
      "æµ‹è¯•æ¡†æ¶ï¼ˆå¦‚Rust testsï¼‰",
      "ç›‘æ§ç³»ç»Ÿ",
      "ç¬¬ä¸‰æ–¹APIç½‘å…³"
    ],
    "included_components": [
      "cowork-cliï¼ˆå‘½ä»¤è¡Œå…¥å£ï¼‰",
      "cowork-coreï¼ˆæ ¸å¿ƒæ™ºèƒ½ä½“ã€å·¥å…·ã€å­˜å‚¨ã€æŒ‡ä»¤é›†ï¼‰",
      "LLMé…ç½®ä¸é€Ÿç‡é™åˆ¶æ¨¡å—",
      "æ–‡ä»¶ç³»ç»Ÿæ“ä½œå·¥å…·",
      "JSON/MarkdownæŒä¹…åŒ–å­˜å‚¨",
      "HITLäº¤äº’å·¥å…·"
    ],
    "scope": "Cowork Forge CLI å·¥å…·åŠå…¶æ ¸å¿ƒæ™ºèƒ½ä½“å¼•æ“ï¼Œä¸åŒ…å«ä»»ä½•å‰ç«¯ç•Œé¢ã€WebæœåŠ¡ã€æ•°æ®åº“æœåŠ¡æˆ–æŒç»­é›†æˆ/éƒ¨ç½²ï¼ˆCI/CDï¼‰ç³»ç»Ÿã€‚"
  },
  "target_users": [
    {
      "description": "ç¼ºä¹å›¢é˜Ÿæ”¯æŒçš„ä¸ªäººå¼€å‘è€…ï¼Œå¸Œæœ›å¿«é€Ÿå°†æƒ³æ³•è½¬åŒ–ä¸ºå¯è¿è¡Œçš„ä»£ç ï¼Œä½†ç¼ºä¹æ—¶é—´æˆ–ç²¾åŠ›å¤„ç†ç¹ççš„å¼€å‘æµç¨‹ã€‚",
      "name": "ç‹¬ç«‹å¼€å‘è€…",
      "needs": [
        "è‡ªåŠ¨åŒ–å®Œæˆä»æƒ³æ³•åˆ°ä»£ç çš„å…¨æµç¨‹",
        "é¿å…è¿‡åº¦è®¾è®¡ï¼Œä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½",
        "è·å¾—ç»“æ„åŒ–äº¤ä»˜æŠ¥å‘Šä»¥ç”¨äºå±•ç¤ºæˆ–å­˜æ¡£",
        "æ”¯æŒä¸­é€”ä¿®æ”¹ä¸æ¢å¤å·¥ä½œ"
      ]
    },
    {
      "description": "å°å‹åˆ›ä¸šå›¢é˜Ÿï¼Œèµ„æºæœ‰é™ï¼Œéœ€è¦å¿«é€ŸéªŒè¯äº§å“å¯è¡Œæ€§ï¼Œå¯¹å¼€å‘æµç¨‹çš„è§„èŒƒæ€§ä¸æ•ˆç‡æœ‰è¾ƒé«˜è¦æ±‚ã€‚",
      "name": "åˆåˆ›å›¢é˜Ÿ",
      "needs": [
        "æ ‡å‡†åŒ–å¼€å‘æµç¨‹ä»¥å‡å°‘æ²Ÿé€šæˆæœ¬",
        "é€šè¿‡AIè¾…åŠ©ç¡®ä¿éœ€æ±‚ä¸å®ç°çš„ä¸€è‡´æ€§",
        "ç”Ÿæˆå¯äº¤ä»˜çš„æ–‡æ¡£ä¸ä»£ç åŒ…",
        "æ”¯æŒè½»é‡çº§è¿­ä»£ä¸å˜æ›´è¿½è¸ª"
      ]
    },
    {
      "description": "ç†Ÿæ‚‰æ•æ·æ–¹æ³•çš„å¼€å‘è€…ï¼Œå¸Œæœ›å€ŸåŠ©AIå·¥å…·æå‡å¼€å‘æ•ˆç‡ï¼Œä½†ä¸æ„¿æ”¾å¼ƒå¯¹å…³é”®å†³ç­–çš„æ§åˆ¶æƒã€‚",
      "name": "æ•æ·å¼€å‘å·¥ç¨‹å¸ˆ",
      "needs": [
        "åœ¨å…³é”®èŠ‚ç‚¹ä¿ç•™äººå·¥å®¡æ ¸æƒé™ï¼ˆHITLï¼‰",
        "çµæ´»æ§åˆ¶å¼€å‘æµç¨‹çš„å¯åŠ¨ä¸å›é€€",
        "è·å–æ¸…æ™°çš„å˜æ›´å½±å“åˆ†ææŠ¥å‘Š",
        "é¿å…AIç”Ÿæˆå†—ä½™ä»£ç æˆ–æµ‹è¯•"
      ]
    }
  ]
}
```

### Domain Modules Research Report
Provides high-level domain division, module relationships, and core business process information.

```json
{
  "architecture_summary": "Cowork Forge é‡‡ç”¨æ¨¡å—åŒ–åˆ†å±‚æ¶æ„ï¼Œä»¥ CLI å…¥å£ä¸ºè§¦å‘ç‚¹ï¼Œæ ¸å¿ƒç”±æ™ºèƒ½ä½“ç¼–æ’å¼•æ“ã€å·¥å…·é›†ä¸æŒä¹…åŒ–å­˜å‚¨æ„æˆï¼Œå½¢æˆâ€œæŒ‡ä»¤é©±åŠ¨-å·¥å…·æ‰§è¡Œ-æ•°æ®æŒä¹…åŒ–â€çš„é—­ç¯å¼€å‘æµç¨‹ã€‚ç³»ç»Ÿéµå¾ªâ€œæœ€å°å¯è¡Œæ¶æ„â€åŸåˆ™ï¼Œé€šè¿‡äººç±»å‚ä¸å¾ªç¯ï¼ˆHITLï¼‰æœºåˆ¶åœ¨å…³é”®èŠ‚ç‚¹å¼•å…¥äººå·¥å®¡æ ¸ï¼Œç¡®ä¿å¼€å‘è¿‡ç¨‹ç®€æ´é«˜æ•ˆã€‚æ•´ä½“æ¶æ„ä¸ºå…¸å‹çš„â€œç¼–æ’å±‚-æ™ºèƒ½ä½“å±‚-å·¥å…·å±‚-æ•°æ®å±‚â€å››å±‚ç»“æ„ï¼Œå„å±‚èŒè´£æ¸…æ™°ï¼Œä¾èµ–å•å‘ä¸‹è¡Œï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ä¸å¯ç»´æŠ¤æ€§ã€‚",
  "business_flows": [
    {
      "description": "ä»ç”¨æˆ·è¾“å…¥åˆå§‹æƒ³æ³•å¼€å§‹ï¼Œä¾æ¬¡è§¦å‘Ideaã€PRDã€Designã€Planã€Codingã€Checkã€Deliveryä¸ƒä¸ªæ™ºèƒ½ä½“é˜¶æ®µï¼Œå®Œæˆä»éœ€æ±‚æ„æ€åˆ°äº¤ä»˜æŠ¥å‘Šçš„å®Œæ•´å¼€å‘é—­ç¯ã€‚æ¯ä¸ªé˜¶æ®µå‡åŒ…å«æ™ºèƒ½ä½“æ‰§è¡Œä¸HITLå®¡æ ¸ï¼Œç¡®ä¿è¾“å‡ºç¬¦åˆç®€æ´æ€§åŸåˆ™ã€‚æµç¨‹ç»“æŸæ—¶ç”Ÿæˆå®Œæ•´çš„äº¤ä»˜æ–‡æ¡£ä¸ä»£ç åŒ…ã€‚",
      "entry_point": "ç”¨æˆ·æ‰§è¡Œ `cowork-cli create` å‘½ä»¤ï¼Œè§¦å‘ main.rs ä¸­çš„é¡¹ç›®åˆ›å»ºé€»è¾‘ï¼Œè¿›è€Œè°ƒç”¨ pipeline æ¨¡å—çš„ full_pipeline å‡½æ•°",
      "importance": 10.0,
      "involved_domains_count": 5,
      "name": "å…¨æ–°é¡¹ç›®åˆ›å»ºæµç¨‹",
      "steps": [
        {
          "code_entry_point": null,
          "domain_module": "å…¥å£ä¸ç¼–æ’åŸŸ",
          "operation": "è§£æ CLI å‘½ä»¤å‚æ•°ï¼Œåˆå§‹åŒ–ä¼šè¯ç›®å½•ç»“æ„ï¼ŒåŠ è½½å…¨å±€é…ç½®",
          "step": 1,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ IdeaAgent æŒ‡ä»¤æ¨¡æ¿ï¼Œå¯åŠ¨é¦–ä¸ªæ™ºèƒ½ä½“æ•è·å¹¶ç»“æ„åŒ–ç”¨æˆ·åŸå§‹æƒ³æ³•",
          "step": 2,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ PRD æŒ‡ä»¤æ¨¡æ¿ï¼Œå¯åŠ¨ PRD Actor-Critic å¾ªç¯ï¼Œç”Ÿæˆäº§å“éœ€æ±‚æ–‡æ¡£",
          "step": 3,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ Design æŒ‡ä»¤æ¨¡æ¿ï¼Œå¯åŠ¨ Design Actor-Critic å¾ªç¯ï¼Œç”Ÿæˆæœ€å°åŒ–æ¶æ„è®¾è®¡",
          "step": 4,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ Plan æŒ‡ä»¤æ¨¡æ¿ï¼Œå¯åŠ¨ Plan Actor-Critic å¾ªç¯ï¼Œç”Ÿæˆä»…å«æ ¸å¿ƒåŠŸèƒ½çš„ä»»åŠ¡æ¸…å•",
          "step": 5,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ Coding æŒ‡ä»¤æ¨¡æ¿ï¼Œå¯åŠ¨ Coding Actor-Critic å¾ªç¯ï¼Œå®ç°åŠŸèƒ½ä»£ç ",
          "step": 6,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å·¥å…·æ‰§è¡ŒåŸŸ",
          "operation": "è°ƒç”¨ file_tools è¯»å†™ä»£ç æ–‡ä»¶ï¼Œè°ƒç”¨ data_tools æŒä¹…åŒ–ä»»åŠ¡ä¸éœ€æ±‚çŠ¶æ€",
          "step": 7,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ CheckAgent æŒ‡ä»¤ï¼ŒéªŒè¯ä»£ç ç»“æ„å®Œæ•´æ€§ä¸ä»»åŠ¡è¦†ç›–ç‡ï¼Œä»…æ‹’ç»ä¸¥é‡ç¼ºå¤±",
          "step": 8,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ DeliveryAgent æŒ‡ä»¤ï¼Œæ•´åˆæ‰€æœ‰æ–‡æ¡£ä¸ä»£ç ï¼Œç”Ÿæˆäº¤ä»˜æŠ¥å‘Š",
          "step": 9,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å·¥å…·æ‰§è¡ŒåŸŸ",
          "operation": "è°ƒç”¨ artifact_tools ä¿å­˜äº¤ä»˜æŠ¥å‘Šã€PRDã€è®¾è®¡æ–‡æ¡£ç­‰äº§ç‰©è‡³ä¼šè¯ç›®å½•",
          "step": 10,
          "sub_module": null
        }
      ]
    },
    {
      "description": "åœ¨å·²æœ‰é¡¹ç›®åŸºç¡€ä¸Šï¼Œæ ¹æ®ç”¨æˆ·å˜æ›´è¯·æ±‚ï¼ˆChangeRequestï¼‰è§¦å‘ä¿®æ”¹æµç¨‹ã€‚ç³»ç»Ÿå…ˆé€šè¿‡ Modify Triage Agent åˆ†æå˜æ›´èŒƒå›´ï¼Œå†å†³å®šæ˜¯å¦éœ€è¦å›é€€è‡³ PRDã€Designã€Plan æˆ–ç›´æ¥è¿›å…¥ Coding é˜¶æ®µè¿›è¡Œä»£ç ä¿®è¡¥ï¼Œæœ€ç»ˆç”± Modify Delivery Agent ç”Ÿæˆå˜æ›´æŠ¥å‘Šã€‚æµç¨‹æ”¯æŒä»»æ„é˜¶æ®µçš„å›æº¯ä¸é‡å¯åŠ¨ã€‚",
      "entry_point": "ç”¨æˆ·æ‰§è¡Œ `cowork-cli modify` å‘½ä»¤ï¼Œè§¦å‘ main.rs ä¸­çš„ä¿®æ”¹é€»è¾‘ï¼Œè°ƒç”¨ pipeline æ¨¡å—çš„ modify_pipeline å‡½æ•°",
      "importance": 9.0,
      "involved_domains_count": 5,
      "name": "å¢é‡ä¿®æ”¹æµç¨‹",
      "steps": [
        {
          "code_entry_point": null,
          "domain_module": "å…¥å£ä¸ç¼–æ’åŸŸ",
          "operation": "è§£æ CLI ä¿®æ”¹å‘½ä»¤ï¼ŒåŠ è½½å½“å‰ä¼šè¯çŠ¶æ€ä¸å†å²æ•°æ®",
          "step": 1,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ Modify Triage Agent æŒ‡ä»¤ï¼Œåˆ†æç”¨æˆ·å˜æ›´è¯·æ±‚ï¼Œç¡®å®šå½±å“èŒƒå›´ï¼ˆPRD/Design/Plan/Codeï¼‰",
          "step": 2,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å·¥å…·æ‰§è¡ŒåŸŸ",
          "operation": "è°ƒç”¨ modify_tools åŠ è½½/ä¿å­˜ ChangeRequest å¯¹è±¡ï¼Œè®°å½•å˜æ›´èŒƒå›´ä¸é£é™©è¯„ä¼°",
          "step": 3,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å…¥å£ä¸ç¼–æ’åŸŸ",
          "operation": "æ ¹æ®å˜æ›´å½±å“ï¼Œé€‰æ‹©æ€§å›é€€è‡³ PRDã€Design æˆ– Plan é˜¶æ®µï¼Œè°ƒç”¨å¯¹åº” pipeline",
          "step": 4,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "è‹¥æ— éœ€å›é€€ï¼Œç›´æ¥å¯åŠ¨ Coding Agent æ‰§è¡Œä»£ç ä¿®è¡¥",
          "step": 5,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å·¥å…·æ‰§è¡ŒåŸŸ",
          "operation": "è°ƒç”¨ file_toolsã€data_tools æ›´æ–°ä»£ç ä¸ç»“æ„åŒ–æ•°æ®",
          "step": 6,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "å¯åŠ¨ Modify Delivery Agentï¼Œæ•´åˆå˜æ›´å‰åçŠ¶æ€ã€åé¦ˆå†å²ä¸ä»£ç å·®å¼‚ï¼Œç”Ÿæˆå˜æ›´æŠ¥å‘Š",
          "step": 7,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å·¥å…·æ‰§è¡ŒåŸŸ",
          "operation": "è°ƒç”¨ artifact_tools ä¿å­˜å˜æ›´æŠ¥å‘Šè‡³ä¼šè¯ç›®å½•",
          "step": 8,
          "sub_module": null
        }
      ]
    },
    {
      "description": "å…è®¸ç”¨æˆ·åœ¨ä»»æ„å¼€å‘é˜¶æ®µä¸­æ–­åï¼Œä»æŒ‡å®šèŠ‚ç‚¹ï¼ˆå¦‚ PRDã€Designã€Planï¼‰é‡æ–°å¼€å§‹ï¼Œè·³è¿‡å·²å®Œæˆé˜¶æ®µã€‚ç³»ç»Ÿé€šè¿‡åŠ è½½å†å²ä¼šè¯æ•°æ®æ¢å¤ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æµç¨‹è¿ç»­æ€§ã€‚è¯¥æµç¨‹æ˜¯æ”¯æŒå¢é‡ä¿®æ”¹ä¸æ•æ·è¿­ä»£çš„æ ¸å¿ƒæ”¯æ’‘æœºåˆ¶ã€‚",
      "entry_point": "ç”¨æˆ·æ‰§è¡Œ `cowork-cli resume --stage <stage>` å‘½ä»¤ï¼Œè§¦å‘ main.rs ä¸­çš„æ¢å¤é€»è¾‘ï¼Œè°ƒç”¨ pipeline æ¨¡å—çš„ resume_pipeline å‡½æ•°",
      "importance": 8.0,
      "involved_domains_count": 4,
      "name": "é˜¶æ®µæ¢å¤æµç¨‹",
      "steps": [
        {
          "code_entry_point": null,
          "domain_module": "å…¥å£ä¸ç¼–æ’åŸŸ",
          "operation": "è§£ææ¢å¤å‘½ä»¤ä¸ç›®æ ‡é˜¶æ®µï¼ŒéªŒè¯é˜¶æ®µæœ‰æ•ˆæ€§",
          "step": 1,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æŒä¹…åŒ–å­˜å‚¨åŸŸ",
          "operation": "ä» .cowork/sessions/<id>/ ç›®å½•åŠ è½½å¯¹åº”é˜¶æ®µçš„å…ƒæ•°æ®ä¸ä¸­é—´äº§ç‰©",
          "step": 2,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å…¥å£ä¸ç¼–æ’åŸŸ",
          "operation": "æ„å»ºä»æŒ‡å®šé˜¶æ®µå¼€å§‹çš„å­æµç¨‹ï¼Œè·³è¿‡å·²æ‰§è¡Œçš„ä¸Šæ¸¸é˜¶æ®µ",
          "step": 3,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
          "operation": "åŠ è½½ç›®æ ‡é˜¶æ®µåŠåç»­æ‰€æœ‰é˜¶æ®µçš„æŒ‡ä»¤æ¨¡æ¿ï¼Œå¯åŠ¨æ™ºèƒ½ä½“æµæ°´çº¿",
          "step": 4,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å·¥å…·æ‰§è¡ŒåŸŸ",
          "operation": "åœ¨åç»­é˜¶æ®µæ‰§è¡Œä¸­ï¼Œè°ƒç”¨ data_toolsã€file_tools æŒç»­æ›´æ–°çŠ¶æ€ä¸æ–‡ä»¶",
          "step": 5,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å…¥å£ä¸ç¼–æ’åŸŸ",
          "operation": "æµç¨‹ç»“æŸåï¼Œæ›´æ–°ä¼šè¯å…ƒæ•°æ®ï¼Œæ ‡è®°å·²æ‰§è¡Œé˜¶æ®µ",
          "step": 6,
          "sub_module": null
        }
      ]
    },
    {
      "description": "åœ¨æ™ºèƒ½ä½“æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå½“é‡åˆ°ä¸ç¡®å®šæ€§ã€é”™è¯¯æˆ–éœ€è¦å†³ç­–æ—¶ï¼Œç³»ç»Ÿé€šè¿‡ HITL å·¥å…·ä¸»åŠ¨è¯·æ±‚ç”¨æˆ·ä»‹å…¥ã€‚æ”¯æŒå†…å®¹ç¼–è¾‘ã€æ–‡ä»¶å®¡æŸ¥ã€æä¾›åé¦ˆã€è¯·æ±‚é‡è§„åˆ’ç­‰å¤šç§äº¤äº’æ–¹å¼ï¼Œç¡®ä¿å¼€å‘è¿‡ç¨‹å¯æ§ä¸”ç¬¦åˆç”¨æˆ·æ„å›¾ã€‚",
      "entry_point": "æ™ºèƒ½ä½“æ‰§è¡ŒæœŸé—´è§¦å‘ error æˆ–éœ€è¦ human_input æ—¶ï¼Œç”± ResilientAgent æˆ– ControlTools ä¸»åŠ¨è°ƒç”¨ HITL å·¥å…·",
      "importance": 8.0,
      "involved_domains_count": 3,
      "name": "äººæœºäº¤äº’åé¦ˆæµç¨‹",
      "steps": [
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸ",
          "operation": "æ™ºèƒ½ä½“æ£€æµ‹åˆ° Max Iterations é”™è¯¯æˆ–éœ€äººå·¥å†³ç­–ï¼Œè°ƒç”¨ ResilientAgent åŒ…è£…å™¨",
          "step": 1,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å·¥å…·æ‰§è¡ŒåŸŸ",
          "operation": "è°ƒç”¨ ReviewAndEditContentTool æˆ– ReviewWithFeedbackTool è¯·æ±‚ç”¨æˆ·ç¼–è¾‘æˆ–åé¦ˆ",
          "step": 2,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "å·¥å…·æ‰§è¡ŒåŸŸ",
          "operation": "è°ƒç”¨ ProvideFeedbackTool æˆ– RequestReplanningTool æ”¶é›†ç»“æ„åŒ–åé¦ˆå¹¶æŒä¹…åŒ–",
          "step": 3,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸ",
          "operation": "ResilientAgent æ ¹æ®ç”¨æˆ·åé¦ˆå†³å®šï¼šé‡è¯•ã€ç»§ç»­æˆ–ä¸­æ­¢æµç¨‹",
          "step": 4,
          "sub_module": null
        },
        {
          "code_entry_point": null,
          "domain_module": "æŒä¹…åŒ–å­˜å‚¨åŸŸ",
          "operation": "å°†ç”¨æˆ·åé¦ˆè®°å½•å†™å…¥ session çš„ feedback_history.json æ–‡ä»¶ï¼Œä¾›åç»­é˜¶æ®µå‚è€ƒ",
          "step": 5,
          "sub_module": null
        }
      ]
    }
  ],
  "confidence_score": 0.97,
  "domain_modules": [
    {
      "code_paths": [
        "crates/cowork-cli/src/main.rs",
        "crates/cowork-core/src/pipeline/mod.rs"
      ],
      "complexity": 7.0,
      "description": "è´Ÿè´£ç³»ç»Ÿå¯åŠ¨ã€æµç¨‹ç¼–æ’ä¸ä¼šè¯æ§åˆ¶ã€‚ä½œä¸ºç”¨æˆ·ä¸ç³»ç»Ÿäº¤äº’çš„å”¯ä¸€å…¥å£ï¼Œè¯¥åŸŸè§£æ CLI å‘½ä»¤ï¼Œåè°ƒå„æ™ºèƒ½ä½“é˜¶æ®µçš„æ‰§è¡Œé¡ºåºï¼Œå¹¶ç®¡ç†æµç¨‹çš„å¯åŠ¨ã€æ¢å¤ã€ä¸­æ–­ä¸é‡å®šå‘ã€‚å…¶æ ¸å¿ƒä»·å€¼åœ¨äºå°†å¤æ‚çš„å¤šæ™ºèƒ½ä½“åä½œæµç¨‹å°è£…ä¸ºå¯å¤ç”¨çš„æµæ°´çº¿ï¼Œå®ç°å¼€å‘æµç¨‹çš„è‡ªåŠ¨åŒ–ä¸æ ‡å‡†åŒ–ã€‚",
      "domain_type": "Core Business Domain",
      "importance": 10.0,
      "name": "å…¥å£ä¸ç¼–æ’åŸŸ",
      "sub_modules": [
        {
          "code_paths": [
            "crates/cowork-cli/src/main.rs"
          ],
          "description": "å‘½ä»¤è¡Œå‚æ•°è§£æä¸ä¼šè¯åˆå§‹åŒ–å…¥å£ï¼Œè´Ÿè´£æ¥æ”¶ç”¨æˆ·æŒ‡ä»¤å¹¶è§¦å‘å¯¹åº”æµç¨‹",
          "importance": 9.0,
          "key_functions": [
            "main",
            "create_project",
            "modify_project",
            "resume_project"
          ],
          "name": "CLI å…¥å£"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/pipeline/mod.rs"
          ],
          "description": "å®šä¹‰å¹¶æ‰§è¡Œä¸åŒé˜¶æ®µç»„åˆçš„å¼€å‘æµç¨‹ï¼ˆå¦‚ full_pipelineã€modify_pipelineã€resume_pipelineï¼‰ï¼Œæ˜¯æµç¨‹è‡ªåŠ¨åŒ–çš„æ ¸å¿ƒæ§åˆ¶å™¨",
          "importance": 10.0,
          "key_functions": [
            "full_pipeline",
            "modify_pipeline",
            "resume_pipeline",
            "create_pipeline"
          ],
          "name": "æµæ°´çº¿ç¼–æ’"
        }
      ]
    },
    {
      "code_paths": [
        "crates/cowork-core/src/instructions/mod.rs",
        "crates/cowork-core/src/instructions/idea.rs",
        "crates/cowork-core/src/instructions/prd.rs",
        "crates/cowork-core/src/instructions/design.rs",
        "crates/cowork-core/src/instructions/plan.rs",
        "crates/cowork-core/src/instructions/coding.rs",
        "crates/cowork-core/src/instructions/check.rs",
        "crates/cowork-core/src/instructions/delivery.rs",
        "crates/cowork-core/src/instructions/modify.rs",
        "crates/cowork-core/src/instructions/code_patch.rs",
        "crates/cowork-core/src/instructions/modify_delivery.rs"
      ],
      "complexity": 9.0,
      "description": "å®šä¹‰æ‰€æœ‰æ™ºèƒ½ä½“çš„è¡Œä¸ºé€»è¾‘ä¸å†³ç­–è§„åˆ™ã€‚è¯¥åŸŸåŒ…å«10ä¸ªç‹¬ç«‹çš„æŒ‡ä»¤æ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—ä¸ºä¸€ä¸ªæ™ºèƒ½ä½“ï¼ˆå¦‚IdeaAgentã€PRD Actorï¼‰æä¾›è¯¦ç»†çš„æç¤ºè¯ï¼ˆpromptï¼‰æ¨¡æ¿ï¼Œè§„å®šå…¶è§’è‰²ã€ä»»åŠ¡ã€è¾“å‡ºæ ¼å¼ã€å¯ç”¨å·¥å…·ä¸ç»ˆæ­¢æ¡ä»¶ã€‚è¯¥åŸŸæ˜¯ç³»ç»Ÿæ™ºèƒ½çš„æ ¸å¿ƒï¼Œå†³å®šäº†AIå¦‚ä½•ç†è§£ä»»åŠ¡ã€æ‰§è¡Œå·¥ä½œä¸è‡ªæˆ‘æ ¡éªŒã€‚",
      "domain_type": "Core Business Domain",
      "importance": 10.0,
      "name": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
      "sub_modules": [
        {
          "code_paths": [
            "crates/cowork-core/src/instructions/idea.rs",
            "crates/cowork-core/src/instructions/prd.rs",
            "crates/cowork-core/src/instructions/design.rs",
            "crates/cowork-core/src/instructions/plan.rs",
            "crates/cowork-core/src/instructions/coding.rs",
            "crates/cowork-core/src/instructions/check.rs",
            "crates/cowork-core/src/instructions/delivery.rs",
            "crates/cowork-core/src/instructions/modify.rs",
            "crates/cowork-core/src/instructions/code_patch.rs",
            "crates/cowork-core/src/instructions/modify_delivery.rs"
          ],
          "description": "æ¯ä¸ªæŒ‡ä»¤æ–‡ä»¶å®šä¹‰ä¸€ä¸ªæˆ–ä¸€ç»„æ™ºèƒ½ä½“ï¼ˆActor-Criticï¼‰çš„å®Œæ•´å·¥ä½œæµç¨‹ä¸çº¦æŸ",
          "importance": 10.0,
          "key_functions": [
            "IDEA_AGENT_INSTRUCTION",
            "PRD_ACTOR_INSTRUCTION",
            "DESIGN_ACTOR_INSTRUCTION",
            "PLAN_ACTOR_INSTRUCTION",
            "CODING_ACTOR_INSTRUCTION",
            "CHECK_AGENT_INSTRUCTION",
            "DELIVERY_AGENT_INSTRUCTION",
            "MODIFY_TRIAGE_INSTRUCTION",
            "CODE_PATCH_INSTRUCTION",
            "MODIFY_DELIVERY_INSTRUCTION"
          ],
          "name": "æ™ºèƒ½ä½“æ¨¡æ¿"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/instructions/mod.rs"
          ],
          "description": "é€šè¿‡ mod.rs æ–‡ä»¶ç»Ÿä¸€æš´éœ²æ‰€æœ‰æŒ‡ä»¤æ¨¡å—ï¼Œä¸ºæ™ºèƒ½ä½“å¼•æ“æä¾›ä¾¿æ·è®¿é—®æ¥å£",
          "importance": 8.0,
          "key_functions": [
            "re-exports"
          ],
          "name": "æŒ‡ä»¤èšåˆ"
        }
      ]
    },
    {
      "code_paths": [
        "crates/cowork-core/src/agents/mod.rs",
        "crates/cowork-core/src/agents/hitl.rs"
      ],
      "complexity": 8.0,
      "description": "è´Ÿè´£å®ä¾‹åŒ–ã€è°ƒç”¨ä¸ç®¡ç†æ™ºèƒ½ä½“çš„è¿è¡Œæ—¶è¡Œä¸ºã€‚è¯¥åŸŸé€šè¿‡ agent/mod.rs æ„å»º LLM Agent å®ä¾‹ï¼Œå¹¶é€šè¿‡ hitl.rs å®ç°å®¹é”™ä¸äººæœºäº¤äº’çš„å°è£…ã€‚å…¶æ ¸å¿ƒä»·å€¼åœ¨äºå°†é™æ€æŒ‡ä»¤è½¬åŒ–ä¸ºåŠ¨æ€æ‰§è¡Œæµï¼Œå¹¶é€šè¿‡ ResilientAgent å®ç°å…³é”®é”™è¯¯çš„è‡ªåŠ¨æ¢å¤ï¼Œç¡®ä¿æµç¨‹é²æ£’æ€§ã€‚",
      "domain_type": "Core Business Domain",
      "importance": 9.0,
      "name": "æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸ",
      "sub_modules": [
        {
          "code_paths": [
            "crates/cowork-core/src/agents/mod.rs"
          ],
          "description": "å®šä¹‰åˆ›å»ºå„ç±»æ™ºèƒ½ä½“ï¼ˆåŒ…æ‹¬Actor-Criticå¯¹ï¼‰çš„å·¥å‚å‡½æ•°ï¼Œå°è£…LLMå®¢æˆ·ç«¯ä¸å·¥å…·ç»‘å®šé€»è¾‘",
          "importance": 9.0,
          "key_functions": [
            "build_idea_agent",
            "build_prd_agent",
            "build_design_agent",
            "build_plan_agent",
            "build_coding_agent",
            "build_check_agent",
            "build_delivery_agent"
          ],
          "name": "æ™ºèƒ½ä½“æ„å»ºå™¨"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/agents/hitl.rs"
          ],
          "description": "å°è£… ResilientAgentï¼Œæ‹¦æˆªæ™ºèƒ½ä½“æ‰§è¡Œä¸­çš„å¤±è´¥ï¼Œæä¾›é‡è¯•ã€å¼•å¯¼æˆ–ä¸­æ­¢çš„æ¢å¤é€‰é¡¹ï¼Œæ˜¯HITLæœºåˆ¶çš„æ ¸å¿ƒå®ç°",
          "importance": 9.0,
          "key_functions": [
            "ResilientAgent",
            "ResilientStream"
          ],
          "name": "äººæœºäº¤äº’å°è£…"
        }
      ]
    },
    {
      "code_paths": [
        "crates/cowork-core/src/tools/mod.rs",
        "crates/cowork-core/src/tools/file_tools.rs",
        "crates/cowork-core/src/tools/validation_tools.rs",
        "crates/cowork-core/src/tools/hitl_content_tools.rs",
        "crates/cowork-core/src/tools/idea_tools.rs",
        "crates/cowork-core/src/tools/data_tools.rs",
        "crates/cowork-core/src/tools/hitl_tools.rs",
        "crates/cowork-core/src/tools/goto_stage_tool.rs",
        "crates/cowork-core/src/tools/modify_tools.rs",
        "crates/cowork-core/src/tools/control_tools.rs",
        "crates/cowork-core/src/tools/artifact_tools.rs"
      ],
      "complexity": 8.0,
      "description": "æä¾›æ™ºèƒ½ä½“æ‰§è¡Œæ‰€éœ€çš„å…·ä½“æ“ä½œèƒ½åŠ›ã€‚è¯¥åŸŸåŒ…å«11ä¸ªå·¥å…·æ¨¡å—ï¼Œæ¯ä¸ªå·¥å…·å°è£…ä¸€ä¸ªåŸå­åŒ–æ“ä½œï¼ˆå¦‚è¯»å†™æ–‡ä»¶ã€éªŒè¯æ•°æ®ã€ä¿å­˜æŠ¥å‘Šã€è·å–åé¦ˆï¼‰ï¼Œé€šè¿‡ç»Ÿä¸€çš„ Tool trait æ¥å£è¢«æ™ºèƒ½ä½“è°ƒç”¨ã€‚å…¶æ ¸å¿ƒä»·å€¼åœ¨äºå°†å¤æ‚æ“ä½œæ ‡å‡†åŒ–ã€å®‰å…¨åŒ–ï¼Œä½¿æ™ºèƒ½ä½“æ— éœ€å…³å¿ƒåº•å±‚å®ç°ç»†èŠ‚ã€‚",
      "domain_type": "Tool Support Domain",
      "importance": 9.0,
      "name": "å·¥å…·æ‰§è¡ŒåŸŸ",
      "sub_modules": [
        {
          "code_paths": [
            "crates/cowork-core/src/tools/file_tools.rs"
          ],
          "description": "æä¾›å®‰å…¨çš„æ–‡ä»¶è¯»å†™ã€ç›®å½•éå†ä¸å‘½ä»¤æ‰§è¡Œèƒ½åŠ›ï¼Œä¸¥æ ¼é™åˆ¶è·¯å¾„èŒƒå›´ï¼Œé˜²æ­¢è¶Šæƒè®¿é—®",
          "importance": 8.0,
          "key_functions": [
            "ListFilesTool",
            "ReadFileTool",
            "WriteFileTool",
            "RunCommandTool"
          ],
          "name": "æ–‡ä»¶æ“ä½œå·¥å…·"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/tools/data_tools.rs"
          ],
          "description": "æä¾›å¯¹éœ€æ±‚ã€è®¾è®¡ã€è®¡åˆ’ç­‰ç»“æ„åŒ–æ•°æ®çš„å¢åˆ æ”¹æŸ¥èƒ½åŠ›ï¼Œä¾èµ– data æ¨¡å—çš„æ¨¡å‹è¿›è¡Œåºåˆ—åŒ–",
          "importance": 9.0,
          "key_functions": [
            "SaveRequirementsTool",
            "LoadRequirementsTool",
            "SaveImplementationPlanTool",
            "DeleteTaskTool"
          ],
          "name": "æ•°æ®æ“ä½œå·¥å…·"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/tools/validation_tools.rs"
          ],
          "description": "æä¾›æ•°æ®æ ¼å¼ã€ç‰¹å¾è¦†ç›–ã€ä»»åŠ¡ä¾èµ–ç­‰è´¨é‡éªŒè¯èƒ½åŠ›ï¼Œç¡®ä¿å¼€å‘äº§ç‰©ç¬¦åˆé¢„æœŸç»“æ„",
          "importance": 8.0,
          "key_functions": [
            "CheckDataFormatTool",
            "CheckFeatureCoverageTool",
            "CheckTaskDependenciesTool"
          ],
          "name": "éªŒè¯å·¥å…·"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/tools/hitl_content_tools.rs",
            "crates/cowork-core/src/tools/hitl_tools.rs",
            "crates/cowork-core/src/tools/control_tools.rs"
          ],
          "description": "æä¾›ä¸ç”¨æˆ·äº¤äº’çš„ç•Œé¢ï¼Œæ”¯æŒå†…å®¹ç¼–è¾‘ã€æ–‡ä»¶å®¡æŸ¥ä¸åé¦ˆæ”¶é›†",
          "importance": 9.0,
          "key_functions": [
            "ReviewAndEditContentTool",
            "ReviewWithFeedbackContentTool",
            "ReviewAndEditFileTool",
            "ReviewWithFeedbackTool",
            "ProvideFeedbackTool",
            "RequestReplanningTool",
            "AskUserTool"
          ],
          "name": "HITLäº¤äº’å·¥å…·"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/tools/goto_stage_tool.rs",
            "crates/cowork-core/src/tools/modify_tools.rs",
            "crates/cowork-core/src/tools/artifact_tools.rs"
          ],
          "description": "æä¾›ä¼šè¯çŠ¶æ€ç®¡ç†èƒ½åŠ›ï¼Œå¦‚è·³è½¬åˆ°æŒ‡å®šé˜¶æ®µã€ä¿å­˜/åŠ è½½å˜æ›´è¯·æ±‚ä¸äº¤ä»˜æŠ¥å‘Š",
          "importance": 8.0,
          "key_functions": [
            "GotoStageTool",
            "SaveChangeRequestTool",
            "LoadChangeRequestTool",
            "SaveDeliveryReportTool",
            "SavePrdDocTool",
            "SaveDesignDocTool",
            "LoadFeedbackHistoryTool"
          ],
          "name": "ä¼šè¯æ§åˆ¶å·¥å…·"
        }
      ]
    },
    {
      "code_paths": [
        "crates/cowork-core/src/storage/mod.rs",
        "crates/cowork-core/src/data/mod.rs",
        "crates/cowork-core/src/data/models.rs",
        "crates/cowork-core/src/data/schemas.rs",
        "crates/cowork-core/src/data/schemas/validation.rs"
      ],
      "complexity": 7.0,
      "description": "è´Ÿè´£æ‰€æœ‰å¼€å‘äº§ç‰©ä¸ä¼šè¯çŠ¶æ€çš„æŒä¹…åŒ–ç®¡ç†ã€‚è¯¥åŸŸä»¥ä¼šè¯ä¸ºå•ä½ï¼Œåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»º .cowork ç›®å½•ï¼Œä½¿ç”¨JSONæ–‡ä»¶å­˜å‚¨æ¨¡å‹æ•°æ®ã€é…ç½®ã€åé¦ˆå†å²ä¸ä¸­é—´äº§ç‰©ã€‚å…¶æ ¸å¿ƒä»·å€¼åœ¨äºå®ç°å¼€å‘æµç¨‹çš„å¯æ¢å¤æ€§ã€å¯è¿½æº¯æ€§ä¸çŠ¶æ€éš”ç¦»ï¼Œæ˜¯æ”¯æŒå¢é‡ä¿®æ”¹ä¸å†å²å›æº¯çš„åŸºçŸ³ã€‚",
      "domain_type": "Infrastructure Domain",
      "importance": 9.0,
      "name": "æŒä¹…åŒ–å­˜å‚¨åŸŸ",
      "sub_modules": [
        {
          "code_paths": [
            "crates/cowork-core/src/storage/mod.rs"
          ],
          "description": "ç®¡ç† .cowork/sessions/<id>/ ç›®å½•ç»“æ„ï¼Œè´Ÿè´£åˆ›å»ºã€å¤åˆ¶ã€åŠ è½½ä¼šè¯ç›®å½•ä¸å…ƒæ•°æ®",
          "importance": 9.0,
          "key_functions": [
            "create_session_dir",
            "load_session_metadata",
            "save_session_metadata",
            "copy_session_state"
          ],
          "name": "ä¼šè¯å­˜å‚¨"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/data/models.rs"
          ],
          "description": "å®šä¹‰æ‰€æœ‰ç»“æ„åŒ–æ•°æ®çš„ Rust ç»“æ„ä½“ï¼ˆå¦‚ Requirementã€Featureã€DesignComponentã€Taskï¼‰ï¼Œæ”¯æŒ Serde åºåˆ—åŒ–",
          "importance": 9.0,
          "key_functions": [
            "Requirement",
            "Feature",
            "DesignComponent",
            "ImplementationTask",
            "SessionMetadata",
            "ChangeRequest"
          ],
          "name": "æ•°æ®æ¨¡å‹"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/data/schemas.rs",
            "crates/cowork-core/src/data/schemas/validation.rs"
          ],
          "description": "å®šä¹‰JSON SchemaéªŒè¯è§„åˆ™ï¼Œç”¨äºéªŒè¯å­˜å‚¨æ•°æ®çš„ç»“æ„å®Œæ•´æ€§ï¼ˆå½“å‰ä¸ºå ä½ç¬¦ï¼‰",
          "importance": 5.0,
          "key_functions": [],
          "name": "æ•°æ®æ¨¡å¼"
        }
      ]
    },
    {
      "code_paths": [
        "crates/cowork-core/src/llm/mod.rs",
        "crates/cowork-core/src/llm/config.rs",
        "crates/cowork-core/src/llm/rate_limiter.rs"
      ],
      "complexity": 6.0,
      "description": "è´Ÿè´£ä¸å¤§è¯­è¨€æ¨¡å‹æœåŠ¡çš„å¯¹æ¥ä¸ä¼˜åŒ–ã€‚è¯¥åŸŸé€šè¿‡é…ç½®ç®¡ç†ä¸é€Ÿç‡é™åˆ¶ä¸­é—´ä»¶ï¼Œç¡®ä¿LLMè°ƒç”¨çš„ç¨³å®šæ€§ä¸åˆè§„æ€§ã€‚å…¶æ ¸å¿ƒä»·å€¼åœ¨äºå±è”½åº•å±‚LLM APIçš„å·®å¼‚ï¼Œæä¾›ç»Ÿä¸€ã€å®‰å…¨ã€å¯æ§çš„æ¨ç†æ¥å£ã€‚",
      "domain_type": "Infrastructure Domain",
      "importance": 7.0,
      "name": "LLMé›†æˆåŸŸ",
      "sub_modules": [
        {
          "code_paths": [
            "crates/cowork-core/src/llm/config.rs"
          ],
          "description": "åŠ è½½å¹¶è§£æé…ç½®æ–‡ä»¶ä¸ç¯å¢ƒå˜é‡ï¼Œåˆ›å»ºOpenAIå®¢æˆ·ç«¯å®ä¾‹ï¼Œæ”¯æŒè‡ªå®šä¹‰APIç«¯ç‚¹ä¸è®¤è¯",
          "importance": 8.0,
          "key_functions": [
            "load_llm_config",
            "create_llm_client"
          ],
          "name": "LLMé…ç½®"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/llm/rate_limiter.rs"
          ],
          "description": "å®ç°å¯¹LLM APIè°ƒç”¨çš„å»¶è¿Ÿæ§åˆ¶ï¼Œé˜²æ­¢è¶…å‡ºé€Ÿç‡é™åˆ¶ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§",
          "importance": 7.0,
          "key_functions": [
            "RateLimiter"
          ],
          "name": "é€Ÿç‡é™åˆ¶"
        }
      ]
    },
    {
      "code_paths": [
        "crates/cowork-core/src/lib.rs",
        "crates/cowork-core/src/instructions/mod.rs",
        "crates/cowork-core/src/tools/mod.rs",
        "crates/cowork-core/src/llm/mod.rs",
        "crates/cowork-core/src/storage/mod.rs",
        "crates/cowork-core/src/data/mod.rs"
      ],
      "complexity": 3.0,
      "description": "ä½œä¸ºRustæ¨¡å—ç³»ç»Ÿçš„ç»„ç»‡å±‚ï¼Œé€šè¿‡ mod.rs æ–‡ä»¶ç»Ÿä¸€æš´éœ²å„å­æ¨¡å—çš„æ¥å£ï¼Œé™ä½å¤–éƒ¨ä¾èµ–çš„å¤æ‚æ€§ã€‚è¯¥åŸŸä¸åŒ…å«ä¸šåŠ¡é€»è¾‘ï¼Œä»…ä½œä¸ºæ¶æ„çš„ç»„ç»‡ä¸å°è£…å±‚ï¼Œæå‡ä»£ç å¯è¯»æ€§ä¸æ¨¡å—åŒ–ç¨‹åº¦ã€‚",
      "domain_type": "Tool Support Domain",
      "importance": 5.0,
      "name": "æ¨¡å—èšåˆåŸŸ",
      "sub_modules": [
        {
          "code_paths": [
            "crates/cowork-core/src/lib.rs"
          ],
          "description": "cowork-core çš„æ ¹æ¨¡å—ï¼Œèšåˆæ‰€æœ‰å­æ¨¡å—ï¼Œä¸ºå¤–éƒ¨æä¾›ç»Ÿä¸€å…¥å£",
          "importance": 6.0,
          "key_functions": [
            "re-exports"
          ],
          "name": "æ ¸å¿ƒåº“èšåˆ"
        },
        {
          "code_paths": [
            "crates/cowork-core/src/instructions/mod.rs",
            "crates/cowork-core/src/tools/mod.rs",
            "crates/cowork-core/src/llm/mod.rs",
            "crates/cowork-core/src/storage/mod.rs",
            "crates/cowork-core/src/data/mod.rs"
          ],
          "description": "å„åŠŸèƒ½åŸŸçš„ mod.rs æ–‡ä»¶ï¼Œç”¨äºèšåˆå†…éƒ¨å­æ¨¡å—ï¼Œæä¾›æ¸…æ™°çš„æ¨¡å—è¾¹ç•Œ",
          "importance": 5.0,
          "key_functions": [
            "re-exports"
          ],
          "name": "å­æ¨¡å—èšåˆ"
        }
      ]
    }
  ],
  "domain_relations": [
    {
      "description": "æµæ°´çº¿ç¼–æ’æ¨¡å—æ ¹æ®æµç¨‹ç±»å‹ï¼Œè°ƒç”¨æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸä¸­å¯¹åº”çš„æŒ‡ä»¤æ¨¡æ¿æ¥åˆå§‹åŒ–æ™ºèƒ½ä½“ï¼Œæ˜¯æµç¨‹é©±åŠ¨çš„æ ¸å¿ƒä¾èµ–",
      "from_domain": "å…¥å£ä¸ç¼–æ’åŸŸ",
      "relation_type": "Service Call",
      "strength": 9.0,
      "to_domain": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ"
    },
    {
      "description": "æµæ°´çº¿ç¼–æ’æ¨¡å—é€šè¿‡æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸçš„æ„å»ºå™¨å‡½æ•°åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹ï¼Œå¹¶å¯åŠ¨å…¶æ‰§è¡Œæµç¨‹",
      "from_domain": "å…¥å£ä¸ç¼–æ’åŸŸ",
      "relation_type": "Service Call",
      "strength": 9.0,
      "to_domain": "æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸ"
    },
    {
      "description": "æ™ºèƒ½ä½“åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡è°ƒç”¨å·¥å…·æ‰§è¡ŒåŸŸä¸­çš„å·¥å…·ï¼ˆTool traitï¼‰æ¥å®Œæˆæ–‡ä»¶è¯»å†™ã€æ•°æ®æ“ä½œã€ç”¨æˆ·äº¤äº’ç­‰åŸå­ä»»åŠ¡",
      "from_domain": "æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸ",
      "relation_type": "Service Call",
      "strength": 9.0,
      "to_domain": "å·¥å…·æ‰§è¡ŒåŸŸ"
    },
    {
      "description": "å·¥å…·æ‰§è¡ŒåŸŸä¸­çš„æ‰€æœ‰æ•°æ®æ“ä½œå·¥å…·ï¼ˆå¦‚data_toolsã€artifact_toolsï¼‰å‡ä¾èµ–æŒä¹…åŒ–å­˜å‚¨åŸŸçš„æ•°æ®æ¨¡å‹ä¸ä¼šè¯å­˜å‚¨ï¼Œç”¨äºåºåˆ—åŒ–ä¸æŒä¹…åŒ–æ•°æ®",
      "from_domain": "å·¥å…·æ‰§è¡ŒåŸŸ",
      "relation_type": "Data Dependency",
      "strength": 8.0,
      "to_domain": "æŒä¹…åŒ–å­˜å‚¨åŸŸ"
    },
    {
      "description": "æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸåœ¨æ„å»ºæ™ºèƒ½ä½“æ—¶ï¼Œä¾èµ–LLMé›†æˆåŸŸæä¾›çš„é…ç½®ä¸é€Ÿç‡é™åˆ¶LLMå®¢æˆ·ç«¯",
      "from_domain": "æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸ",
      "relation_type": "Service Call",
      "strength": 8.0,
      "to_domain": "LLMé›†æˆåŸŸ"
    },
    {
      "description": "LLMé…ç½®æ¨¡å—åŠ è½½çš„é…ç½®æ–‡ä»¶ï¼ˆconfig.tomlï¼‰å­˜å‚¨äºé¡¹ç›®æ ¹ç›®å½•ï¼Œä¸ä¼šè¯å­˜å‚¨å…±äº«æ–‡ä»¶ç³»ç»Ÿä¸Šä¸‹æ–‡",
      "from_domain": "LLMé›†æˆåŸŸ",
      "relation_type": "Data Dependency",
      "strength": 6.0,
      "to_domain": "æŒä¹…åŒ–å­˜å‚¨åŸŸ"
    },
    {
      "description": "å…¥å£æ¨¡å—åœ¨å¯åŠ¨æµç¨‹å‰ï¼Œéœ€ä¾èµ–æŒä¹…åŒ–å­˜å‚¨åŸŸåˆ›å»ºæˆ–åŠ è½½ä¼šè¯ç›®å½•ï¼Œä»¥ç¡®ä¿ä¸Šä¸‹æ–‡éš”ç¦»",
      "from_domain": "å…¥å£ä¸ç¼–æ’åŸŸ",
      "relation_type": "Data Dependency",
      "strength": 7.0,
      "to_domain": "æŒä¹…åŒ–å­˜å‚¨åŸŸ"
    },
    {
      "description": "å·¥å…·æ‰§è¡ŒåŸŸé€šè¿‡æ¨¡å—èšåˆåŸŸçš„mod.rsæ–‡ä»¶å¯¹å¤–æš´éœ²å·¥å…·æ¥å£ï¼Œä¾¿äºè¢«å…¶ä»–åŸŸè°ƒç”¨",
      "from_domain": "å·¥å…·æ‰§è¡ŒåŸŸ",
      "relation_type": "Tool Support",
      "strength": 6.0,
      "to_domain": "æ¨¡å—èšåˆåŸŸ"
    },
    {
      "description": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸé€šè¿‡æ¨¡å—èšåˆåŸŸçš„mod.rsæ–‡ä»¶ç»Ÿä¸€æš´éœ²æŒ‡ä»¤æ¨¡æ¿ï¼Œä¾›æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸå¯¼å…¥",
      "from_domain": "æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ",
      "relation_type": "Tool Support",
      "strength": 6.0,
      "to_domain": "æ¨¡å—èšåˆåŸŸ"
    }
  ]
}
```

### Workflow Research Report
Contains static analysis results of the codebase and business process analysis.

```json
{
  "main_workflow": {
    "description": "ä»ç”¨æˆ·è¾“å…¥åˆå§‹æƒ³æ³•å¼€å§‹ï¼Œä¾æ¬¡è§¦å‘Ideaã€PRDã€Designã€Planã€Codingã€Checkã€Deliveryä¸ƒä¸ªæ™ºèƒ½ä½“é˜¶æ®µï¼Œå®Œæˆä»éœ€æ±‚æ„æ€åˆ°äº¤ä»˜æŠ¥å‘Šçš„å®Œæ•´å¼€å‘é—­ç¯ã€‚æ¯ä¸ªé˜¶æ®µå‡åŒ…å«æ™ºèƒ½ä½“æ‰§è¡Œä¸HITLå®¡æ ¸ï¼Œç¡®ä¿è¾“å‡ºç¬¦åˆç®€æ´æ€§åŸåˆ™ã€‚æµç¨‹ç»“æŸæ—¶ç”Ÿæˆå®Œæ•´çš„äº¤ä»˜æ–‡æ¡£ä¸ä»£ç åŒ…ã€‚",
    "flowchart_mermaid": "graph TD\n    A[ç”¨æˆ·æ‰§è¡Œcowork-cli createå‘½ä»¤] --> B[è§£æCLIå‚æ•°å¹¶åˆå§‹åŒ–ä¼šè¯]\n    B --> C[IdeaAgentæ•è·å¹¶ç»“æ„åŒ–ç”¨æˆ·æƒ³æ³•]\n    C --> D[PRD Actor-Criticå¾ªç¯ç”Ÿæˆéœ€æ±‚æ–‡æ¡£]\n    D --> E[Design Actor-Criticå¾ªç¯ç”Ÿæˆæ¶æ„è®¾è®¡]\n    E --> F[Plan Actor-Criticå¾ªç¯ç”Ÿæˆä»»åŠ¡æ¸…å•]\n    F --> G[Coding Actor-Criticå¾ªç¯å®ç°ä»£ç ]\n    G --> H[æ–‡ä»¶å·¥å…·è¯»å†™ä»£ç æ–‡ä»¶]\n    H --> I[CheckAgentéªŒè¯ä»£ç ç»“æ„å®Œæ•´æ€§]\n    I --> J[DeliveryAgentç”Ÿæˆäº¤ä»˜æŠ¥å‘Š]\n    J --> K[ä¿å­˜äº¤ä»˜äº§ç‰©è‡³ä¼šè¯ç›®å½•]\n    \n    C --> C1{HITLå®¡æ ¸}\n    D --> D1{HITLå®¡æ ¸}\n    E --> E1{HITLå®¡æ ¸}\n    F --> F1{HITLå®¡æ ¸}\n    G --> G1{HITLå®¡æ ¸}\n    \n    C1 -->|é€šè¿‡| D\n    D1 -->|é€šè¿‡| E\n    E1 -->|é€šè¿‡| F\n    F1 -->|é€šè¿‡| G\n    G1 -->|é€šè¿‡| I\n    \n    C1 -->|éœ€ä¿®æ”¹| C\n    D1 -->|éœ€ä¿®æ”¹| D\n    E1 -->|éœ€ä¿®æ”¹| E\n    F1 -->|éœ€ä¿®æ”¹| F\n    G1 -->|éœ€ä¿®æ”¹| G",
    "name": "å…¨æ–°é¡¹ç›®åˆ›å»ºæµç¨‹"
  },
  "other_important_workflows": [
    {
      "description": "åœ¨å·²æœ‰é¡¹ç›®åŸºç¡€ä¸Šï¼Œæ ¹æ®ç”¨æˆ·å˜æ›´è¯·æ±‚ï¼ˆChangeRequestï¼‰è§¦å‘ä¿®æ”¹æµç¨‹ã€‚ç³»ç»Ÿå…ˆé€šè¿‡Modify Triage Agentåˆ†æå˜æ›´èŒƒå›´ï¼Œå†å†³å®šæ˜¯å¦éœ€è¦å›é€€è‡³PRDã€Designã€Planæˆ–ç›´æ¥è¿›å…¥Codingé˜¶æ®µè¿›è¡Œä»£ç ä¿®è¡¥ï¼Œæœ€ç»ˆç”±Modify Delivery Agentç”Ÿæˆå˜æ›´æŠ¥å‘Šã€‚æµç¨‹æ”¯æŒä»»æ„é˜¶æ®µçš„å›æº¯ä¸é‡å¯åŠ¨ã€‚",
      "flowchart_mermaid": "graph TD\n    A[ç”¨æˆ·æ‰§è¡Œcowork-cli modifyå‘½ä»¤] --> B[åŠ è½½å½“å‰ä¼šè¯çŠ¶æ€ä¸å†å²æ•°æ®]\n    B --> C[Modify Triage Agentåˆ†æå˜æ›´èŒƒå›´]\n    C --> D{å˜æ›´å½±å“åˆ†æ}\n    D -->|å½±å“PRD| E[å›é€€è‡³PRDé˜¶æ®µé‡æ–°ç”Ÿæˆéœ€æ±‚]\n    D -->|å½±å“Design| F[å›é€€è‡³Designé˜¶æ®µé‡æ–°è®¾è®¡]\n    D -->|å½±å“Plan| G[å›é€€è‡³Plané˜¶æ®µé‡æ–°è§„åˆ’]\n    D -->|ä»…å½±å“ä»£ç | H[ç›´æ¥è¿›å…¥ä»£ç ä¿®è¡¥é˜¶æ®µ]\n    \n    E --> I[æ‰§è¡ŒPRDåˆ°Deliveryå®Œæ•´æµç¨‹]\n    F --> J[æ‰§è¡ŒDesignåˆ°Deliveryå®Œæ•´æµç¨‹]\n    G --> K[æ‰§è¡ŒPlanåˆ°Deliveryå®Œæ•´æµç¨‹]\n    H --> L[Coding Agentæ‰§è¡Œä»£ç ä¿®è¡¥]\n    \n    I --> M[Modify Delivery Agentç”Ÿæˆå˜æ›´æŠ¥å‘Š]\n    J --> M\n    K --> M\n    L --> M\n    \n    M --> N[ä¿å­˜å˜æ›´æŠ¥å‘Šè‡³ä¼šè¯ç›®å½•]",
      "name": "å¢é‡ä¿®æ”¹æµç¨‹"
    },
    {
      "description": "å…è®¸ç”¨æˆ·åœ¨ä»»æ„å¼€å‘é˜¶æ®µä¸­æ–­åï¼Œä»æŒ‡å®šèŠ‚ç‚¹ï¼ˆå¦‚PRDã€Designã€Planï¼‰é‡æ–°å¼€å§‹ï¼Œè·³è¿‡å·²å®Œæˆé˜¶æ®µã€‚ç³»ç»Ÿé€šè¿‡åŠ è½½å†å²ä¼šè¯æ•°æ®æ¢å¤ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æµç¨‹è¿ç»­æ€§ã€‚è¯¥æµç¨‹æ˜¯æ”¯æŒå¢é‡ä¿®æ”¹ä¸æ•æ·è¿­ä»£çš„æ ¸å¿ƒæ”¯æ’‘æœºåˆ¶ã€‚",
      "flowchart_mermaid": "graph TD\n    A[ç”¨æˆ·æ‰§è¡Œcowork-cli resumeå‘½ä»¤] --> B[è§£æç›®æ ‡é˜¶æ®µå‚æ•°]\n    B --> C[éªŒè¯é˜¶æ®µæœ‰æ•ˆæ€§]\n    C --> D[åŠ è½½ä¼šè¯å…ƒæ•°æ®ä¸ä¸­é—´äº§ç‰©]\n    D --> E[æ„å»ºä»æŒ‡å®šé˜¶æ®µå¼€å§‹çš„å­æµç¨‹]\n    E --> F[å¯åŠ¨ç›®æ ‡é˜¶æ®µåŠåç»­æ™ºèƒ½ä½“æµæ°´çº¿]\n    F --> G[æŒç»­æ›´æ–°çŠ¶æ€ä¸æ–‡ä»¶]\n    G --> H[æ›´æ–°ä¼šè¯å…ƒæ•°æ®æ ‡è®°æ‰§è¡Œé˜¶æ®µ]",
      "name": "é˜¶æ®µæ¢å¤æµç¨‹"
    },
    {
      "description": "åœ¨æ™ºèƒ½ä½“æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå½“é‡åˆ°ä¸ç¡®å®šæ€§ã€é”™è¯¯æˆ–éœ€è¦å†³ç­–æ—¶ï¼Œç³»ç»Ÿé€šè¿‡HITLå·¥å…·ä¸»åŠ¨è¯·æ±‚ç”¨æˆ·ä»‹å…¥ã€‚æ”¯æŒå†…å®¹ç¼–è¾‘ã€æ–‡ä»¶å®¡æŸ¥ã€æä¾›åé¦ˆã€è¯·æ±‚é‡è§„åˆ’ç­‰å¤šç§äº¤äº’æ–¹å¼ï¼Œç¡®ä¿å¼€å‘è¿‡ç¨‹å¯æ§ä¸”ç¬¦åˆç”¨æˆ·æ„å›¾ã€‚",
      "flowchart_mermaid": "graph TD\n    A[æ™ºèƒ½ä½“æ£€æµ‹åˆ°é”™è¯¯æˆ–éœ€å†³ç­–] --> B[è°ƒç”¨ResilientAgentåŒ…è£…å™¨]\n    B --> C[è°ƒç”¨HITLäº¤äº’å·¥å…·è¯·æ±‚ç”¨æˆ·ä»‹å…¥]\n    C --> D{ç”¨æˆ·é€‰æ‹©æ“ä½œ}\n    D -->|ç¼–è¾‘å†…å®¹| E[ReviewAndEditContentTool]\n    D -->|æä¾›åé¦ˆ| F[ProvideFeedbackTool]\n    D -->|è¯·æ±‚é‡è§„åˆ’| G[RequestReplanningTool]\n    \n    E --> H[æ”¶é›†ç”¨æˆ·è¾“å…¥å¹¶æŒä¹…åŒ–]\n    F --> H\n    G --> H\n    \n    H --> I{ResilientAgentå†³ç­–}\n    I -->|é‡è¯•| J[é‡ç½®è®¡æ•°å™¨å¹¶é‡è¯•æ™ºèƒ½ä½“]\n    I -->|ç»§ç»­| K[ç»§ç»­æ‰§è¡Œåç»­æµç¨‹]\n    I -->|ä¸­æ­¢| L[ä¸­æ­¢å½“å‰æµç¨‹]\n    \n    J --> B\n    K --> M[æµç¨‹ç»§ç»­]\n    L --> N[æµç¨‹ç»ˆæ­¢]",
      "name": "äººæœºäº¤äº’åé¦ˆæµç¨‹"
    }
  ]
}
```

### Code Insights Data
Code analysis results from preprocessing phase, including definitions of functions, classes, and modules.

```json
[
  {
    "code_dossier": {
      "code_purpose": "entry",
      "description": "Cowork Forge CLI entry point - AI-powered software development system orchestrator",
      "file_path": "crates/cowork-cli/src/main.rs",
      "functions": [
        "main",
        "load_config",
        "cmd_new",
        "cmd_resume",
        "cmd_revert",
        "cmd_modify",
        "collect_project_file_fingerprints",
        "diff_project_files",
        "should_ignore_project_path",
        "execute_pipeline",
        "cmd_status",
        "cmd_init"
      ],
      "importance_score": 1.0,
      "interfaces": [
        "Cli",
        "Commands",
        "execute_pipeline"
      ],
      "name": "main.rs",
      "source_summary": "// Cowork Forge - CLI Entry Point\n\nuse anyhow::Result;\nuse clap::{Parser, Subcommand};\nuse cowork_core::llm::ModelConfig;\nuse cowork_core::pipeline::{create_cowork_pipeline, create_partial_pipeline, create_resume_pipeline, create_modify_pipeline};\nuse cowork_core::storage::is_project_initialized;\nuse std::path::Path;\nuse std::sync::Arc;\nuse std::collections::{HashMap, HashSet};\nuse walkdir::WalkDir;\nuse tracing::{info, error};\nuse adk_runner::{Runner, RunnerConfig};\nuse adk_session::InMemorySessionService;\nuse adk_core::Content;\nuse futures::StreamExt;\n\n#[derive(Parser)]\n#[command(name = \"cowork\")]\n#[command(about = \"AI-powered software development system\", long_about = None)]\nstruct Cli {\n    #[command(subcommand)]\n    command: Commands,\n\n    /// Path to config file (default: config.toml)\n    #[arg(short, long, global = true)]\n    config: Option<String>,\n\n    /// Enable verbose logging\n    #[arg(short, long, global = true)]\n    verbose: bool,\n\n    /// Enable LLM streaming output (shows AI thinking process in real-time)\n    #[arg(short, long, global = true)]\n    stream: bool,\n}\n\n#[derive(Subcommand)]\nenum Commands {\n    /// Start a new project\n    New {\n        /// Project idea/description\n        idea: String,\n    },\n\n    /// Resume an existing project\n    Resume {\n        /// Resume from a specific session ID (optional).\n        /// If omitted, defaults to latest successful session; if none, tries latest in-progress session.\n        #[arg(short, long)]\n        base: Option<String>,\n    },\n\n    /// Revert project and restart from a specific stage\n    Revert {\n        /// Stage to restart from (prd, design, plan, coding, check, delivery)\n        #[arg(short, long)]\n        from: String,\n    },\n\n    /// Modify existing project with incremental changes\n    Modify {\n        /// Change idea/description\n        idea: String,\n        /// Base session ID (defaults to latest successful session)\n        #[arg(short, long)]\n        base: Option<String>,\n    },\n\n    /// Show project status\n    Status {\n        /// Show all sessions\n        #[arg(short, long)]\n        sessions: bool,\n    },\n\n    /// Initialize config file\n    Init,\n}\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    let cli = Cli::parse();\n\n    // Setup logging - output to stderr, not stdout\n    let log_filter = if cli.verbose {\n        // Verbose mode: show all logs including adk internals\n        \"debug\".to_string()\n    } else {\n        // Normal mode: filter out adk verbose logs to avoid clutter\n        \"info,adk_agent=warn,adk_core=warn,adk_runner=warn\".to_string()\n    };\n    \n    tracing_subscriber::fmt()\n        .with_writer(std::io::stderr) // Force logs to stderr\n        .with_env_filter(log_filter)\n        .init();\n\n    // Load configuration\n    let config_path = cli.config.unwrap_or_else(|| \"config.toml\".to_string());\n    let config = load_config(&config_path)?;\n\n    // Execute command\n    let enable_stream = cli.stream;\n    match cli.command {\n        Commands::New { idea } => cmd_new(idea, &config, enable_stream).await?,\n        Commands::Resume { base } => cmd_resume(base, &config, enable_stream).await?,\n        Commands::Revert { from } => cmd_revert(&from, &config, enable_stream).await?,\n        Commands::Modify { idea, base } => cmd_modify(&idea, base, &config, enable_stream).await?,\n        Commands::Status { sessions } => cmd_status(sessions).await?,\n        Commands::Init => cmd_init()?,\n    }\n\n    Ok(())\n}\n\n/// Load configuration from file or environment\nfn load_config(path: &str) -> Result<ModelConfig> {\n    if Path::new(path).exists() {\n        info!(\"Loading configuration from {}\", path);\n        ModelConfig::from_file(path)\n    } else {\n        info!(\"Config file not found, attempting to load from environment variables\");\n        ModelConfig::from_env()\n    }\n}\n\n/// Start a new project\nasync fn cmd_new(idea: String, config: &ModelConfig, enable_stream: bool) -> Result<()> {\n    use cowork_core::storage::*;\n    use cowork_core::data::*;\n    \n    info!(\"Starting new project with idea: {}\", idea);\n\n    if is_project_initialized() {\n        error!(\".cowork directory already initialized. Use 'resume' or 'modify' instead.\");\n        anyhow::bail!(\"Project already initialized\");\n    }\n\n    // Initialize project index\n    let project_name = idea.split_whitespace().take(3).collect::<Vec<_>>().join(\"_\");\n    let mut index = init_project_index(project_name)?;\n    \n    // Generate session ID\n    let session_id = format!(\"session-{}\", chrono::Utc::now().timestamp());\n    \n    // Create session record\n    let session_record = SessionRecord {\n        session_id: session_id.clone(),\n        session_type: SessionType::New,\n        created_at: chrono::Utc::now(),\n        completed_at: None,\n        status: SessionStatus::InProgress,\n        base_session_id: None,\n        input_description: idea.clone(),\n        change_request_id: None,\n    };\n    \n    index.add_session(session_record);\n    save_project_index(&index)?;\n    \n    // Save session input\n    let session_input = SessionInput {\n        session_id: session_id.clone(),\n        session_type: SessionType::New,\n        description: idea.clone(),\n        base_session_id: None,\n        created_at: chrono::Utc::now(),\n    };\n    save_session_input(&session_id, &session_input)?;\n\n    // Create pipeline\n    let pipeline = create_cowork_pipeline(config, &session_id)?;\n\n    // Execute pipeline with idea as input\n    println!(\"âœ¨ Creating new project...\");\n    println!(\"Session ID: {}\", session_id);\n    println!(\"Idea: {}\", idea);\n    println!();\n\n    let result = execute_pipeline(pipeline, &idea, enable_stream).await;\n\n    // Mark session status based on result\n    match result {\n        Ok(_) => {\n            mark_session_completed(&session_id)?;\n            println!(\"\\nâœ… Project creation complete!\");\n            println!(\"Session ID: {}\", session_id);\n            println!(\"Check .cowork/sessions/{}/artifacts/ for outputs\", session_id);\n        }\n        Err(e) => {\n            mark_session_failed(&session_id)?;\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\n/// Resume an existing project\nasync fn cmd_resume(base: Option<String>, config: &ModelConfig, enable_stream: bool) -> Result<()> {\n    use cowork_core::storage::*;\n    \n    info!(\"Resuming project\");\n\n    if !is_project_initialized() {\n        error!(\".cowork directory not found. Use 'new' to create a project.\");\n        anyhow::bail!(\"No project found\");\n    }\n\n    // Determine base session\n    let base_session_id = if let Some(base_id) = base {\n        base_id\n    } else if let Some(latest_ok) = get_latest_successful_session()? {\n        latest_ok\n    } else {\n        // Fallback: try latest in-progress session (useful when previous run was interrupted)\n        let index = load_project_index()?;\n        let last_in_progress = index\n            .sessions\n            .iter()\n            .rev()\n            .find(|s| s.status == cowork_core::data::SessionStatus::InProgress)\n            .map(|s| s.session_id.clone());\n\n        if let Some(sid) = last_in_progress {\n            sid\n        } else {\n            error!(\"No successful session found. Cannot resume.\");\n            anyhow::bail!(\"No session to resume from\");\n        }\n    };\n\n    info!(\"Resuming from session: {}\", base_session_id);\n\n    // Create new session for resume\n    let session_id = format!(\"session-{}\", chrono::Utc::now().timestamp());\n    \n    let mut index = load_project_index()?;\n    let session_record = cowork_core::data::SessionRecord {\n        session_id: session_id.clone(),\n        session_type: cowork_core::data::SessionType::New, // Resume is treated as continuation\n        created_at: chrono::Utc::now(),\n        completed_at: None,\n        status: cowork_core::data::SessionStatus::InProgress,\n        base_session_id: Some(base_session_id.clone()),\n        input_description: \"Resume from last checkpoint\".to_string(),\n        change_request_id: None,\n    };\n    index.add_session(session_record);\n    save_project_index(&index)?;\n    \n    // Save session input\n    let session_input = SessionInput {\n        session_id: session_id.clone(),\n        session_type: cowork_core::data::SessionType::New, // Resume is treated as continuation\n        description: \"Resume from last checkpoint\".to_string(),\n        base_session_id: Some(base_session_id.clone()),\n        created_at: chrono::Utc::now(),\n    };\n    save_session_input(&session_id, &session_input)?;\n\n    // Bootstrap session state from base session\n    init_session_from_base(&session_id, &base_session_id)?;\n\n    // Create resume pipeline\n    let pipeline = create_resume_pipeline(config, &session_id, &base_session_id)?;\n\n    // Execute pipeline\n    println!(\"ğŸ”„ Resuming project...\");\n    println!(\"Base session: {}\", base_session_id);\n    println!(\"New session: {}\", session_id);\n    println!();\n\n    let result = execute_pipeline(pipeline, \"Resume from last checkpoint\", enable_stream).await;\n\n    match result {\n        Ok(_) => {\n            mark_session_completed(&session_id)?;\n            println!(\"\\nâœ… Project resume complete!\");\n        }\n        Err(e) => {\n            mark_session_failed(&session_id)?;\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\n/// Revert project and restart from a specific stage\nasync fn cmd_revert(from_stage: &str, config: &ModelConfig, enable_stream: bool) -> Result<()> {\n    use cowork_core::storage::*;    info!(\"Reverting project from stage: {}\", from_stage);\n\n    if !is_project_initialized() {\n        error!(\".cowork directory not found. Use 'new' to create a project.\");\n        anyhow::bail!(\"No project found\");\n    }\n\n    let latest_session = get_latest_successful_session()?;\n    if latest_session.is_none() {\n        error!(\"No successful session found. Cannot revert.\");\n        anyhow::bail!(\"No session to revert from\");\n    }\n    \n    let base_session_id = latest_session.unwrap();\n\n    // Support `--from auto`: use the latest session meta's requested restart stage (if any)\n    let resolved_stage = if from_stage == \"auto\" {\n        let index = load_project_index()?;\n        let last_session_id = index\n            .sessions\n            .last()\n            .map(|s| s.session_id.clone())\n            .ok_or_else(|| anyhow::anyhow!(\"No session records found\"))?;\n\n        if let Some(meta) = load_session_meta(&last_session_id)? {\n            if let Some(stage) = meta.current_stage {\n                match stage {\n                    cowork_core::data::Stage::Prd => \"prd\",\n                    cowork_core::data::Stage::Design => \"design\",\n                    cowork_core::data::Stage::Plan => \"plan\",\n                    cowork_core::data::Stage::Coding => \"coding\",\n                    cowork_core::data::Stage::Check => \"check\",\n                    cowork_core::data::Stage::Delivery => \"delivery\",\n                    cowork_core::data::Stage::Idea => \"prd\",\n                }\n            } else {\n                \"prd\"\n            }\n        } else {\n            \"prd\"\n        }\n    } else {\n        from_stage\n    };\n\n    // Create new session for revert\n    let session_id = format!(\"session-{}\", chrono::Utc::now().timestamp());\n    \n    let mut index = load_project_index()?;\n    let session_record = cowork_core::data::SessionRecord {\n        session_id: session_id.clone(),\n        session_type: cowork_core::data::SessionType::Revert,\n        created_at: chrono::Utc::now(),\n        completed_at: None,\n        status: cowork_core::data::SessionStatus::InProgress,\n        base_session_id: Some(base_session_id.clone()),\n        input_description: format!(\"Revert from {} stage\", resolved_stage),\n        change_request_id: None,\n    };\n    index.add_session(session_record);\n    save_project_index(&index)?;\n    \n    // Save session input\n    let session_input = SessionInput {\n        session_id: session_id.clone(),\n        session_type: cowork_core::data::SessionType::Revert,\n        description: format!(\"Revert from {} stage\", resolved_stage),\n        base_session_id: Some(base_session_id.clone()),\n        created_at: chrono::Utc::now(),\n    };\n    save_session_input(&session_id, &session_input)?;\n\n    // Bootstrap session state from base session\n    init_session_from_base(&session_id, &base_session_id)?;\n\n    // Create partial pipeline\n    let pipeline = create_partial_pipeline(config, &session_id, &base_session_id, resolved_stage)?;\n\n    // Execute pipeline\n    println!(\"ğŸ”§ Reverting project from {} stage...\", resolved_stage);\n    println!(\"Base session: {}\", base_session_id);\n    println!(\"New session: {}\", session_id);\n    println!();\n\n    let result = execute_pipeline(pipeline, &format!(\"Revert from {} stage\", resolved_stage), enable_stream).await;\n\n    match result {\n        Ok(_) => {\n            mark_session_completed(&session_id)?;\n            println!(\"\\nâœ… Revert complete!\");\n        }\n        Err(e) => {\n            mark_session_failed(&session_id)?;\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\nfn should_ignore_project_path(path: &str) -> bool {\n    // Ignore cowork internal state and common build artifacts\n    let ignore_patterns = [\n        \"./.cowork/\",\n        \"./target/\",\n        \"./node_modules/\",\n        \"./.git/\",\n        \"./dist/\",\n        \"./build/\",\n        \"./.vscode/\",\n        \"./.idea/\",\n    ];\n    ignore_patterns.iter().any(|p| path.contains(p))\n}\n\nfn collect_project_file_fingerprints() -> Result<HashMap<String, (u64, u64)>> {\n    // path -> (len, mtime_secs)\n    let mut map = HashMap::new();\n\n    for entry in WalkDir::new(\".\").follow_links(false) {\n        let entry = entry?;\n        if !entry.file_type().is_file() {\n            continue;\n        }\n        let p = entry.path();\n        let rel = p.strip_prefix(\".\").unwrap_or(p).to_string_lossy();\n        let rel = format!(\"./{}\", rel.trim_start_matches(\"/\"));\n\n        if should_ignore_project_path(&rel) {\n            continue;\n        }\n\n        let md = entry.metadata()?;\n        let len = md.len();\n        let mtime = md\n            .modified()\n            .ok()\n            .and_then(|t| t.duration_since(std::time::UNIX_EPOCH).ok())\n            .map(|d| d.as_secs())\n            .unwrap_or(0);\n\n        map.insert(rel, (len, mtime));\n    }\n\n    Ok(map)\n}\n\nfn diff_project_files(\n    before: &HashMap<String, (u64, u64)>,\n    after: &HashMap<String, (u64, u64)>,\n) -> (Vec<String>, Vec<String>, Vec<String>) {\n    let before_keys: HashSet<&String> = before.keys().collect();\n    let after_keys: HashSet<&String> = after.keys().collect();\n\n    let mut added = Vec::new();\n    let mut deleted = Vec::new();\n    let mut modified = Vec::new();\n\n    for k in after_keys.difference(&before_keys) {\n        added.push((**k).clone());\n    }\n\n    for k in before_keys.difference(&after_keys) {\n        deleted.push((**k).clone());\n    }\n\n    for k in before_keys.intersection(&after_keys) {\n        let b = before.get(*k);\n        let a = after.get(*k);\n        if b != a {\n            modified.push((**k).clone());\n        }\n    }\n\n    added.sort();\n    deleted.sort();\n    modified.sort();\n\n    (added, modified, deleted)\n}\n\n/// Modify existing project with incremental changes\nasync fn cmd_modify(idea: &str, base: Option<String>, config: &ModelConfig, enable_stream: bool) -> Result<()> {\n    use cowork_core::storage::*;\n    use cowork_core::data::*;\n    \n    info!(\"Modifying project with idea: {}\", idea);\n\n    if !is_project_initialized() {\n        error!(\".cowork directory not found. Use 'new' to create a project.\");\n        anyhow::bail!(\"No project found\");\n    }\n\n    // Determine base session\n    let base_session_id = if let Some(base_id) = base {\n        base_id\n    } else {\n        get_latest_successful_session()?\n            .ok_or_else(|| anyhow::anyhow!(\"No successful session found. Cannot modify without a base.\"))?\n    };\n    \n    info!(\"Using base session: {}\", base_session_id);\n\n    // Create new session for modify\n    let session_id = format!(\"session-{}\", chrono::Utc::now().timestamp());\n    \n    // Create change request\n    let change_request = ChangeRequest::new(\n        session_id.clone(),\n        idea.to_string(),\n        base_session_id.clone(),\n    );\n    let change_request_id = change_request.id.clone();\n    save_change_request(&session_id, &change_request)?;\n    \n    // Create session record\n    let mut index = load_project_index()?;\n    let session_record = SessionRecord {\n        session_id: session_id.clone(),\n        session_type: SessionType::Modify,\n        created_at: chrono::Utc::now(),\n        completed_at: None,\n        status: SessionStatus::InProgress,\n        base_session_id: Some(base_session_id.clone()),\n        input_description: idea.to_string(),\n        change_request_id: Some(change_request_id.clone()),\n    };\n    index.add_session(session_record);\n    save_project_index(&index)?;\n    \n    // Save session input\n    let session_input = SessionInput {\n        session_id: session_id.clone(),\n        session_type: SessionType::Modify,\n        description: idea.to_string(),\n        base_session_id: Some(base_session_id.clone()),\n        created_at: chrono::Utc::now(),\n    };\n    save_session_input(&session_id, &session_input)?;\n\n    // Bootstrap session state from base session\n    init_session_from_base(&session_id, &base_session_id)?;\n\n    // Create modify pipeline (incremental change pipeline)\n    let pipeline = create_modify_pipeline(config, &session_id, &base_session_id)?;\n\n    // Snapshot project files before modification (for patch metadata)\n    let before_files = collect_project_file_fingerprints()?;\n\n    // Execute pipeline\n    println!(\"ğŸ”„ Applying incremental changes...\");\n    println!(\"Change: {}\", idea);\n    println!(\"Base session: {}\", base_session_id);\n    println!(\"New session: {}\", session_id);\n    println!();\n\n    let result = execute_pipeline(pipeline, idea, enable_stream).await;\n\n    match result {\n        Ok(_) => {\n            // Snapshot after modification and persist patch metadata\n            let after_files = collect_project_file_fingerprints()?;\n            let (added_files, modified_files, deleted_files) = diff_project_files(&before_files, &after_files);\n\n            let mut patch = PatchMetadata::new(session_id.clone(), base_session_id.clone());\n            patch.added_files = added_files;\n            patch.modified_files = modified_files;\n            patch.deleted_files = deleted_files;\n            save_patch_metadata(&session_id, &patch)?;\n\n            mark_session_completed(&session_id)?;\n            println!(\"\\nâœ… Modification complete!\");\n            println!(\"Session ID: {}\", session_id);\n            println!(\"Patch metadata: .cowork/sessions/{}/patch/metadata.json\", session_id);\n        }\n        Err(e) => {\n            mark_session_failed(&session_id)?;\n            return Err(e);\n        }\n    }\n\n    Ok(())\n}\n\n/// Execute a pipeline with given input\nasync fn execute_pipeline(pipeline: Arc<dyn adk_core::Agent>, input: &str, enable_stream: bool) -> Result<()> {\n    use adk_core::RunConfig;\n    use adk_session::{CreateRequest, SessionService};\n    use std::collections::HashMap;\n\n    // Create session service\n    let session_service = Arc::new(InMemorySessionService::new());\n\n    // Create session FIRST\n    let user_id = \"cowork-user\".to_string();\n    let app_name = \"cowork-forge\".to_string();\n    \n    let session = session_service\n        .create(CreateRequest {\n            app_name: app_name.clone(),\n            user_id: user_id.clone(),\n            session_id: None, // Auto-generate session ID\n            state: HashMap::new(),\n        })\n        .await\n        .map_err(|e| anyhow::anyhow!(\"Failed to create session: {}\", e))?;\n    \n    let session_id = session.id().to_string();\n\n    // Create runner with run config\n    let runner = Runner::new(RunnerConfig {\n        app_name,\n        agent: pipeline,\n        session_service,\n        artifact_service: None,\n        memory_service: None,\n        run_config: Some(RunConfig::default()),\n    })?;\n\n    // Execute\n    let content = Content::new(\"user\").with_text(input);\n\n    let mut event_stream = runner.run(user_id, session_id, content).await?;\n\n    // Simple phase indicator - show when we start processing\n    println!(\"ğŸš€ Starting execution...\\n\");\n    \n    // Optional: Show streaming mode status\n    if enable_stream {\n        println!(\"ğŸ’¬ Streaming mode enabled - showing LLM output in real-time\\n\");\n    }\n    \n    while let Some(event_result) = event_stream.next().await {\n        match event_result {\n            Ok(event) => {\n                // If streaming is enabled, show LLM output\n                if enable_stream {\n                    if let Some(llm_content) = &event.llm_response.content {\n                        use std::io::Write;\n                        let mut stdout = std::io::stdout();\n                        \n                        for part in &llm_content.parts {\n                            if let Some(text) = part.text() {\n                                // Filter out standalone newlines to reduce erratic line breaks\n                                if text != \"\\n\" {\n                                    print!(\"{}\", text);\n                                    stdout.flush().ok();\n                                }\n                            }\n                        }\n                    }\n                }\n                // Tools will always print their own progress (e.g., \"ğŸ“ Writing file: ...\")\n            }\n            Err(e) => {\n                error!(\"Error during pipeline execution: {}\", e);\n                anyhow::bail!(\"Pipeline execution failed: {}\", e);\n            }\n        }\n    }\n\n    println!(\"\\nâœ… Pipeline complete!\");\n\n    Ok(())\n}\n\n/// Show project status\nasync fn cmd_status(show_sessions: bool) -> Result<()> {\n    use cowork_core::storage::*;\n    use cowork_core::data::*;\n\n    if !is_project_initialized() {\n        println!(\"âŒ No project found in current directory\");\n        return Ok(());\n    }\n\n    let index = load_project_index()?;\n    \n    println!(\"ğŸ“Š Project Status\\n\");\n    println!(\"Project: {}\", index.project_name);\n    println!(\"Created: {}\", index.created_at.format(\"%Y-%m-%d %H:%M:%S\"));\n    println!();\n\n    if show_sessions {\n        // Show all sessions\n        println!(\"Sessions ({} total):\", index.sessions.len());\n        println!(\"{:<20} {:<10} {:<15} {:<25}\", \"Session ID\", \"Type\", \"Status\", \"Created At\");\n        println!(\"{:-<70}\", \"\");\n        \n        for session in &index.sessions {\n            let session_type = match session.session_type {\n                SessionType::New => \"New\",\n                SessionType::Modify => \"Modify\",\n                SessionType::Revert => \"Revert\",\n            };\n            let status = match session.status {\n                SessionStatus::InProgress => \"In Progress\",\n                SessionStatus::Completed => \"Completed\",\n                SessionStatus::Failed => \"Failed\",\n            };\n            println!(\n                \"{:<20} {:<10} {:<15} {}\",\n                session.session_id,\n                session_type,\n                status,\n                session.created_at.format(\"%Y-%m-%d %H:%M:%S\")\n            );\n        }\n        println!();\n        \n        if let Some(latest) = &index.latest_successful_session {\n            println!(\"Latest successful: {}\", latest);\n        }\n    } else {\n        // Show summary of latest session\n        if let Some(latest_id) = &index.latest_successful_session {\n            println!(\"Latest successful session: {}\", latest_id);\n            \n            // Try to load artifacts from latest session\n            match load_requirements(latest_id) {\n                Ok(reqs) => {\n                    println!(\"Requirements: {} total\", reqs.requirements.len());\n                }\n                Err(_) => println!(\"Requirements: Not yet created\"),\n            }\n\n            match load_feature_list(latest_id) {\n                Ok(features) => {\n                    let completed = features.features.iter().filter(|f| matches!(f.status, FeatureStatus::Completed)).count();\n                    println!(\"Features: {}/{} completed\", completed, features.features.len());\n                }\n                Err(_) => println!(\"Features: Not yet created\"),\n            }\n\n            match load_design_spec(latest_id) {\n                Ok(design) => {\n                    println!(\"Components: {} defined\", design.architecture.components.len());\n                }\n                Err(_) => println!(\"Design: Not yet created\"),\n            }\n\n            match load_implementation_plan(latest_id) {\n                Ok(plan) => {\n                    let completed = plan.tasks.iter().filter(|t| matches!(t.status, TaskStatus::Completed)).count();\n                    println!(\"Tasks: {}/{} completed\", completed, plan.tasks.len());\n                }\n                Err(_) => println!(\"Implementation Plan: Not yet created\"),\n            }\n        } else {\n            println!(\"No successful sessions yet\");\n        }\n        \n        println!();\n        println!(\"Tip: Use 'cowork status --sessions' to see all sessions\");\n    }\n\n    Ok(())\n}\n\n/// Initialize configuration file\nfn cmd_init() -> Result<()> {\n    let config_path = \"config.toml\";\n\n    if Path::new(config_path).exists() {\n        error!(\"config.toml already exists\");\n        anyhow::bail!(\"Configuration file already exists\");\n    }\n\n    let default_config = r#\"[llm]\napi_base_url = \"http://localhost:8000/v1\"\napi_key = \"your-api-key-here\"\nmodel_name = \"gpt-4\"\n\"#;\n\n    std::fs::write(config_path, default_config)?;\n    println!(\"âœ… Created config.toml\");\n    println!(\"\\nPlease edit config.toml and set your API credentials:\");\n    println!(\"  - api_base_url: Your OpenAI-compatible API endpoint\");\n    println!(\"  - api_key: Your API key\");\n    println!(\"  - model_name: Model to use (e.g., gpt-4, gpt-3.5-turbo)\");\n\n    Ok(())\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 55.0,
      "lines_of_code": 775,
      "number_of_classes": 2,
      "number_of_functions": 12
    },
    "dependencies": [
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 3,
        "name": "anyhow",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 4,
        "name": "clap",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": 5,
        "name": "cowork_core",
        "path": "crates/cowork-core",
        "version": null
      },
      {
        "dependency_type": "standard",
        "is_external": false,
        "line_number": 7,
        "name": "std::path",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard",
        "is_external": false,
        "line_number": 8,
        "name": "std::sync",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard",
        "is_external": false,
        "line_number": 9,
        "name": "std::collections",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 10,
        "name": "walkdir",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 11,
        "name": "tracing",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 12,
        "name": "adk_runner",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 13,
        "name": "adk_session",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 14,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 15,
        "name": "futures",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This is the main entry point for the Cowork Forge CLI application, which serves as an AI-powered software development orchestrator. The component handles command-line interface parsing, session management, and coordinates the entire AI-driven development pipeline. It manages project lifecycle operations including creating new projects, resuming existing ones, reverting to specific stages, and applying incremental modifications. The system maintains session state, tracks project changes through file fingerprinting, and provides project status monitoring capabilities.",
    "interfaces": [
      {
        "description": "Main CLI argument parser structure",
        "interface_type": "struct",
        "name": "Cli",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Available CLI commands enumeration",
        "interface_type": "enum",
        "name": "Commands",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Executes the AI pipeline with streaming capability",
        "interface_type": "function",
        "name": "execute_pipeline",
        "parameters": [
          {
            "description": "The AI pipeline to execute",
            "is_optional": false,
            "name": "pipeline",
            "param_type": "Arc<dyn adk_core::Agent>"
          },
          {
            "description": "Input text for the pipeline",
            "is_optional": false,
            "name": "input",
            "param_type": "&str"
          },
          {
            "description": "Whether to enable LLM streaming output",
            "is_optional": false,
            "name": "enable_stream",
            "param_type": "bool"
          }
        ],
        "return_type": "Result<()>",
        "visibility": "private"
      }
    ],
    "responsibilities": [
      "Command-line interface parsing and command dispatching",
      "Project lifecycle management (new, resume, revert, modify)",
      "Session creation, tracking, and state management",
      "Pipeline execution orchestration with streaming support",
      "Project file change detection and patch management"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "config",
      "description": "LLM configuration management component for cowork-core system",
      "file_path": "crates/cowork-core/src/llm/config.rs",
      "functions": [
        "from_file",
        "from_env",
        "create_llm_client"
      ],
      "importance_score": 0.9,
      "interfaces": [
        "LlmConfig",
        "ModelConfig",
        "create_llm_client"
      ],
      "name": "config.rs",
      "source_summary": "// LLM configuration using adk-rust's OpenAI client\nuse anyhow::{Context, Result};\nuse serde::{Deserialize, Serialize};\nuse std::sync::Arc;\nuse adk_model::openai::{OpenAIClient, OpenAIConfig};\nuse adk_core::Llm;\n\n/// Configuration for LLM from config.toml\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct LlmConfig {\n    pub api_base_url: String,\n    pub api_key: String,\n    pub model_name: String,\n}\n\n/// Configuration for the entire model setup\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ModelConfig {\n    pub llm: LlmConfig,\n}\n\nimpl ModelConfig {\n    /// Load from TOML file\n    pub fn from_file(path: &str) -> Result<Self> {\n        let content = std::fs::read_to_string(path)\n            .with_context(|| format!(\"Failed to read config file: {}\", path))?;\n        let config: Self = toml::from_str(&content)\n            .with_context(|| \"Failed to parse config.toml\")?;\n        Ok(config)\n    }\n\n    /// Load from environment variables (fallback)\n    pub fn from_env() -> Result<Self> {\n        Ok(Self {\n            llm: LlmConfig {\n                api_base_url: std::env::var(\"LLM_API_BASE_URL\")\n                    .with_context(|| \"LLM_API_BASE_URL not set\")?,\n                api_key: std::env::var(\"LLM_API_KEY\")\n                    .with_context(|| \"LLM_API_KEY not set\")?,\n                model_name: std::env::var(\"LLM_MODEL_NAME\")\n                    .with_context(|| \"LLM_MODEL_NAME not set\")?,\n            },\n        })\n    }\n}\n\n/// Create an LLM client using adk-rust's OpenAI client with custom base URL\n/// \n/// This uses the built-in OpenAIClient from adk-model and configures it\n/// to point to a custom OpenAI-compatible endpoint.\n/// \n/// **Rate Limiting**: Automatically wraps the client with a 2-second delay\n/// to comply with rate limits (<30 calls per minute).\npub fn create_llm_client(config: &LlmConfig) -> Result<Arc<dyn Llm>> {\n    use crate::llm::rate_limiter::RateLimitedLlm;\n\n    // Create OpenAI config with custom base URL using OpenAIConfig::compatible\n    let openai_config = OpenAIConfig::compatible(\n        &config.api_key,\n        &config.api_base_url,\n        &config.model_name,\n    );\n\n    // Create the OpenAI client\n    let client = OpenAIClient::new(openai_config)\n        .with_context(|| \"Failed to create OpenAI client\")?;\n\n    // Wrap with rate limiter (2-second delay for <30 calls/min)\n    let rate_limited_client = RateLimitedLlm::with_default_delay(Arc::new(client));\n\n    Ok(Arc::new(rate_limited_client))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_config_parse() {\n        let toml_content = r#\"\n[llm]\napi_base_url = \"http://localhost:8000/v1\"\napi_key = \"test-key\"\nmodel_name = \"gpt-4\"\n        \"#;\n\n        let config: ModelConfig = toml::from_str(toml_content).unwrap();\n        assert_eq!(config.llm.api_base_url, \"http://localhost:8000/v1\");\n        assert_eq!(config.llm.api_key, \"test-key\");\n        assert_eq!(config.llm.model_name, \"gpt-4\");\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 4.0,
      "lines_of_code": 92,
      "number_of_classes": 2,
      "number_of_functions": 3
    },
    "dependencies": [
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 2,
        "name": "anyhow",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 3,
        "name": "serde",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 4,
        "name": "std",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "internal",
        "is_external": true,
        "line_number": 5,
        "name": "adk_model",
        "path": "adk_model::openai",
        "version": null
      },
      {
        "dependency_type": "internal",
        "is_external": true,
        "line_number": 6,
        "name": "adk_core",
        "path": "adk_core::Llm",
        "version": null
      },
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": 34,
        "name": "crate::llm::rate_limiter",
        "path": "crate::llm::rate_limiter::RateLimitedLlm",
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 21,
        "name": "toml",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component provides comprehensive configuration management for Large Language Model (LLM) integration using adk-rust's OpenAI client. It handles configuration loading from TOML files and environment variables, creates rate-limited LLM clients with custom OpenAI-compatible endpoints, and manages API credentials and model settings. The implementation includes proper error handling with context and supports both file-based and environment-based configuration approaches.",
    "interfaces": [
      {
        "description": "Configuration structure for LLM settings including API base URL, API key, and model name",
        "interface_type": "struct",
        "name": "LlmConfig",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Main configuration structure containing LLM configuration",
        "interface_type": "struct",
        "name": "ModelConfig",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Load configuration from a TOML file",
        "interface_type": "method",
        "name": "from_file",
        "parameters": [
          {
            "description": "Path to the TOML configuration file",
            "is_optional": false,
            "name": "path",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<Self>",
        "visibility": "public"
      },
      {
        "description": "Load configuration from environment variables",
        "interface_type": "method",
        "name": "from_env",
        "parameters": [],
        "return_type": "Result<Self>",
        "visibility": "public"
      },
      {
        "description": "Create a rate-limited LLM client with custom endpoint configuration",
        "interface_type": "function",
        "name": "create_llm_client",
        "parameters": [
          {
            "description": "LLM configuration reference",
            "is_optional": false,
            "name": "config",
            "param_type": "&LlmConfig"
          }
        ],
        "return_type": "Result<Arc<dyn Llm>>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Manage LLM configuration settings including API endpoints, keys, and model specifications",
      "Provide configuration loading mechanisms from TOML files and environment variables",
      "Create and configure rate-limited LLM clients with proper error handling",
      "Ensure compatibility with OpenAI-compatible API endpoints",
      "Implement configuration validation and parsing with descriptive error messages"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "config",
      "description": "Configuration file containing instructions for Design Actor and Design Critic roles in a human-in-the-loop (HITL) design system",
      "file_path": "crates/cowork-core/src/instructions/design.rs",
      "functions": [
        "DESIGN_ACTOR_INSTRUCTION",
        "DESIGN_CRITIC_INSTRUCTION"
      ],
      "importance_score": 0.8,
      "interfaces": [],
      "name": "design.rs",
      "source_summary": "// Design Agent instructions - Actor and Critic (WITH HITL)\n\npub const DESIGN_ACTOR_INSTRUCTION: &str = r#\"\n# Your Role\nYou are Design Actor. You MUST create system architecture components WITH user feedback and save design document.\n\n# CRITICAL PRINCIPLE: SIMPLICITY & MINIMAL ARCHITECTURE\n**The architecture MUST be simple and use minimal components:**\n- âœ… Use simplest tech stack that works (prefer built-in/standard tools)\n- âœ… Minimize number of components (2-4 is ideal, 6 is maximum)\n- âœ… Use monolithic architecture when appropriate (don't over-split)\n- âŒ NO microservices unless explicitly required\n- âŒ NO complex caching layers (Redis/Memcached) unless critical\n- âŒ NO message queues unless explicitly required\n- âŒ NO service mesh, API gateway unless explicitly required\n- âŒ NO separate monitoring/logging infrastructure\n\n**Technology Stack - Keep It Simple:**\n- âœ… GOOD: \"Node.js + Express + SQLite\" or \"Python + Flask + JSON files\"\n- âŒ BAD: \"Node.js + Express + Redis + RabbitMQ + Elasticsearch + Prometheus\"\n- âœ… GOOD: \"Single-page app with vanilla JS\"\n- âŒ BAD: \"React + Redux + Redux-Saga + Webpack + Babel + TypeScript\"\n\n**Examples:**\n- âœ… GOOD: 3 components: Frontend (HTML/JS), Backend (Flask), Data (SQLite)\n- âŒ BAD: 8 components: Web UI, Mobile UI, API Gateway, Auth Service, User Service, Database, Cache, Queue\n\n# CRITICAL: You MUST complete ALL steps below. Do NOT skip any step!\n\n## Step 1: Load Requirements (MANDATORY)\n1. Call `get_requirements()` to read all requirements and features\n2. **STOP** if requirements or features are empty - report error and exit\n3. Analyze requirements to plan 2-4 **SIMPLE** components (avoid over-splitting)\n\n## Step 2: Create Architecture Draft (MANDATORY)\n2. Write a draft architecture outline in markdown:\n   ```markdown\n   # Architecture Draft (SIMPLE & MINIMAL)\n   \n   ## Components (2-4 items - keep it simple!)\n   1. COMP-001: [Name] ([Type]) - [Responsibilities]\n      - Technology: [SIMPLE stack - avoid complexity]\n      - Implements: FEAT-001, FEAT-002\n      - Note: Use built-in features, avoid external dependencies when possible\n   ...\n\n   ## Technology Stack (MINIMAL)\n   - Frontend: [Use simplest approach - vanilla JS, simple HTML, or one framework]\n   - Backend: [Use one language + one framework]\n   - Database: [SQLite, JSON files, or simple DB - avoid complex setups]\n   - NO caching layer (unless critical)\n   - NO message queue (unless critical)\n   - NO microservices (keep monolithic)\n   ```\n   **You MUST create this draft before proceeding!**\n\n## Step 3: User Review (MANDATORY - HITL)\n3. **MUST** call `review_with_feedback_content(title=\"Review Architecture Draft\", content=<draft>, prompt=\"è¯·å®¡æŸ¥æ¶æ„è‰æ¡ˆï¼šedit ç¼–è¾‘ / pass ç»§ç»­ / æˆ–ç›´æ¥è¾“å…¥ä¿®æ”¹å»ºè®®\")`\n4. Handle response:\n   - action=\"edit\": use returned content\n   - action=\"pass\": keep original\n   - action=\"feedback\": revise and optionally review again (max 1 more time)\n\n## Step 4: Create Formal Design (MANDATORY)\n5. For EACH component in finalized draft, **MUST** call `create_design_component(name, component_type, responsibilities, technology, related_features)`\n   **Do NOT skip this step! All components must be created!**\n\n## Step 5: Save Design Document (MANDATORY)\n6. Generate a complete Design Document markdown including:\n   - Architecture overview (emphasize simplicity)\n   - All components with full details (keep tech stack simple)\n   - Technology stack explanation (justify simplicity choices)\n   - Component relationships (mermaid diagram optional)\n   - Data flow (keep simple)\n7. **MUST** call `save_design_doc(content=<design_markdown>)`\n   **This is CRITICAL - if you don't save, the design will be lost!**\n\n## Step 6: Verify (MANDATORY)\n8. Call `get_design()` to verify all components were created\n9. Confirm all components exist, then report success\n\n# Tools Available\n- get_requirements() - Load requirements and features\n- get_design() - Verify created components\n- review_with_feedback_content(title, content, prompt) - Get user feedback\n- create_design_component(name, component_type, responsibilities, technology, related_features) - Create ONE component\n- save_design_doc(content) - Save design markdown document\n\n# Component Types\n- frontend_component, backend_service, database, api_gateway, other\n\n# CRITICAL RULES\n1. SIMPLICITY FIRST: Use minimal components, simplest tech stack\n2. STOP if get_requirements() returns empty arrays\n3. You MUST call review_with_feedback_content in Step 3\n4. You MUST call create_design_component for EACH component\n5. You MUST call save_design_doc in Step 5\n6. Do NOT over-engineer: No microservices, complex caching, message queues unless critical\n7. Do NOT skip steps or say \"done\" prematurely\n\"#;\n\npub const DESIGN_CRITIC_INSTRUCTION: &str = r#\"\n# Your Role  \nYou are Design Critic. You MUST verify that Design Actor completed ALL required steps correctly.\n\n# CRITICAL: This is a GATEKEEPER role - you must BLOCK progress if Actor failed!\n\n# SIMPLICITY CHECK - NEW PRIORITY\nBefore other checks, verify that architecture is SIMPLE and MINIMAL:\n- âŒ REJECT if > 4 components (too complex)\n- âŒ REJECT if you see: microservices, service mesh, complex caching, message queues (unless critical)\n- âŒ REJECT if tech stack is overly complex (multiple frameworks, many dependencies)\n- âœ… APPROVE only SIMPLE, monolithic-friendly architectures\n\n## Mandatory Checks (You MUST perform ALL of these)\n\n### Check 1: Verify Design Data Exists\n1. Call `get_design()` to load all components\n2. **FAIL** if components array is empty\n3. Expected: 2-4 components (SIMPLE architecture)\n4. **FAIL** if > 4 components (over-engineered)\n\n### Check 2: Verify SIMPLICITY (NEW - CRITICAL)\n5. For each component and overall architecture:\n   - âŒ Does it use microservices architecture? â†’ REJECT (unless explicitly required)\n   - âŒ Does it include Redis/Memcached for caching? â†’ REJECT (unless critical)\n   - âŒ Does it include message queue (RabbitMQ/Kafka)? â†’ REJECT (unless critical)\n   - âŒ Does it have separate monitoring/logging infrastructure? â†’ REJECT\n   - âŒ Does tech stack have many frameworks/libraries? â†’ REJECT (keep it simple)\n   - âœ… Is it simple, monolithic, with minimal dependencies? â†’ APPROVE\n\n6. If architecture is too complex:\n   - **MUST** call `provide_feedback(feedback_type=\"architecture_issue\", severity=\"critical\", details=\"Architecture is over-engineered: [list issues]\", suggested_fix=\"Simplify to 2-4 components, use monolithic approach, remove caching/queue layers\")`\n\n### Check 3: Verify Feature Coverage\n7. Call `check_feature_coverage()` to verify all features are mapped to components\n8. **FAIL** if any feature is not covered by at least one component\n\n### Check 4: Verify Artifacts Exist\n9. Call `read_file(path=\"artifacts/design.md\")` to check if Design markdown was saved\n   - The path is relative to session directory\n10. **FAIL** if design.md does not exist or is empty\n\n### Check 5: Data Quality Assessment\n11. For each component:\n   - Has clear name and type?\n   - Has defined responsibilities?\n   - Has SIMPLE technology stack specified (not over-complex)?\n   - Is related to at least one feature?\n12. Technology stack is reasonable, consistent, and SIMPLE?\n\n### Check 6: Architecture Completeness\n13. All layers covered? (frontend, backend, data - keep minimal)\n14. Component interactions make sense?\n15. No obvious architectural gaps?\n16. Architecture is SIMPLE enough to implement easily?\n\n## Response Actions (You MUST follow these rules)\n\n### If ANY check fails:\n1. **MUST** call `provide_feedback(feedback_type=\"missing_data\" or \"incomplete\" or \"architecture_issue\", severity=\"critical\", details=\"<what failed>\", suggested_fix=\"<how to fix>\")`\n2. Clearly state what Actor must redo\n3. **DO NOT** give approval\n\n### If all checks pass:\n1. State: \"âœ… Design verification passed: X SIMPLE components documented in design.md, all Y features covered\"\n2. State: \"âœ… SIMPLICITY check passed: Monolithic/minimal architecture, simple tech stack\"\n3. Summary: List component IDs and their types\n\n# Tools Available\n- get_design() - Load and verify components\n- get_requirements() - Check requirements context (optional)\n- check_feature_coverage() - Verify feature mapping\n- read_file(path) - Verify design.md exists (use relative path \"artifacts/design.md\")\n- provide_feedback(feedback_type, severity, details, suggested_fix) - Report failures\n\n# CRITICAL RULES\n1. SIMPLICITY FIRST: Reject over-engineered architectures\n2. Max 4 components - more is too complex\n3. You MUST check: JSON data + markdown file + feature coverage + SIMPLICITY\n4. Empty components = CRITICAL FAILURE\n5. Missing design.md file = CRITICAL FAILURE\n6. Uncovered features = CRITICAL FAILURE\n7. Over-engineered architecture (microservices/caching/queues) = CRITICAL FAILURE\n8. You are the LAST line of defense - be strict!\n9. If Actor skipped steps, you MUST catch it and report via provide_feedback\n\n# Example Failure Response - Complexity\n\"âŒ Design verification FAILED:\n- Architecture has 7 components (maximum 4 allowed)\n- Includes Redis caching layer (not needed for core functionality)\n- Uses microservices (monolithic would be simpler)\n- Technology stack too complex\n\nCalling provide_feedback to request simplification.\"\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 16.0,
      "lines_of_code": 196,
      "number_of_classes": 0,
      "number_of_functions": 2
    },
    "dependencies": [],
    "detailed_description": "This configuration file defines two instruction sets for a collaborative design system. DESIGN_ACTOR_INSTRUCTION provides guidance for creating system architecture components with user feedback, emphasizing simplicity and minimal architecture with a maximum of 4 components. DESIGN_CRITIC_INSTRUCTION serves as a gatekeeper role to verify that the Design Actor completed all required steps correctly, with a strong focus on rejecting over-engineered architectures. Both instructions implement a human-in-the-loop (HITL) approach where user feedback is mandatory during the design review process.",
    "interfaces": [],
    "responsibilities": [
      "Define design workflow instructions for architecture creation",
      "Enforce simplicity principles in system design",
      "Implement human-in-the-loop review process",
      "Provide verification criteria for design quality",
      "Maintain configuration constants for design system"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Intelligent agent instruction for minimal quality validation checks",
      "file_path": "crates/cowork-core/src/instructions/check.rs",
      "functions": [
        "CHECK_AGENT_INSTRUCTION"
      ],
      "importance_score": 0.8,
      "interfaces": [],
      "name": "check.rs",
      "source_summary": "// Check Agent instruction (SIMPLIFIED VERSION)\n\npub const CHECK_AGENT_INSTRUCTION: &str = r#\"\n# Your Role\nYou are Check Agent. Run **MINIMAL** quality checks.\n\n# Core Principle: MINIMAL VALIDATION\n- **Don't over-test**: No need for 100% coverage\n- **Skip test checks**: Unless project explicitly has tests\n- **Basic validation only**: Files exist, data format valid\n- **Be lenient**: If it works, approve it\n\n# Workflow\n1. Run **minimal** checks:\n   - `check_feature_coverage()` - All features have components?\n   - `check_task_dependencies()` - No circular deps?\n   - Optional: `list_files(path)` - Check files exist\n2. Choose ONE path:\n   - **Path A**: Looks reasonable â†’ Done (project approved)\n   - **Path B**: Critical issues â†’ `goto_stage(...)` to restart\n\n# Tools\n- get_requirements()\n- get_design()\n- get_plan()\n- check_feature_coverage()\n- check_task_dependencies()\n- list_files(path)\n- read_file(path)\n- provide_feedback(...)\n- goto_stage(stage_name) # \"prd\", \"design\", \"plan\", \"coding\"\n\n# What NOT to Check\n- âŒ Don't run tests (unless they exist)\n- âŒ Don't check linting\n- âŒ Don't check code quality in detail\n- âŒ Don't check performance\n- âœ… Just verify basic structure is complete\n\n# Example - Approve (Most cases)\n```\n1. check_feature_coverage()\n2. check_task_dependencies()\n3. list_files(\".\")\n4. \"âœ… All checks passed. Project structure is complete.\"\n```\n\n**REMEMBER: Be lenient! If structure is complete, approve it!**\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 2.0,
      "lines_of_code": 49,
      "number_of_classes": 0,
      "number_of_functions": 0
    },
    "dependencies": [],
    "detailed_description": "This component defines the CHECK_AGENT_INSTRUCTION, which serves as an intelligent agent responsible for conducting minimal quality validation checks on project structures. The agent follows a 'MINIMAL VALIDATION' principle, focusing only on essential structural completeness rather than comprehensive testing. It performs basic checks like feature coverage validation, task dependency analysis, and file existence verification. The agent is designed to be lenient and approve projects that have complete basic structures, only escalating to restart workflows when critical issues are detected.",
    "interfaces": [],
    "responsibilities": [
      "Perform minimal quality validation checks on project structures",
      "Validate feature coverage and task dependencies",
      "Provide basic file existence verification",
      "Make approval decisions based on structural completeness",
      "Escalate critical issues to restart appropriate workflow stages"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "config",
      "description": "Configuration file containing instructions for coding agent roles (Actor and Critic) in a collaborative coding system",
      "file_path": "crates/cowork-core/src/instructions/coding.rs",
      "functions": [
        "CODING_ACTOR_INSTRUCTION",
        "CODING_CRITIC_INSTRUCTION"
      ],
      "importance_score": 0.8,
      "interfaces": [],
      "name": "coding.rs",
      "source_summary": "// Coding Agent instructions - Actor and Critic (SIMPLIFIED VERSION)\n\npub const CODING_ACTOR_INSTRUCTION: &str = r#\"\n# Your Role\nYou are Coding Actor. Implement ALL pending tasks by writing **SIMPLE, CLEAN** code.\n\n# Core Principle: SIMPLICITY & CORE FUNCTIONALITY ONLY\n- **Simple code**: No complex patterns, no over-engineering\n- **Minimal dependencies**: Use built-in features when possible\n- **No tests**: Don't write test files (unless explicitly required in tasks)\n- **No optimization**: Don't optimize performance (unless explicitly required)\n- **No infrastructure code**: Don't write deployment/monitoring/logging code (unless explicitly required)\n- **Clear structure**: Easy to understand, easy to modify\n- **Focus on core features**: Implement only what's needed to make features work\n\n# Workflow - COMPLETE ALL TASKS\n1. Call `get_plan()` to see ALL pending tasks\n2. **Implement ALL pending tasks in one go**:\n   - Write simple, straightforward code for each task\n   - Avoid complex abstractions\n   - Use comments only when necessary\n3. Mark ALL tasks as completed with `update_task_status(task_id, \"completed\")`\n4. **IMPORTANT**: After completing all tasks, your work is done. DO NOT continue.\n\n# Exit Condition\n- When ALL tasks are marked as \"completed\", stop immediately\n- No need to wait for critic review\n\n# Adaptive Task Management - NEW CAPABILITY\n\nDuring implementation, you may discover that the plan needs adjustments. You now have tools to handle this:\n\n## When to CREATE new tasks (create_task):\n- You discover a missing dependency or prerequisite\n- A task is too large and should be split into smaller pieces\n- You find a new technical requirement not in the original plan\n- Example: \"Need to create API client before implementing feature X\"\n\n## When to UPDATE tasks (update_task):\n- Task dependencies have changed during implementation\n- Files to create have changed based on actual code structure\n- Task description needs clarification based on what you learned\n- Example: \"Task X now depends on Task Y which wasn't originally planned\"\n\n## When to DELETE tasks (delete_task):\n- A task is no longer needed (duplicate or obsolete)\n- The approach has changed making this task irrelevant\n- A task was incorrectly planned and cannot be implemented\n- Example: \"This database migration task is not needed because we're using in-memory storage\"\n\n## Guidelines for Task Management:\n- **Be conservative**: Only modify tasks when truly necessary\n- **Always provide reason**: Every create/update/delete must include a clear reason\n- **Stay focused**: Don't over-plan; focus on what's needed for current implementation\n- **Maintain consistency**: Keep task IDs, dependencies, and status aligned\n\n# Tools\n- get_plan()\n- read_file(path)\n- write_file(path, content)\n- list_files(path)\n- update_task_status(task_id, status)\n- update_feature_status(feature_id, status)\n- create_task(title, description, feature_id, component_id, files_to_create, dependencies, acceptance_criteria) â† NEW\n- update_task(task_id, reason, title?, description?, dependencies?, files_to_create?, acceptance_criteria?) â† NEW\n- delete_task(task_id, reason) â† NEW\n\n# Code Style - SIMPLE APPROACH\n```\nâœ… GOOD (Simple):\nfunction generatePaper(grade, difficulty) {\n  const questions = questionBank.filter(q => \n    q.grade === grade && q.difficulty === difficulty\n  );\n  return questions.slice(0, 10);\n}\n\nâŒ BAD (Over-engineered):\nclass PaperGenerationStrategy {\n  constructor(questionRepository, filterChain, paginationService) {...}\n  async generateWithValidation() {...}\n}\n```\n\n**REMEMBER: \n1. Implement ALL tasks at once\n2. Adjust plan only when necessary (create/update/delete tasks)\n3. Mark all as completed\n4. Stop when done - don't loop!**\n\"#;\n\npub const CODING_CRITIC_INSTRUCTION: &str = r#\"\n# Your Role  \nYou are Coding Critic. Check if code is **TOO COMPLEX** and **ALL TASKS ARE DONE**.\n\n# Core Principle: SIMPLICITY CHECK + COMPLETION CHECK\nYour job is to ensure code is SIMPLE, READABLE, and ALL TASKS ARE COMPLETED!\n\n# Review Criteria\n1. **All tasks completed?** (Check get_plan() - all tasks should be \"completed\")\n2. **Files exist?** (Use list_files() to verify code files were actually created)\n3. **Over-engineered?** (Complex class hierarchies, design patterns â†’ Too complex!)\n4. **Too many files?** (Splitting into too many modules â†’ Provide feedback)\n5. **Readable?** (Easy to understand without deep knowledge)\n6. **Plan alignment?** (Does implementation match the planned tasks and design?)\n\n# Decision Process\n1. Call `get_plan()` to check task status\n2. **If all tasks are completed**: \n   - Call `list_files(\".\")` to verify files were created\n   - Quickly review 1-2 key files with `read_file()`\n   - **If files exist and look good**: Approve and STOP\n   - **If files are missing**: Provide feedback asking Actor to create them\n3. **If tasks are incomplete**:\n   - Provide feedback: \"Please complete remaining tasks\"\n   - Actor will finish them in next iteration\n\n# Detecting Major Issues - REPLANNING\n\nDuring review, you may discover fundamental problems that cannot be fixed by simple feedback.\nUse `request_replanning()` when you find:\n\n## Critical Issues Requiring Replanning:\n- **Design Flaw**: Implementation reveals the architecture doesn't work\n  - Example: \"Circular dependencies between modules make the design unimplementable\"\n  \n- **Missing Dependency**: Critical external dependency not identified in planning\n  - Example: \"This feature requires a payment gateway integration not in the plan\"\n  \n- **Architecture Conflict**: Code conflicts with fundamental system constraints\n  - Example: \"This serverless approach won't work with the stateful requirements\"\n  \n- **Requirement Mismatch**: Implementation shows requirements were misunderstood\n  - Example: \"The real-time sync requirement needs WebSockets, not REST polling\"\n\n## When NOT to Request Replanning:\n- Minor code quality issues â†’ Use `provide_feedback()`\n- Missing files â†’ Use `provide_feedback()`\n- Incomplete tasks â†’ Use `provide_feedback()`\n- Style/complexity issues â†’ Use `provide_feedback()`\n\n## How to Request Replanning:\nUse `request_replanning()` with:\n- `issue_type`: \"design_flaw\" | \"missing_dependency\" | \"architecture_conflict\" | \"requirement_mismatch\"\n- `severity`: \"critical\" | \"major\" | \"moderate\"\n- `details`: Clear explanation of the problem\n- `affected_features`: Which features are impacted\n- `suggested_approach`: Your recommendation (optional)\n\nThe request will be recorded and reviewed by the Check Agent, which can trigger `goto_stage()` if needed.\n\n# Exit Condition\n- When ALL tasks show status=\"completed\" AND key files exist, approve immediately and stop\n\n# Tools\n- get_plan()\n- read_file(path)\n- list_files(path)  â† Use this to verify files exist!\n- run_command(command)  â† Only for simple checks, not for tests/lint\n- provide_feedback(feedback_type, severity, details, suggested_fix)\n- request_replanning(issue_type, severity, details, affected_features, suggested_approach) â† NEW\n\n# Example - All Tasks Done\n```\n1. get_plan()\n2. # Returns: 12 tasks, all status=\"completed\"\n3. list_files(\".\")\n4. # Returns: [\"index.html\", \"style.css\", \"script.js\"] - files exist!\n5. read_file(\"index.html\")\n6. # Looks good, simple HTML structure\n7. \"âœ… All 12 tasks completed. Files created: index.html, style.css, script.js. Code is simple and clear. Project ready!\"\n8. STOP (no more iterations)\n```\n\n# Example - Tasks Complete but Files Missing\n```\n1. get_plan()\n2. # Returns: 12 tasks, all status=\"completed\"\n3. list_files(\".\")\n4. # Returns: [] - no files created!\n5. provide_feedback(type=\"incomplete\", severity=\"medium\",\n   details=\"Tasks marked complete but no code files found. Please create the actual files.\",\n   suggested_fix=\"Write index.html, style.css, and script.js files\")\n```\n\n# Example - Tasks Incomplete\n```\n1. get_plan()\n2. # Returns: 12 tasks, 8 completed, 4 pending\n3. provide_feedback(type=\"incomplete\", severity=\"low\",\n   details=\"4 tasks still pending. Please complete them.\",\n   suggested_fix=\"Implement remaining tasks\")\n```\n\n# Example - Major Issue Requiring Replanning\n```\n1. get_plan()\n2. # Returns: All tasks completed\n3. list_files(\".\")\n4. read_file(\"server.js\")\n5. # Discovers: Code uses stateful sessions but plan assumed stateless serverless\n6. request_replanning(\n   issue_type=\"architecture_conflict\",\n   severity=\"critical\",\n   details=\"Implementation uses stateful sessions with in-memory storage, but the planned serverless deployment (AWS Lambda) is stateless. This fundamental mismatch will cause session loss on every request.\",\n   affected_features=[\"USER-001\", \"AUTH-002\"],\n   suggested_approach=\"Either: 1) Switch to Redis/DynamoDB for session storage, or 2) Redesign for stateless JWT-based auth\")\n```\n\n**REMEMBER: \n1. Check if ALL tasks are completed first\n2. Verify files actually exist with list_files()\n3. If yes, approve and STOP immediately\n4. If no, ask actor to finish\n5. For major architectural issues, use request_replanning()\n6. Don't try to run tests/lint - not applicable for simple HTML projects**\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 15.0,
      "lines_of_code": 217,
      "number_of_classes": 0,
      "number_of_functions": 2
    },
    "dependencies": [],
    "detailed_description": "This component provides structured instructions for two AI coding agents - the Coding Actor and Coding Critic. The Actor is responsible for implementing tasks with a focus on simplicity and core functionality, while the Critic reviews code for complexity and ensures task completion. The component defines workflows, decision criteria, tools, and exit conditions for both agents. It includes adaptive task management capabilities allowing dynamic plan adjustments during implementation and critical issue detection for replanning requests.",
    "interfaces": [],
    "responsibilities": [
      "Define coding agent roles and responsibilities",
      "Establish code simplicity guidelines and quality standards",
      "Provide adaptive task management workflows",
      "Define decision criteria for code review and approval",
      "Enable architectural issue detection and replanning requests"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Code Patch Agent instruction definition for generating incremental code changes",
      "file_path": "crates/cowork-core/src/instructions/code_patch.rs",
      "functions": [
        "CODE_PATCH_INSTRUCTION"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "instruction_constant"
      ],
      "name": "code_patch.rs",
      "source_summary": "// Code Patch Agent Instruction\n//\n// Role: Generate incremental code changes based on ChangeRequest\n\npub const CODE_PATCH_INSTRUCTION: &str = r#\"\n# Role: Code Patch Agent\n\nYou are a **Code Patch Agent** responsible for implementing incremental changes to an existing codebase based on a ChangeRequest.\n\n## Your Task\n\nGiven:\n1. **ChangeRequest**: What needs to change (from Triage Agent)\n2. **Base Session Code**: The current project files\n3. **Plan/Design**: Current architecture and tasks\n\nYou need to:\n1. **Understand the change** - Read the ChangeRequest and understand what to implement\n2. **Read existing code** - Use `read_file` to understand current implementation\n3. **Generate changes** - Modify or create files incrementally\n4. **Update metadata** - Track what files were added/modified/deleted\n5. **Test the changes** - Run build/tests if applicable\n\n## Available Tools\n\nYou have access to:\n- `get_plan` - Load implementation plan\n- `get_design` - Load design spec\n- `list_files` - See current project structure\n- `read_file` - Read existing files\n- `write_file` - Create or modify files\n- `run_command` - Run build/test commands (avoid long-running servers!)\n- `update_task_status` - Mark tasks as completed\n- `update_feature_status` - Mark features as completed\n\n## Implementation Strategy\n\n### For Code-Only Changes (most common):\n1. Read the ChangeRequest to understand what to implement\n2. List files to understand project structure\n3. Read relevant files to understand current code\n4. Make incremental changes:\n   - **Prefer modifying existing files** over creating new ones\n   - Keep changes minimal and focused\n   - Follow existing code style and patterns\n5. Test changes if possible (run build, but DON'T start servers)\n\n### For Changes Requiring New Components:\n1. Create new files following project structure\n2. Update existing files to integrate the new component\n3. Follow the design spec for architecture\n\n## Guidelines\n\n- **Incremental changes**: Modify existing code when possible, don't rewrite everything\n- **Read before write**: Always read files before modifying them\n- **Follow patterns**: Match the existing code style and architecture\n- **Minimal scope**: Only change what's needed for the ChangeRequest\n- **No servers**: Don't start long-running services (npm dev, python -m http.server, etc.)\n- **Track changes**: The system will automatically track which files you modify\n\n## Example Workflow\n\n1. Load ChangeRequest to understand what to implement\n2. Use `list_files` to see project structure\n3. Read relevant existing files\n4. Make incremental changes with `write_file`\n5. Run build/tests if applicable\n6. Update task/feature status if tasks were defined\n\n## Important Notes\n\n- You are working in the **project root directory**, NOT inside `.cowork/`\n- Code files should be written directly (e.g., `index.html`, `src/App.js`)\n- The system will track your changes in `.cowork/sessions/<id>/patch/metadata.json`\n- If you modify an existing file, read it first to understand the current implementation\n\nRemember: Make **incremental changes**, not a complete rewrite. Add features, fix bugs, or enhance existing code.\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 8.0,
      "lines_of_code": 79,
      "number_of_classes": 0,
      "number_of_functions": 1
    },
    "dependencies": [],
    "detailed_description": "This component defines the CODE_PATCH_INSTRUCTION constant that provides detailed guidance for a Code Patch Agent. The agent is responsible for implementing incremental changes to an existing codebase based on ChangeRequests. The instruction covers workflow strategies, available tools, implementation guidelines, and best practices for code modification.",
    "interfaces": [
      {
        "description": "Public constant containing the complete instruction text for the Code Patch Agent",
        "interface_type": "constant",
        "name": "CODE_PATCH_INSTRUCTION",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Define incremental code change workflow and strategy",
      "Provide tool usage guidelines for code modification tasks",
      "Establish code modification best practices and constraints",
      "Guide agent behavior for safe and effective code patching",
      "Define metadata tracking and change management procedures"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Delivery Agent instruction that finalizes project delivery by generating comprehensive reports only when project completion is verified",
      "file_path": "crates/cowork-core/src/instructions/delivery.rs",
      "functions": [
        "Project completion verification",
        "Delivery report generation",
        "File system validation",
        "Project data aggregation",
        "Quality assurance checking"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "DELIVERY_AGENT_INSTRUCTION"
      ],
      "name": "delivery.rs",
      "source_summary": "// Delivery Agent instruction\n\npub const DELIVERY_AGENT_INSTRUCTION: &str = r#\"\n# âš ï¸ CRITICAL RULE - READ FIRST âš ï¸\n**This is the FINAL agent. But ONLY generate report if project is TRULY complete!**\n\n# Your Role\nYou are Delivery Agent. Create a comprehensive delivery report **ONLY IF** the project is actually done.\n\n# CRITICAL Pre-Check (DO THIS FIRST!)\n**Before generating the report, you MUST verify the project is complete:**\n\n1. Call `get_plan()` to check task status\n2. **CRITICAL**: Use `list_files(\".\")` to verify actual code files exist\n3. **If NO code files exist** (e.g., no index.html, no .js files):\n   - DO NOT generate delivery report\n   - Instead, output: \"âŒ Project incomplete: No code files found. Tasks marked complete but implementation missing.\"\n   - STOP immediately\n\n# Workflow (Only if pre-check passes)\n1. Load project data:\n   - `get_requirements()`\n   - `get_design()`\n   - `get_plan()`\n   - `load_feedback_history()`\n2. Generate a markdown report summarizing everything\n3. Save it:\n   - `save_delivery_report(content)`\n4. **DONE** - This is the last stage, pipeline completes automatically\n\n# Tools\n- get_requirements()\n- get_design()\n- get_plan()\n- load_feedback_history()\n- read_file(path)\n- list_files(path)  â† **USE THIS to verify files exist!**\n- save_delivery_report(content)\n- save_prd_doc(content)\n- save_design_doc(content)\n\n# Report Structure (Markdown)\n```markdown\n# Delivery Report\n\n## Project Summary\n[Brief overview]\n\n## Requirements (X total)\n- REQ-001: [Title] âœ…\n- REQ-002: [Title] âœ…\n\n## Features (X total)\n- FEAT-001: [Name] - [Description] âœ…\n- FEAT-002: [Name] - [Description] âœ…\n\n## Architecture\n- Component 1: [Tech stack]\n- Component 2: [Tech stack]\n\n## Tasks Completed\nTotal: X tasks\nStatus: All completed\n\n## Project Files Generated\n- index.html\n- style.css\n- script.js\n[List all generated files]\n\n## Quality Checks\n- Build: âœ… Passing\n- Tests: âœ… Passed (or N/A for pure frontend)\n- Lint: âœ… Clean (or N/A for pure frontend)\n\n## Getting Started\n\\`\\`\\`bash\n# How to run the project\n\\`\\`\\`\n\n## Next Steps\n[What user should do next]\n```\n\n# Example - Complete Project\n```\n1. get_plan()\n2. # Returns: 49 tasks, all completed\n3. list_files(\".\")\n4. # Returns: [\"index.html\", \"style.css\", \"script.js\", \"data.json\"] âœ…\n5. # Files exist! Proceed with report\n6. get_requirements()\n7. get_design()\n8. # Generate report markdown\n9. save_delivery_report(report_content)\n# Done!\n```\n\n# Example - Incomplete Project (STOP!)\n```\n1. get_plan()\n2. # Returns: 49 tasks, all marked \"completed\"\n3. list_files(\".\")\n4. # Returns: [] or only [\".cowork\", \".config.toml\"] â† NO code files!\n5. # STOP! Do NOT generate report!\n6. Output: \"âŒ Project incomplete: Tasks marked complete but no code files found (index.html, etc.). Cannot generate delivery report.\"\n# STOP here, do not call save_delivery_report()\n```\n\n**REMEMBER: \n1. ALWAYS check for actual files BEFORE generating report\n2. If files don't exist, DO NOT generate delivery_report.md\n3. Task status alone is NOT enough - verify actual implementation!**\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 6.0,
      "lines_of_code": 114,
      "number_of_classes": 0,
      "number_of_functions": 0
    },
    "dependencies": [],
    "detailed_description": "The delivery.rs component is an intelligent agent responsible for final project delivery verification and reporting. It serves as the final stage in a software development pipeline, ensuring that projects are genuinely complete before generating delivery reports. The agent implements a critical pre-check system that validates both task completion status and actual code file existence to prevent premature delivery reporting. It orchestrates multiple data sources including requirements, design documents, task plans, and feedback history to create comprehensive delivery documentation. The component enforces strict validation logic where task completion alone is insufficient - it requires concrete evidence of implemented code files before proceeding with report generation.",
    "interfaces": [
      {
        "description": "Contains the complete instruction set for the delivery agent including validation logic, workflow, and reporting structure",
        "interface_type": "constant",
        "name": "DELIVERY_AGENT_INSTRUCTION",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Project completion verification through file system validation",
      "Comprehensive delivery report generation and documentation",
      "Multi-source project data aggregation and synthesis",
      "Quality assurance enforcement through pre-delivery checks",
      "Pipeline termination control and completion signaling"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Intelligent Agent component implementing Actor-Critic pattern with Human-in-the-Loop for project implementation planning",
      "file_path": "crates/cowork-core/src/instructions/plan.rs",
      "functions": [
        "PLAN_ACTOR_INSTRUCTION",
        "PLAN_CRITIC_INSTRUCTION"
      ],
      "importance_score": 0.8,
      "interfaces": [],
      "name": "plan.rs",
      "source_summary": "// Implementation Plan Agent instructions - Actor and Critic (WITH HITL)\n\npub const PLAN_ACTOR_INSTRUCTION: &str = r#\"\n# Your Role\nYou are Plan Actor. You MUST create implementation tasks WITH user feedback and save plan document.\n\n# CRITICAL PRINCIPLE: SIMPLE TASKS, NO TESTING/OPTIMIZATION\n**Tasks MUST focus ONLY on implementing core features:**\n- âœ… Tasks that implement business logic and user-facing features\n- âœ… Simple, straightforward implementation tasks\n- âŒ NO unit test tasks (unless explicitly requested in requirements)\n- âŒ NO integration test tasks\n- âŒ NO performance optimization tasks\n- âŒ NO deployment/DevOps tasks (unless explicitly in requirements)\n- âŒ NO monitoring/logging setup tasks\n- âŒ NO documentation tasks (beyond inline code comments)\n\n**Examples:**\n- âœ… GOOD: \"Implement user login API endpoint\"\n- âŒ BAD: \"Write unit tests for login endpoint\"\n- âœ… GOOD: \"Create simple SQLite database schema\"\n- âŒ BAD: \"Set up database connection pooling and optimize query performance\"\n\n**Task Count:**\n- Keep it minimal: 5-12 tasks for simple projects\n- Each task should be clear and focused\n- Avoid creating separate tasks for testing/optimization\n\n# CRITICAL: You MUST complete ALL steps below. Do NOT skip any step!\n\n## Step 1: Load Design (MANDATORY)\n1. Call `get_design()` to read all components\n2. **STOP** if components are empty - report error and exit\n3. (Optional) Call `get_requirements()` for additional context\n4. Analyze design to plan 5-12 **SIMPLE** implementation tasks (core functionality only)\n\n## Step 2: Create Task Draft (MANDATORY)\n3. Write a draft task list in markdown:\n   ```markdown\n   # Implementation Plan Draft (SIMPLE & CORE ONLY)\n\n   ## Tasks (5-12 items - NO testing/optimization tasks)\n   1. TASK-001: [Title - core functionality]\n      - Feature: FEAT-001\n      - Component: COMP-001\n      - Dependencies: []\n      - Files: [actual implementation files ONLY]\n      - Note: Focus on implementing feature, NOT testing/optimizing it\n   ...\n   \n   ## Excluded (DO NOT create tasks for):\n   - Unit tests (unless explicitly in requirements)\n   - Integration tests\n   - Performance optimization\n   - Deployment scripts\n   - Monitoring setup\n   - CI/CD pipelines\n   ```\n   **You MUST create this draft before proceeding!**\n\n## Step 3: User Review (MANDATORY - HITL)\n4. **MUST** call `review_with_feedback_content(title=\"Review Task Plan\", content=<draft>, prompt=\"è¯·å®¡æŸ¥ä»»åŠ¡è®¡åˆ’ï¼šedit ç¼–è¾‘ / pass ç»§ç»­ / æˆ–ç›´æ¥è¾“å…¥ä¿®æ”¹å»ºè®®\")`\n5. Handle response:\n   - action=\"edit\": use returned content\n   - action=\"pass\": keep original\n   - action=\"feedback\": revise and optionally review again (max 1 more time)\n\n## Step 4: Create Formal Tasks (MANDATORY)\n6. For EACH task in finalized draft, **MUST** call `create_task(title, description, feature_id, component_id, dependencies, files_to_create, acceptance_criteria)`\n   **Do NOT skip this step! All tasks must be created!**\n\n## Step 5: Verify (MANDATORY)\n7. Call `get_plan()` to verify all tasks were created\n8. Confirm all tasks exist, then report success\n\n# Tools Available\n- get_requirements() - Load requirements (optional context)\n- get_design() - Load design components (MUST check first)\n- get_plan() - Verify created tasks\n- review_with_feedback_content(title, content, prompt) - Get user feedback\n- create_task(title, description, feature_id, component_id, dependencies, files_to_create, acceptance_criteria) - Create ONE task\n\n# CRITICAL RULES\n1. SIMPLICITY FIRST: Only create tasks for core feature implementation\n2. NO testing tasks (unless explicitly in requirements)\n3. NO optimization tasks (performance, scalability, etc.)\n4. NO deployment/infrastructure tasks (unless explicitly in requirements)\n5. STOP if get_design() returns empty components\n6. You MUST call review_with_feedback_content in Step 3\n7. You MUST call create_task for EACH task\n8. Keep dependencies clean and tasks actionable\n9. Do NOT skip steps or say \"done\" prematurely\n\"#;\n\npub const PLAN_CRITIC_INSTRUCTION: &str = r#\"\n# Your Role  \nYou are Plan Critic. You MUST verify that Plan Actor completed ALL required steps correctly.\n\n# CRITICAL: This is a GATEKEEPER role - you must BLOCK progress if Actor failed!\n\n# SIMPLICITY CHECK - NEW PRIORITY\nBefore other checks, verify that tasks are SIMPLE and focus on CORE implementation:\n- âŒ REJECT if you see: test tasks, optimization tasks, deployment tasks (unless in requirements)\n- âŒ REJECT if tasks include: \"write unit tests\", \"performance tuning\", \"CI/CD setup\"\n- âœ… APPROVE only CORE feature implementation tasks\n\n## Mandatory Checks (You MUST perform ALL of these)\n\n### Check 1: Verify Plan Data Exists\n1. Call `get_plan()` to load all tasks\n2. **FAIL** if tasks array is empty\n3. Expected: 5-12 tasks (CORE implementation only)\n\n### Check 2: Verify SIMPLICITY (NEW - CRITICAL)\n4. For each task, check:\n   - âŒ Does title/description mention \"test\", \"unit test\", \"integration test\"? â†’ REJECT\n   - âŒ Does it mention \"optimize\", \"performance tuning\", \"caching\"? â†’ REJECT\n   - âŒ Does it mention \"deploy\", \"CI/CD\", \"pipeline\", \"docker\"? â†’ REJECT (unless in requirements)\n   - âŒ Does it mention \"monitoring\", \"logging\", \"metrics\"? â†’ REJECT (unless in requirements)\n   - âœ… Does it focus on implementing CORE business logic? â†’ APPROVE\n\n5. If ANY non-core tasks found:\n   - **MUST** call `provide_feedback(feedback_type=\"incomplete\", severity=\"critical\", details=\"Tasks include non-core items: [list them]\", suggested_fix=\"Remove all testing, optimization, deployment tasks. Keep ONLY core feature implementation tasks\")`\n\n### Check 3: Verify Task Dependencies\n6. Call `check_task_dependencies()` to verify:\n   - No circular dependencies\n   - All referenced dependencies exist\n   - Dependency graph is valid\n7. **FAIL** if circular dependencies detected\n\n### Check 4: Verify Feature Coverage\n8. Compare tasks against features from requirements\n9. **FAIL** if any feature has NO tasks assigned\n10. Each feature should have at least 1-3 implementation tasks\n\n### Check 5: Data Quality Assessment\n11. For each task:\n   - Has clear title and description?\n   - Linked to a valid feature_id?\n   - Linked to a valid component_id?\n   - Has files_to_create list (implementation files ONLY, not test files)?\n   - Has acceptance criteria (functional, not performance metrics)?\n12. Dependencies are reasonable (not too many, not circular)?\n\n### Check 6: Implementation Completeness\n13. Tasks cover all components from design?\n14. Task breakdown is granular enough (not too big)?\n15. Task order makes sense (dependencies logical)?\n16. Tasks are SIMPLE and focused on core functionality?\n\n## Response Actions (You MUST follow these rules)\n\n### If ANY check fails:\n1. **MUST** call `provide_feedback(feedback_type=\"missing_data\" or \"incomplete\" or \"circular_dependency\" or \"coverage_gap\", severity=\"critical\", details=\"<what failed>\", suggested_fix=\"<how to fix>\")`\n2. Clearly state what Actor must redo\n3. **DO NOT** give approval\n\n### If all checks pass:\n1. State: \"âœ… Plan verification passed: X CORE implementation tasks created, all Y features covered, dependencies valid\"\n2. State: \"âœ… SIMPLICITY check passed: No testing/optimization/deployment tasks found\"\n3. Summary: List task IDs and their feature/component mappings\n\n# Tools Available\n- get_plan() - Load and verify tasks\n- get_requirements() - Check features context (optional)\n- get_design() - Check components context (optional)\n- check_task_dependencies() - Verify dependency graph\n- provide_feedback(feedback_type, severity, details, suggested_fix) - Report failures\n\n# CRITICAL RULES\n1. SIMPLICITY FIRST: Reject testing/optimization/deployment tasks\n2. You MUST check: tasks data + dependencies + feature coverage + SIMPLICITY\n3. Empty tasks = CRITICAL FAILURE\n4. Circular dependencies = CRITICAL FAILURE\n5. Uncovered features = CRITICAL FAILURE\n6. Non-core tasks (testing/optimization) = CRITICAL FAILURE\n7. You are the LAST line of defense - be strict!\n8. If Actor skipped steps, you MUST catch it and report via provide_feedback\n\n# Example Failure Response - Complexity\n\"âŒ Plan verification FAILED:\n- Found non-core tasks: TASK-005 (Write unit tests), TASK-008 (Performance optimization)\n- These are NOT core feature implementation\n- Expected: ONLY implementation tasks for business logic\n\nCalling provide_feedback to request removal of testing/optimization tasks.\"\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 16.0,
      "lines_of_code": 188,
      "number_of_classes": 0,
      "number_of_functions": 2
    },
    "dependencies": [],
    "detailed_description": "This component serves as an intelligent planning coordinator that implements an Actor-Critic pattern with Human-in-the-Loop (HITL) validation. The Plan Actor creates implementation task lists focused exclusively on core functionality implementation, while the Plan Critic acts as a gatekeeper to verify task quality, simplicity, and adherence to core implementation principles. The system enforces strict rules against including testing, optimization, deployment, or monitoring tasks unless explicitly required.",
    "interfaces": [],
    "responsibilities": [
      "Generate implementation task drafts focusing exclusively on core business logic features",
      "Validate task plans through human review and automated verification",
      "Enforce simplicity principles by rejecting testing/optimization/deployment tasks",
      "Maintain task dependency integrity and feature coverage",
      "Coordinate between design components, requirements, and implementation tasks"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Idea Agent instruction component that handles initial project idea processing in Cowork Forge system",
      "file_path": "crates/cowork-core/src/instructions/idea.rs",
      "functions": [
        "save_idea",
        "review_and_edit_content",
        "load_idea"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "IDEA_AGENT_INSTRUCTION"
      ],
      "name": "idea.rs",
      "source_summary": "// IdeaAgent instruction\n\npub const IDEA_AGENT_INSTRUCTION: &str = r#\"\nYou are the Idea Agent, the first step in the Cowork Forge system.\n\n# Your Role\nYour job is to understand the user's initial idea, save it to `idea.md`, and let the user review/refine it.\n\n# Task Workflow\n1. **Understand** the user's project idea from their input\n2. **Save** a structured summary to session-scoped `idea.md` using `save_idea(content)`\n3. **Let the user review** using `review_and_edit_content(title, content)`\n4. If the user makes changes, acknowledge them\n5. **Finish** - the idea is ready for the PRD team\n\n# Important Rules\n- Do NOT ask questions and wait for answers - the user has provided their initial idea already\n- If the idea is vague, write down what you understand and let the user refine it in the editor\n- After saving idea.md, ALWAYS call review_and_edit_file to let the user review\n- Once the review is complete (whether user edits or not), your job is DONE\n\n# Output Format for idea.md\n\n```markdown\n# Project Idea\n\n## Problem Statement\n[What problem does this solve?]\n\n## Target Users\n[Who will use this?]\n\n## Key Goals\n- Goal 1\n- Goal 2\n- ...\n\n## Initial Thoughts\n[Any additional context or constraints from user's input]\n\n## Technical Considerations\n[Any technical requirements or preferences mentioned]\n\n## Next Steps\nThis idea will be passed to the PRD team for requirement analysis.\n```\n\n# Tools Available\n- `save_idea(content)` - Save session-scoped idea.md\n- `review_and_edit_content(title, content)` - Let user review/edit content and return updated content\n- `load_idea()` - Load idea.md content (if needed)\n\n# Example Workflow\n\nUser input: \"å°å­¦æ™ºèƒ½æ•°å­¦è¯•å·\"\n\nStep 1: Understand this is about an intelligent math exam paper system for elementary school\nStep 2: Write idea.md with structured content based on this input\nStep 3: Call review_and_edit_file to let user refine details\nStep 4: Done - pass to next stage\n\n**Remember**: Do NOT engage in Q&A dialogue. Write what you understand, then let the user edit if needed.\n\"#;\n\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 8.0,
      "lines_of_code": 64,
      "number_of_classes": 0,
      "number_of_functions": 3
    },
    "dependencies": [],
    "detailed_description": "The Idea Agent is the first processing step in the Cowork Forge system responsible for capturing and structuring user project ideas. It provides a comprehensive workflow for understanding user input, saving structured project ideas to idea.md, and facilitating user review/refinement. The component contains detailed instructions for AI agents including role definition, workflow steps, important rules, output format specifications, and available tools. It emphasizes non-interactive processing - understanding the initial idea without Q&A, structuring it according to a predefined markdown template, and passing control to the next stage after user review.",
    "interfaces": [
      {
        "description": "Comprehensive instruction string defining the Idea Agent's behavior and workflow",
        "interface_type": "constant",
        "name": "IDEA_AGENT_INSTRUCTION",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Capture and understand user's initial project idea from input",
      "Structure and save project ideas to session-scoped idea.md file using predefined template",
      "Facilitate user review and refinement of captured ideas through editing interface",
      "Maintain workflow integrity by ensuring proper sequencing and completion criteria",
      "Provide clear documentation and examples for AI agent execution"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Change Triage Agent instruction definition for analyzing modifications",
      "file_path": "crates/cowork-core/src/instructions/modify.rs",
      "functions": [
        "CHANGE_TRIAGE_INSTRUCTION"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "CHANGE_TRIAGE_INSTRUCTION"
      ],
      "name": "modify.rs",
      "source_summary": "// Change Triage Agent Instruction\n//\n// Role: Analyze user's change request and determine the scope of modifications needed\n\npub const CHANGE_TRIAGE_INSTRUCTION: &str = r#\"\n# Role: Change Triage Agent\n\nYou are a **Change Triage Agent** responsible for analyzing user's change requests for an existing project and determining what needs to be modified.\n\n## Your Task\n\nGiven:\n1. **User's Change Request**: What the user wants to add/modify/fix\n2. **Base Session Data**: The current project state (requirements, design, plan, code)\n\nYou need to:\n1. **Analyze the change request** - Understand what the user wants\n2. **Determine scope** - Which parts of the project need to change:\n   - Does PRD need updating? (new requirements)\n   - Does Design need updating? (new components/architecture changes)\n   - Does Plan need updating? (new tasks)\n   - Is it code-only? (just implementation changes)\n3. **Identify affected components** - Which existing components/features are impacted\n4. **Assess risk** - Low/Medium/High based on:\n   - How many files will change\n   - Whether it's a new feature or modifying existing code\n   - Whether it affects core functionality\n5. **Create ChangeRequest** with analysis\n\n## Available Tools\n\nYou have access to:\n- `get_requirements` - Load current requirements and features\n- `get_design` - Load current design spec\n- `get_plan` - Load current implementation plan\n- `list_files` - See what files exist in the project\n- `read_file` - Read specific files to understand current implementation\n\n## Output Requirements\n\nYour MUST create a comprehensive ChangeRequest by saving it. The ChangeRequest should include:\n\n1. **Scope Analysis**:\n   - `requires_prd_update`: true/false\n   - `requires_design_update`: true/false\n   - `requires_plan_update`: true/false\n   - `requires_code_change`: true (almost always)\n\n2. **Impact Analysis**:\n   - `affected_components`: List of component IDs that will change\n   - `affected_features`: List of feature IDs that will be impacted\n   - `risk_level`: \"low\" / \"medium\" / \"high\"\n   - `estimated_effort`: Brief estimate like \"Small (1-2 files)\" or \"Large (5+ files, new components)\"\n\n3. **Acceptance Criteria**: Extract from user's request what defines \"done\"\n\n4. **Constraints**: Things to preserve (e.g., \"Don't break existing user authentication\")\n\n## Guidelines\n\n- **Start small**: If unclear, assume code-only change (don't update PRD/Design unless clearly needed)\n- **Be conservative**: Low risk if it's just adding a small feature\n- **Read existing code**: Use `read_file` to understand current implementation before deciding\n- **Ask clarifying questions** if the change request is ambiguous (via feedback)\n\n## Example Workflow\n\n1. Read user's change request\n2. Load current requirements/design/plan to understand project\n3. Use `list_files` to see project structure\n4. Read relevant files to understand current implementation\n5. Determine scope (code-only? or need PRD update?)\n6. Identify affected components/features\n7. Assess risk based on change size\n8. Save ChangeRequest with all analysis\n\nRemember: You are NOT implementing the change - just analyzing what needs to change.\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 5.0,
      "lines_of_code": 78,
      "number_of_classes": 0,
      "number_of_functions": 1
    },
    "dependencies": [],
    "detailed_description": "This component defines a comprehensive instruction set for a Change Triage Agent that analyzes user change requests and determines modification scope. The agent evaluates what needs to be changed (requirements, design, plan, code), identifies affected components, assesses risk levels, and creates structured ChangeRequest objects. It provides a systematic workflow for change analysis including scope determination, impact assessment, and acceptance criteria extraction.",
    "interfaces": [
      {
        "description": "String constant containing the complete instruction set for the Change Triage Agent",
        "interface_type": "constant",
        "name": "CHANGE_TRIAGE_INSTRUCTION",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Analyze user change requests to understand modification requirements",
      "Determine scope of modifications needed across project artifacts",
      "Identify affected components and assess implementation risk",
      "Create structured ChangeRequest objects with comprehensive analysis",
      "Provide guidance on change triage workflow and best practices"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "PRD (Product Requirements Document) Agent instructions defining Actor and Critic roles for requirements engineering workflow",
      "file_path": "crates/cowork-core/src/instructions/prd.rs",
      "functions": [
        "PRD_ACTOR_INSTRUCTION",
        "PRD_CRITIC_INSTRUCTION"
      ],
      "importance_score": 0.8,
      "interfaces": [],
      "name": "prd.rs",
      "source_summary": "// PRD Agent instructions - Actor and Critic (WITH HITL)\n\npub const PRD_ACTOR_INSTRUCTION: &str = r#\"\n# Your Role\nYou are PRD Actor. You MUST create requirements and features from the idea, get user feedback, and save PRD document.\n\n# CRITICAL PRINCIPLE: SIMPLICITY & CORE FOCUS\n**The project MUST be simple and focus ONLY on core functionality:**\n- âœ… Core business requirements ONLY\n- âœ… Minimum viable features to solve the problem\n- âŒ NO performance optimization requirements\n- âŒ NO testing/CI/CD infrastructure requirements\n- âŒ NO deployment/DevOps requirements unless explicitly requested\n- âŒ NO monitoring/logging/analytics unless critical\n- âŒ NO scalability/high-availability unless explicitly requested\n\n**Examples:**\n- âœ… GOOD: \"User can create, view, edit, delete tasks\"\n- âŒ BAD: \"System must handle 10000 concurrent users with <100ms latency\"\n- âœ… GOOD: \"Save data to local file\"\n- âŒ BAD: \"Implement Redis cache with master-slave replication for high availability\"\n\n# CRITICAL: You MUST complete ALL steps below. Do NOT skip any step!\n\n## Step 1: Load Idea (MANDATORY)\n1. Call `load_idea()` to get the project idea\n2. Analyze the scope and identify 3-6 **CORE** requirements and 2-4 **CORE** features\n3. **Focus ONLY on core functionality** - ignore peripheral features\n\n## Step 2: Create Requirements Draft (MANDATORY)\n3. Write a draft PRD outline in markdown format:\n   ```markdown\n   # Requirements Draft\n   \n   ## Core Requirements (3-6 items - SIMPLE & FOCUSED)\n   1. REQ-001: [Title] - [Brief description of CORE functionality]\n   2. REQ-002: ...\n   \n   Note: Focus on WHAT the system must do, not HOW (no tech details yet)\n   Avoid: performance specs, testing requirements, deployment requirements\n   \n   ## Core Features (2-4 items - MINIMUM VIABLE)\n   1. FEAT-001: [Name] - [Brief description of CORE feature]\n   2. FEAT-002: ...\n   \n   Note: Only features essential to solve the problem\n   ```\n   **You MUST create this draft before proceeding!**\n\n## Step 3: User Review (MANDATORY - HITL)\n4. **MUST** call `review_with_feedback_content(title=\"Review PRD Draft\", content=<your_draft>, prompt=\"è¯·å®¡æŸ¥éœ€æ±‚å¤§çº²ï¼šedit ç¼–è¾‘ / pass ç»§ç»­ / æˆ–ç›´æ¥è¾“å…¥ä¿®æ”¹å»ºè®®\")`\n5. Handle response:\n   - action=\"edit\": use returned content\n   - action=\"pass\": keep original\n   - action=\"feedback\": revise and optionally review again (max 1 more time)\n\n## Step 4: Create Formal Requirements (MANDATORY)\n6. For EACH requirement in finalized draft, **MUST** call `create_requirement(title, description, priority, category, acceptance_criteria)`\n7. For EACH feature in finalized draft, **MUST** call `add_feature(name, description, requirement_ids, completion_criteria)`\n   **Do NOT skip this step! All requirements and features must be created!**\n\n## Step 5: Save PRD Document (MANDATORY)\n8. Generate a complete PRD markdown document including:\n   - Project overview (focus on core value)\n   - All requirements with full details (keep simple)\n   - All features with requirement mappings\n   - Acceptance criteria (functional, not performance)\n9. **MUST** call `save_prd_doc(content=<full_prd_markdown>)`\n   **This is CRITICAL - if you don't save, the PRD will be lost!**\n\n## Step 6: Verify (MANDATORY)\n10. Call `get_requirements()` to verify all data was saved correctly\n11. Confirm you see all requirements and features, then report success\n\n# Tools Available\n- load_idea() - Load project idea\n- review_with_feedback_content(title, content, prompt) - Get user feedback\n- create_requirement(title, description, priority, category, acceptance_criteria) - Create ONE requirement\n- add_feature(name, description, requirement_ids, completion_criteria) - Create ONE feature\n- get_requirements() - Verify created data\n- save_prd_doc(content) - Save PRD markdown document\n\n# CRITICAL RULES\n1. SIMPLICITY FIRST: Keep requirements minimal and focused on core functionality\n2. NO peripheral requirements: testing, performance, deployment, monitoring (unless explicitly in idea)\n3. You MUST call review_with_feedback_content in Step 3\n4. You MUST call create_requirement for EACH requirement\n5. You MUST call add_feature for EACH feature\n6. You MUST call save_prd_doc in Step 5\n7. Do NOT skip steps or say \"done\" prematurely\n\"#;\n\npub const PRD_CRITIC_INSTRUCTION: &str = r#\"\n# Your Role  \nYou are PRD Critic. You MUST verify that PRD Actor completed ALL required steps correctly.\n\n# CRITICAL: This is a GATEKEEPER role - you must BLOCK progress if Actor failed!\n\n# SIMPLICITY CHECK - NEW PRIORITY\nBefore other checks, verify that requirements are SIMPLE and FOCUSED:\n- âŒ REJECT if you see: performance requirements, testing infrastructure, deployment pipelines, monitoring systems\n- âŒ REJECT if requirements are too complex or over-engineered\n- âœ… APPROVE only CORE business functionality requirements\n\n## Mandatory Checks (You MUST perform ALL of these)\n\n### Check 1: Verify Requirements Data Exists\n1. Call `get_requirements()` to load requirements and features\n2. **FAIL** if requirements array is empty\n3. **FAIL** if features array is empty\n4. Expected: 3-6 requirements (CORE only), 2-4 features (MINIMUM VIABLE)\n\n### Check 2: Verify SIMPLICITY (NEW - CRITICAL)\n5. For each requirement, check:\n   - âŒ Does it mention \"performance\", \"scalability\", \"high availability\"? â†’ REJECT\n   - âŒ Does it mention \"testing\", \"CI/CD\", \"deployment pipeline\"? â†’ REJECT\n   - âŒ Does it mention \"monitoring\", \"logging\", \"analytics\" (unless critical)? â†’ REJECT\n   - âœ… Does it focus on CORE user-facing functionality? â†’ APPROVE\n\n6. If ANY non-core requirements found:\n   - **MUST** call `provide_feedback(feedback_type=\"incomplete\", severity=\"critical\", details=\"Requirements include non-core items: [list them]\", suggested_fix=\"Remove all testing, performance, deployment requirements. Focus ONLY on core business functionality\")`\n\n### Check 3: Verify Artifacts Exist\n7. Call `read_file(path=\"artifacts/prd.md\")` to check if PRD markdown was saved\n   - The path is relative to session directory (tools handle session scope automatically)\n8. **FAIL** if prd.md does not exist or is empty\n\n### Check 4: Data Quality Assessment\n9. For each requirement:\n   - Has clear title and description?\n   - Has priority and category?\n   - Has acceptance criteria (FUNCTIONAL, not performance)?\n10. For each feature:\n   - Has clear name and description?\n   - Linked to at least one requirement?\n   - Has completion criteria?\n\n### Check 5: Coverage Analysis\n11. Do requirements cover the CORE project scope from idea.md?\n12. Are features sufficient to implement the requirements?\n13. Is the scope MINIMAL and FOCUSED (not over-designed)?\n\n## Response Actions (You MUST follow these rules)\n\n### If ANY check fails:\n1. **MUST** call `provide_feedback(feedback_type=\"missing_data\" or \"incomplete\", severity=\"critical\", details=\"<what failed>\", suggested_fix=\"<how to fix>\")`\n2. Clearly state what Actor must redo\n3. **DO NOT** give approval\n\n### If all checks pass:\n1. State: \"âœ… PRD verification passed: X CORE requirements and Y MINIMAL features documented in prd.md\"\n2. State: \"âœ… SIMPLICITY check passed: No performance/testing/deployment requirements found\"\n3. Summary: List requirement IDs and feature IDs created\n\n# Tools Available\n- get_requirements() - Load and verify requirements/features data\n- read_file(path) - Verify prd.md exists (use relative path \"artifacts/prd.md\")\n- provide_feedback(feedback_type, severity, details, suggested_fix) - Report failures\n\n# CRITICAL RULES\n1. SIMPLICITY FIRST: Reject complex/peripheral requirements\n2. You MUST check BOTH JSON data AND markdown file\n3. Empty requirements/features = CRITICAL FAILURE\n4. Missing prd.md file = CRITICAL FAILURE\n5. Non-core requirements (testing/performance/deployment) = CRITICAL FAILURE\n6. You are the LAST line of defense - be strict!\n7. If Actor skipped steps, you MUST catch it and report via provide_feedback\n\n# Example Failure Response\n\"âŒ PRD verification FAILED:\n- Found non-core requirements: REQ-003 (performance testing), REQ-005 (CI/CD pipeline)\n- These are NOT core business functionality\n- Expected: ONLY core user-facing features\n\nCalling provide_feedback to request removal of peripheral requirements.\"\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 12.0,
      "lines_of_code": 176,
      "number_of_classes": 0,
      "number_of_functions": 2
    },
    "dependencies": [],
    "detailed_description": "This component implements a Human-in-the-Loop (HITL) PRD creation system with two intelligent agent roles: PRD Actor responsible for creating requirements and features from ideas, and PRD Critic responsible for verification and quality control. The Actor follows a 6-step workflow including idea loading, draft creation, user review, formal requirement creation, documentation saving, and verification. The Critic performs mandatory checks including data existence verification, simplicity validation, artifact verification, data quality assessment, and coverage analysis. The system emphasizes simplicity and core functionality focus, explicitly rejecting performance, testing, deployment, and monitoring requirements unless explicitly requested.",
    "interfaces": [],
    "responsibilities": [
      "Define PRD Actor role workflow and instructions for requirements engineering",
      "Define PRD Critic role verification process and quality gates",
      "Enforce simplicity principle by rejecting non-core requirements",
      "Coordinate Human-in-the-Loop interaction for requirements review",
      "Ensure complete PRD documentation creation and validation"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Intelligent agent responsible for generating comprehensive change reports for incremental modifications in a software project",
      "file_path": "crates/cowork-core/src/instructions/modify_delivery.rs",
      "functions": [
        "generate_change_report",
        "summarize_changes",
        "save_delivery_report"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "MODIFY_DELIVERY_INSTRUCTION"
      ],
      "name": "modify_delivery.rs",
      "source_summary": "// Modify Delivery Agent Instruction\n//\n// Role: Generate change report for incremental modifications\n\npub const MODIFY_DELIVERY_INSTRUCTION: &str = r#\"\n# Role: Modify Delivery Agent\n\nYou are a **Modify Delivery Agent** responsible for generating a comprehensive change report after incremental modifications.\n\n## Your Task\n\nGiven:\n1. **ChangeRequest**: What was requested\n2. **Patch Metadata**: What files were actually changed\n3. **Base Session**: Original project state\n4. **Current Session**: Updated project state\n\nYou need to:\n1. **Summarize changes** - What was added/modified/deleted\n2. **Generate change report** - Document the modifications\n3. **Save the report** as delivery_report.md\n\n## Available Tools\n\nYou have access to:\n- `get_requirements` - Load requirements (if updated)\n- `get_design` - Load design spec (if updated)\n- `get_plan` - Load plan (if updated)\n- `list_files` - See current files\n- `read_file` - Read modified files\n- `load_feedback_history` - Load any feedback during implementation\n- `save_delivery_report` - Save the final change report\n\n## Change Report Format\n\nYour change report should be structured like a **Pull Request description**:\n\n```markdown\n# Change Report: [Brief Title]\n\n## Summary\nBrief description of what changed.\n\n## Change Details\n\n### User Request\n[Original user's change request]\n\n### Implementation\n- **Files Added**: List of new files\n- **Files Modified**: List of modified files  \n- **Files Deleted**: List of deleted files\n\n### Scope Analysis\n- PRD Updated: Yes/No\n- Design Updated: Yes/No\n- Plan Updated: Yes/No\n- Code Changed: Yes/No\n\n## Changes Made\n\n### [Component/Feature Name]\n- What was added\n- What was modified\n- Why it was changed\n\n## Testing\n- Build status: âœ… / âŒ\n- Tests run: Yes/No\n- Manual testing needed: [Instructions if any]\n\n## Notes\n- Any important considerations\n- Breaking changes (if any)\n- Next steps (if any)\n\n## Session Info\n- Base Session: session-xxx\n- Current Session: session-yyy\n- Timestamp: [date]\n```\n\n## Guidelines\n\n- **Clear and concise**: Focus on what actually changed\n- **Developer-friendly**: Write for someone reviewing the changes\n- **Include context**: Explain why changes were made\n- **Highlight risks**: Mention any breaking changes or concerns\n- **Actionable**: Include testing instructions if needed\n\n## Example Workflow\n\n1. Load ChangeRequest to see what was requested\n2. Read Patch Metadata to see what files changed\n3. Read modified files to understand the actual changes\n4. Load feedback history to see if there were issues\n5. Generate comprehensive change report\n6. Save using `save_delivery_report`\n\nRemember: This is a **change report**, not a full project delivery report. Focus on the incremental modifications.\n\"#;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 12.0,
      "lines_of_code": 101,
      "number_of_classes": 0,
      "number_of_functions": 3
    },
    "dependencies": [],
    "detailed_description": "This component is an intelligent agent that serves as a Modify Delivery Agent instruction. Its primary function is to generate comprehensive change reports after incremental modifications to a codebase. The agent takes inputs including change requests, patch metadata, base session state, and current session state, then produces structured change reports in a pull request-like format. It follows a systematic workflow: loading requirements and design specs, analyzing file changes, reading modified files, incorporating feedback history, and generating detailed documentation of modifications including added/modified/deleted files, scope analysis, implementation details, testing status, and session information.",
    "interfaces": [
      {
        "description": "The main instruction string defining the agent's behavior and workflow",
        "interface_type": "constant",
        "name": "MODIFY_DELIVERY_INSTRUCTION",
        "parameters": [],
        "return_type": "string",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Generate comprehensive change reports for incremental code modifications",
      "Analyze and document file-level changes (added/modified/deleted)",
      "Provide scope analysis covering PRD, design, plan, and code changes",
      "Structure change reports in developer-friendly pull request format",
      "Ensure change documentation includes testing instructions and risk assessment"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "entry",
      "description": "Main pipeline orchestration component for Cowork Forge workflow system",
      "file_path": "crates/cowork-core/src/pipeline/mod.rs",
      "functions": [
        "create_cowork_pipeline",
        "create_resume_pipeline",
        "create_partial_pipeline",
        "create_modify_pipeline",
        "create_change_triage_agent",
        "create_code_patch_agent",
        "create_modify_delivery_agent"
      ],
      "importance_score": 0.8,
      "interfaces": [],
      "name": "mod.rs",
      "source_summary": "// Main pipeline - Cowork Forge workflow\n\nuse crate::agents::*;\nuse crate::llm::*;\nuse adk_agent::SequentialAgent;\nuse adk_core::Agent;\nuse anyhow::Result;\nuse std::sync::Arc;\n\n/// Create the main Cowork Forge pipeline for new projects\n/// \n/// This assembles all agents into a sequential workflow:\n/// 1. IdeaAgent - Capture user's idea\n/// 2. PRD Loop - Requirements + Features (Actor-Critic)\n/// 3. Design Loop - Architecture (Actor-Critic)\n/// 4. Plan Loop - Implementation plan (Actor-Critic)\n/// 5. Coding Loop - Code implementation (Actor-Critic)\n/// 6. Check Agent - Quality assurance\n/// 7. Delivery Agent - Final report\npub fn create_cowork_pipeline(config: &ModelConfig, session_id: &str) -> Result<Arc<dyn Agent>> {\n    // Create LLM client\n    let llm = create_llm_client(&config.llm)?;\n\n    // Create all agents with session context\n    let idea_agent = create_idea_agent(llm.clone(), session_id)?;\n    let prd_loop = create_prd_loop(llm.clone(), session_id)?;\n    let design_loop = create_design_loop(llm.clone(), session_id)?;\n    let plan_loop = create_plan_loop(llm.clone(), session_id)?;\n    let coding_loop = create_coding_loop(llm.clone(), session_id)?;\n    let check_agent = create_check_agent(llm.clone(), session_id)?;\n    let delivery_agent = create_delivery_agent(llm, session_id)?;\n\n    // Assemble into SequentialAgent\n    let pipeline = SequentialAgent::new(\n        \"cowork_forge_pipeline\",\n        vec![\n            idea_agent,\n            prd_loop as Arc<dyn Agent>,\n            design_loop as Arc<dyn Agent>,\n            plan_loop as Arc<dyn Agent>,\n            coding_loop as Arc<dyn Agent>,\n            check_agent,\n            delivery_agent,\n        ],\n    );\n\n    Ok(Arc::new(pipeline))\n}\n\n/// Create a resume pipeline (skip Idea stage and completed stages)\n/// \n/// This function determines which stage to resume from by checking\n/// what data files exist in the base session\npub fn create_resume_pipeline(\n    config: &ModelConfig,\n    session_id: &str,\n    base_session_id: &str,\n) -> Result<Arc<dyn Agent>> {\n    use crate::storage::*;\n    \n    let _llm = create_llm_client(&config.llm)?;\n\n    // Determine which stage to start from based on existing data files in base session\n    // NOTE: load_* returns default empty structs when files don't exist, so we must check file existence.\n    // IMPORTANT: Check from the most advanced stage to the earliest to resume from the furthest progress point.\n    let start_stage = if has_code_files(base_session_id)? {\n        // Code files exist â†’ Coding is complete, resume from Check\n        \"check\"\n    } else if has_implementation_plan(base_session_id)?\n        && has_design_spec(base_session_id)?\n        && has_requirements(base_session_id)?\n    {\n        // PRD, Design, Plan exist (but no code files yet) â†’ Resume from Coding\n        \"coding\"\n    } else if has_design_spec(base_session_id)? && has_requirements(base_session_id)? {\n        // PRD, Design exist â†’ Resume from Plan\n        \"plan\"\n    } else if has_requirements(base_session_id)? {\n        // PRD exists â†’ Resume from Design\n        \"design\"\n    } else {\n        // Nothing exists or only idea.md â†’ Start from PRD\n        \"prd\"\n    };\n\n    println!(\"ğŸ“ Resuming from: {} stage\", start_stage);\n\n    // Use create_partial_pipeline to start from the determined stage\n    create_partial_pipeline(config, session_id, base_session_id, start_stage)\n}\n\n/// Create a partial pipeline starting from a specific stage (for revert)\n/// \n/// Useful for:\n/// - Modifying requirements (start from PRD)\n/// - Redesigning architecture (start from Design)\n/// - Replanning (start from Plan)\n/// - Recoding (start from Coding)\npub fn create_partial_pipeline(\n    config: &ModelConfig,\n    session_id: &str,\n    _base_session_id: &str,\n    start_stage: &str,\n) -> Result<Arc<dyn Agent>> {\n    let llm = create_llm_client(&config.llm)?;\n\n    let agents: Vec<Arc<dyn Agent>> = match start_stage {\n        \"prd\" => {\n            vec![\n                create_prd_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_design_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_plan_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_coding_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_check_agent(llm.clone(), session_id)?,\n                create_delivery_agent(llm, session_id)?,\n            ]\n        }\n        \"design\" => {\n            vec![\n                create_design_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_plan_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_coding_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_check_agent(llm.clone(), session_id)?,\n                create_delivery_agent(llm, session_id)?,\n            ]\n        }\n        \"plan\" => {\n            vec![\n                create_plan_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_coding_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_check_agent(llm.clone(), session_id)?,\n                create_delivery_agent(llm, session_id)?,\n            ]\n        }\n        \"coding\" => {\n            vec![\n                create_coding_loop(llm.clone(), session_id)? as Arc<dyn Agent>,\n                create_check_agent(llm.clone(), session_id)?,\n                create_delivery_agent(llm, session_id)?,\n            ]\n        }\n        \"check\" => {\n            vec![\n                create_check_agent(llm.clone(), session_id)?,\n                create_delivery_agent(llm, session_id)?,\n            ]\n        }\n        \"delivery\" => {\n            vec![create_delivery_agent(llm, session_id)?]\n        }\n        _ => {\n            anyhow::bail!(\"Unknown stage: {}. Valid stages: prd, design, plan, coding, check, delivery\", start_stage)\n        }\n    };\n\n    let pipeline = SequentialAgent::new(\n        format!(\"cowork_partial_pipeline_{}\", start_stage),\n        agents,\n    );\n\n    Ok(Arc::new(pipeline))\n}\n\n/// Create a modify pipeline for incremental changes\n/// \n/// This is a new pipeline designed for incremental updates:\n/// 1. Change Triage - Analyze the change and determine scope\n/// 2. Artifact Patch - Update affected artifacts (PRD/Design/Plan as needed)\n/// 3. Code Patch - Generate code changes (patches, not full rewrite)\n/// 4. Check - Verify changes\n/// 5. Delivery - Generate change report\npub fn create_modify_pipeline(\n    config: &ModelConfig,\n    session_id: &str,\n    base_session_id: &str,\n) -> Result<Arc<dyn Agent>> {\n    let llm = create_llm_client(&config.llm)?;\n\n    // For now, create a simplified modify pipeline\n    // TODO: Implement specialized change triage and patch agents\n    let agents: Vec<Arc<dyn Agent>> = vec![\n        create_change_triage_agent(llm.clone(), session_id, base_session_id)?,\n        create_code_patch_agent(llm.clone(), session_id, base_session_id)?,\n        create_check_agent(llm.clone(), session_id)?,\n        create_modify_delivery_agent(llm, session_id, base_session_id)?,\n    ];\n\n    let pipeline = SequentialAgent::new(\n        format!(\"cowork_modify_pipeline_{}\", session_id),\n        agents,\n    );\n\n    Ok(Arc::new(pipeline))\n}\n\n// Placeholder for new modify-specific agents\n// These are now implemented below\nfn create_change_triage_agent(\n    llm: Arc<dyn adk_core::Llm>,\n    session_id: &str,\n    base_session_id: &str,\n) -> Result<Arc<dyn Agent>> {\n    use crate::instructions::CHANGE_TRIAGE_INSTRUCTION;\n    use crate::tools::*;\n    use adk_agent::LlmAgentBuilder;\n    use adk_core::IncludeContents;\n    \n    let session = session_id.to_string();\n    \n    let agent = LlmAgentBuilder::new(\"change_triage_agent\")\n        .instruction(CHANGE_TRIAGE_INSTRUCTION)\n        .model(llm)\n        .tool(Arc::new(GetRequirementsTool::new(base_session_id.to_string())))\n        .tool(Arc::new(GetDesignTool::new(base_session_id.to_string())))\n        .tool(Arc::new(GetPlanTool::new(base_session_id.to_string())))\n        .tool(Arc::new(ListFilesTool))\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(LoadChangeRequestTool::new(session.clone())))\n        .tool(Arc::new(SaveChangeRequestTool::new(session.clone())))\n        .tool(Arc::new(ProvideFeedbackTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n    \n    Ok(Arc::new(agent))\n}\n\nfn create_code_patch_agent(\n    llm: Arc<dyn adk_core::Llm>,\n    session_id: &str,\n    _base_session_id: &str,\n) -> Result<Arc<dyn Agent>> {\n    use crate::instructions::CODE_PATCH_INSTRUCTION;\n    use crate::tools::*;\n    use adk_agent::LlmAgentBuilder;\n    use adk_core::IncludeContents;\n    \n    let session = session_id.to_string();\n    \n    let agent = LlmAgentBuilder::new(\"code_patch_agent\")\n        .instruction(CODE_PATCH_INSTRUCTION)\n        .model(llm)\n        .tool(Arc::new(LoadChangeRequestTool::new(session.clone())))\n        .tool(Arc::new(GetPlanTool::new(session.clone())))\n        .tool(Arc::new(GetDesignTool::new(session.clone())))\n        .tool(Arc::new(ListFilesTool))\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(WriteFileTool))\n        .tool(Arc::new(RunCommandTool))\n        .tool(Arc::new(UpdateTaskStatusTool::new(session.clone())))\n        .tool(Arc::new(UpdateFeatureStatusTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n    \n    Ok(Arc::new(agent))\n}\n\nfn create_modify_delivery_agent(\n    llm: Arc<dyn adk_core::Llm>,\n    session_id: &str,\n    _base_session_id: &str,\n) -> Result<Arc<dyn Agent>> {\n    use crate::instructions::MODIFY_DELIVERY_INSTRUCTION;\n    use crate::tools::*;\n    use adk_agent::LlmAgentBuilder;\n    use adk_core::IncludeContents;\n    \n    let session = session_id.to_string();\n    \n    let agent = LlmAgentBuilder::new(\"modify_delivery_agent\")\n        .instruction(MODIFY_DELIVERY_INSTRUCTION)\n        .model(llm)\n        .tool(Arc::new(LoadChangeRequestTool::new(session.clone())))\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(GetDesignTool::new(session.clone())))\n        .tool(Arc::new(GetPlanTool::new(session.clone())))\n        .tool(Arc::new(ListFilesTool))\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(LoadFeedbackHistoryTool::new(session.clone())))\n        .tool(Arc::new(SaveDeliveryReportTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n    \n    Ok(Arc::new(agent))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_config_loading() {\n        // Test that we can create a config\n        let config = ModelConfig {\n            llm: LlmConfig {\n                api_base_url: \"http://localhost:8000/v1\".to_string(),\n                api_key: \"test-key\".to_string(),\n                model_name: \"gpt-4\".to_string(),\n            },\n        };\n\n        assert_eq!(config.llm.model_name, \"gpt-4\");\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 11.0,
      "lines_of_code": 303,
      "number_of_classes": 0,
      "number_of_functions": 7
    },
    "dependencies": [
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 2,
        "name": "crate::agents::*",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 3,
        "name": "crate::llm::*",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": true,
        "line_number": 4,
        "name": "adk_agent::SequentialAgent",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "trait",
        "is_external": true,
        "line_number": 5,
        "name": "adk_core::Agent",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "type",
        "is_external": true,
        "line_number": 6,
        "name": "anyhow::Result",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "type",
        "is_external": true,
        "line_number": 7,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 51,
        "name": "crate::storage::*",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "constant",
        "is_external": false,
        "line_number": 146,
        "name": "crate::instructions::CHANGE_TRIAGE_INSTRUCTION",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 147,
        "name": "crate::tools::*",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": true,
        "line_number": 148,
        "name": "adk_agent::LlmAgentBuilder",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "enum",
        "is_external": true,
        "line_number": 149,
        "name": "adk_core::IncludeContents",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 154,
        "name": "crate::tools::GetRequirementsTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 155,
        "name": "crate::tools::GetDesignTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 156,
        "name": "crate::tools::GetPlanTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 157,
        "name": "crate::tools::ListFilesTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 158,
        "name": "crate::tools::ReadFileTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 159,
        "name": "crate::tools::LoadChangeRequestTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 160,
        "name": "crate::tools::SaveChangeRequestTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 161,
        "name": "crate::tools::ProvideFeedbackTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "constant",
        "is_external": false,
        "line_number": 170,
        "name": "crate::instructions::CODE_PATCH_INSTRUCTION",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 178,
        "name": "crate::tools::WriteFileTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 179,
        "name": "crate::tools::RunCommandTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 180,
        "name": "crate::tools::UpdateTaskStatusTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 181,
        "name": "crate::tools::UpdateFeatureStatusTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "constant",
        "is_external": false,
        "line_number": 190,
        "name": "crate::instructions::MODIFY_DELIVERY_INSTRUCTION",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 197,
        "name": "crate::tools::LoadFeedbackHistoryTool",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "struct",
        "is_external": false,
        "line_number": 198,
        "name": "crate::tools::SaveDeliveryReportTool",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component serves as the central orchestration module for the Cowork Forge AI development workflow system. It provides multiple pipeline creation functions that assemble different combinations of agents (IdeaAgent, PRD Loop, Design Loop, Plan Loop, Coding Loop, Check Agent, Delivery Agent) into sequential workflows. The module supports full project creation, resuming from specific stages, partial pipelines for modifications, and incremental change pipelines with specialized agents for change triage and code patching.",
    "interfaces": [
      {
        "description": "Create full pipeline for new project development",
        "interface_type": "function",
        "name": "create_cowork_pipeline",
        "parameters": [
          {
            "description": "Model configuration for LLM client",
            "is_optional": false,
            "name": "config",
            "param_type": "&ModelConfig"
          },
          {
            "description": "Current session identifier",
            "is_optional": false,
            "name": "session_id",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<Arc<dyn Agent>>",
        "visibility": "public"
      },
      {
        "description": "Create pipeline resuming from appropriate stage based on existing artifacts",
        "interface_type": "function",
        "name": "create_resume_pipeline",
        "parameters": [
          {
            "description": "Model configuration",
            "is_optional": false,
            "name": "config",
            "param_type": "&ModelConfig"
          },
          {
            "description": "Current session identifier",
            "is_optional": false,
            "name": "session_id",
            "param_type": "&str"
          },
          {
            "description": "Base session to resume from",
            "is_optional": false,
            "name": "base_session_id",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<Arc<dyn Agent>>",
        "visibility": "public"
      },
      {
        "description": "Create pipeline starting from specific stage",
        "interface_type": "function",
        "name": "create_partial_pipeline",
        "parameters": [
          {
            "description": "Model configuration",
            "is_optional": false,
            "name": "config",
            "param_type": "&ModelConfig"
          },
          {
            "description": "Current session identifier",
            "is_optional": false,
            "name": "session_id",
            "param_type": "&str"
          },
          {
            "description": "Base session identifier",
            "is_optional": false,
            "name": "base_session_id",
            "param_type": "&str"
          },
          {
            "description": "Stage to start from",
            "is_optional": false,
            "name": "start_stage",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<Arc<dyn Agent>>",
        "visibility": "public"
      },
      {
        "description": "Create pipeline for incremental modifications",
        "interface_type": "function",
        "name": "create_modify_pipeline",
        "parameters": [
          {
            "description": "Model configuration",
            "is_optional": false,
            "name": "config",
            "param_type": "&ModelConfig"
          },
          {
            "description": "Current session identifier",
            "is_optional": false,
            "name": "session_id",
            "param_type": "&str"
          },
          {
            "description": "Base session identifier",
            "is_optional": false,
            "name": "base_session_id",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<Arc<dyn Agent>>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Orchestrate sequential agent workflows for AI-driven software development",
      "Manage pipeline creation for different workflow scenarios (new project, resume, modify)",
      "Determine appropriate starting points for resumed workflows based on existing artifacts",
      "Provide specialized pipeline configurations for incremental modifications",
      "Handle agent lifecycle and dependency injection"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": "File operation tools with security constraints for the Cowork system",
      "file_path": "crates/cowork-core/src/tools/file_tools.rs",
      "functions": [
        "validate_path_security",
        "should_ignore",
        "is_blocking_service_command",
        "ListFilesTool::name",
        "ListFilesTool::description",
        "ListFilesTool::parameters_schema",
        "ListFilesTool::execute",
        "ReadFileTool::name",
        "ReadFileTool::description",
        "ReadFileTool::parameters_schema",
        "ReadFileTool::execute",
        "WriteFileTool::name",
        "WriteFileTool::description",
        "WriteFileTool::parameters_schema",
        "WriteFileTool::execute",
        "RunCommandTool::name",
        "RunCommandTool::description",
        "RunCommandTool::parameters_schema",
        "RunCommandTool::execute"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "ListFilesTool",
        "ReadFileTool",
        "WriteFileTool",
        "RunCommandTool"
      ],
      "name": "file_tools.rs",
      "source_summary": "// File operation tools with SECURITY constraints\nuse adk_core::{Tool, ToolContext};\nuse async_trait::async_trait;\nuse serde_json::{json, Value};\nuse std::sync::Arc;\nuse std::fs;\nuse std::path::{Path, PathBuf};\nuse walkdir::WalkDir;\n\n// ============================================================================\n// Security Helper - Path Validation\n// ============================================================================\n\n/// Validate that a path is safe to access\n/// Rules:\n/// 1. Must be relative path (no absolute paths like /tmp, C:\\)\n/// 2. Must not escape current directory (no ..)\n/// 3. Must be within current working directory or .cowork\nfn validate_path_security(path: &str) -> Result<PathBuf, String> {\n    let path_obj = Path::new(path);\n    \n    // Rule 1: Reject absolute paths\n    if path_obj.is_absolute() {\n        return Err(format!(\n            \"Security: Absolute paths are not allowed. Path '{}' must be relative to current directory.\",\n            path\n        ));\n    }\n    \n    // Rule 2: Reject parent directory access (..)\n    if path.contains(\"..\") {\n        return Err(format!(\n            \"Security: Parent directory access (..) is not allowed. Path: '{}'\",\n            path\n        ));\n    }\n    \n    // Rule 3: Canonicalize and verify it's within current directory\n    let current_dir = std::env::current_dir()\n        .map_err(|e| format!(\"Failed to get current directory: {}\", e))?;\n    \n    let full_path = current_dir.join(path);\n    \n    // Canonicalize if path exists, otherwise just check the constructed path\n    let canonical_path = if full_path.exists() {\n        full_path.canonicalize()\n            .map_err(|e| format!(\"Failed to resolve path: {}\", e))?\n    } else {\n        // For non-existent paths (e.g., files to be created), just verify parent\n        full_path\n    };\n    \n    // Verify the path is within current directory\n    if !canonical_path.starts_with(&current_dir) {\n        return Err(format!(\n            \"Security: Path escapes current directory. Path '{}' resolves to '{}'\",\n            path,\n            canonical_path.display()\n        ));\n    }\n    \n    Ok(canonical_path)\n}\n\n// ============================================================================\n// ListFilesTool\n// ============================================================================\n\npub struct ListFilesTool;\n\n#[async_trait]\nimpl Tool for ListFilesTool {\n    fn name(&self) -> &str {\n        \"list_files\"\n    }\n\n    fn description(&self) -> &str {\n        \"List files in a directory (recursively or non-recursively). \\\n         SECURITY: Only works within current directory. \\\n         Useful for understanding project structure.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"path\": {\n                    \"type\": \"string\",\n                    \"description\": \"Directory path to list (default: current directory). Must be relative path.\"\n                },\n                \"recursive\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether to list files recursively (default: false)\"\n                },\n                \"max_depth\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum depth for recursive listing (default: 3)\"\n                }\n            }\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let path = args.get(\"path\")\n            .and_then(|v| v.as_str())\n            .unwrap_or(\".\");\n        \n        // Security check\n        let safe_path = match validate_path_security(path) {\n            Ok(p) => p,\n            Err(e) => {\n                return Ok(json!({\n                    \"status\": \"security_error\",\n                    \"message\": e\n                }));\n            }\n        };\n        \n        let recursive = args.get(\"recursive\")\n            .and_then(|v| v.as_bool())\n            .unwrap_or(false);\n        \n        let max_depth = args.get(\"max_depth\")\n            .and_then(|v| v.as_u64())\n            .unwrap_or(3) as usize;\n\n        if !safe_path.exists() {\n            return Ok(json!({\n                \"status\": \"error\",\n                \"message\": format!(\"Path not found: {}\", path)\n            }));\n        }\n\n        let mut files = Vec::new();\n        let mut directories = Vec::new();\n\n        if recursive {\n            // Recursive listing with max depth\n            let cwd = std::env::current_dir()\n                .map_err(|e| adk_core::AdkError::Tool(format!(\"Failed to get current dir: {}\", e)))?;\n\n            for entry in WalkDir::new(&safe_path)\n                .max_depth(max_depth)\n                .follow_links(false)\n                .into_iter()\n                .filter_entry(|e| {\n                    // Prune hidden directories early (except the root itself)\n                    if let Some(name) = e.file_name().to_str() {\n                        if name.starts_with('.') && name != \".\" {\n                            return false;\n                        }\n                    }\n                    true\n                })\n                .filter_map(|e| e.ok())\n            {\n                // Convert to relative path for stable ignore matching\n                let rel = entry.path().strip_prefix(&cwd).unwrap_or(entry.path());\n                let rel_str = rel.to_string_lossy();\n                let path_str = format!(\"./{}\", rel_str.trim_start_matches(\"./\"));\n\n                // Skip hidden files and common ignore patterns\n                if should_ignore(&path_str) {\n                    continue;\n                }\n\n                if entry.file_type().is_dir() {\n                    directories.push(path_str);\n                } else {\n                    files.push(path_str);\n                }\n            }\n        } else {\n            // Non-recursive listing\n            let cwd = std::env::current_dir()\n                .map_err(|e| adk_core::AdkError::Tool(format!(\"Failed to get current dir: {}\", e)))?;\n\n            let entries = fs::read_dir(&safe_path)\n                .map_err(|e| adk_core::AdkError::Tool(format!(\"Failed to read directory: {}\", e)))?;\n\n            for entry in entries {\n                let entry = entry.map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n                // Skip hidden at top-level\n                if let Some(name) = entry.file_name().to_str() {\n                    if name.starts_with('.') {\n                        continue;\n                    }\n                }\n\n                let full = entry.path().to_path_buf();\n                let rel = full.strip_prefix(&cwd).unwrap_or(&full);\n                let rel_str = rel.to_string_lossy();\n                let path_str = format!(\"./{}\", rel_str.trim_start_matches(\"./\"));\n\n                if should_ignore(&path_str) {\n                    continue;\n                }\n\n                if entry.file_type().map(|ft| ft.is_dir()).unwrap_or(false) {\n                    directories.push(path_str);\n                } else {\n                    files.push(path_str);\n                }\n            }\n        }\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"path\": path,\n            \"files\": files,\n            \"directories\": directories,\n            \"total_files\": files.len(),\n            \"total_directories\": directories.len()\n        }))\n    }\n}\n\nfn should_ignore(path: &str) -> bool {\n    // Normalize: we mostly work with \"./...\" relative paths now\n\n    // 1) Hide dotfiles / dot-directories broadly\n    // (We still keep root path \".\" out of this function; callers handle it)\n    if let Some(name) = Path::new(path).file_name().and_then(|n| n.to_str()) {\n        if name.starts_with('.') {\n            return true;\n        }\n    }\n\n    // 2) Common ignore patterns\n    let ignore_patterns = [\n        \"./.git\", \"./target\", \"./node_modules\", \"./.cowork\", \"./.litho\",\n        \"./.idea\", \"./.vscode\", \"./dist\", \"./build\", \"./docs\", \"./tests\",\n        \"__tests__\", \"./.archived\",\n        \".DS_Store\", \"Thumbs.db\",\n    ];\n\n    ignore_patterns.iter().any(|pattern| path.contains(pattern))\n}\n\n// ============================================================================\n// ReadFileTool\n// ============================================================================\n\npub struct ReadFileTool;\n\n#[async_trait]\nimpl Tool for ReadFileTool {\n    fn name(&self) -> &str {\n        \"read_file\"\n    }\n\n    fn description(&self) -> &str {\n        \"Read the contents of a file. \\\n         SECURITY: Only works within current directory.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"path\": {\n                    \"type\": \"string\",\n                    \"description\": \"File path to read (must be relative path within current directory)\"\n                }\n            },\n            \"required\": [\"path\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let path = args[\"path\"].as_str().unwrap();\n\n        // Security check\n        let safe_path = match validate_path_security(path) {\n            Ok(p) => p,\n            Err(e) => {\n                return Ok(json!({\n                    \"status\": \"security_error\",\n                    \"message\": e\n                }));\n            }\n        };\n\n        if !safe_path.exists() {\n            return Ok(json!({\n                \"status\": \"error\",\n                \"message\": format!(\"File not found: {}\", path)\n            }));\n        }\n        \n        match fs::read_to_string(&safe_path) {\n            Ok(content) => Ok(json!({\n                \"status\": \"success\",\n                \"path\": path,\n                \"content\": content\n            })),\n            Err(e) => Ok(json!({\n                \"status\": \"error\",\n                \"message\": format!(\"Failed to read file: {}\", e)\n            })),\n        }\n    }\n}\n\n// ============================================================================\n// WriteFileTool\n// ============================================================================\n\npub struct WriteFileTool;\n\n#[async_trait]\nimpl Tool for WriteFileTool {\n    fn name(&self) -> &str {\n        \"write_file\"\n    }\n\n    fn description(&self) -> &str {\n        \"Write content to a file. Creates parent directories if needed. \\\n         SECURITY: Only works within current directory. Absolute paths and .. are forbidden.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"path\": {\n                    \"type\": \"string\",\n                    \"description\": \"File path to write (must be relative path within current directory)\"\n                },\n                \"content\": {\n                    \"type\": \"string\",\n                    \"description\": \"Content to write\"\n                }\n            },\n            \"required\": [\"path\", \"content\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let path = args[\"path\"].as_str().unwrap();\n        let content = args[\"content\"].as_str().unwrap();\n\n        // Security check\n        let safe_path = match validate_path_security(path) {\n            Ok(p) => p,\n            Err(e) => {\n                return Ok(json!({\n                    \"status\": \"security_error\",\n                    \"message\": e\n                }));\n            }\n        };\n\n        // Create parent directories if needed\n        if let Some(parent) = safe_path.parent() {\n            fs::create_dir_all(parent).map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n        }\n\n        match fs::write(&safe_path, content) {\n            Ok(_) => {\n                // Log file creation for user visibility\n                println!(\"ğŸ“ Writing file: {} ({} lines)\", path, content.lines().count());\n                Ok(json!({\n                    \"status\": \"success\",\n                    \"path\": path,\n                    \"lines_written\": content.lines().count()\n                }))\n            },\n            Err(e) => Ok(json!({\n                \"status\": \"error\",\n                \"message\": format!(\"Failed to write file: {}\", e)\n            })),\n        }\n    }\n}\n\n// ============================================================================\n// RunCommandTool with blocking detection\n// ============================================================================\n\npub struct RunCommandTool;\n\n/// Detect if a command is a long-running service that would block execution\nfn is_blocking_service_command(command: &str) -> bool {\n    let blocking_patterns = vec![\n        \"http.server\",      // python -m http.server\n        \"npm run dev\",      // npm dev server\n        \"npm start\",        // npm start\n        \"yarn dev\",\n        \"yarn start\",\n        \"pnpm dev\",\n        \"pnpm start\",\n        \"uvicorn\",          // Python ASGI server\n        \"gunicorn\",         // Python WSGI server\n        \"flask run\",\n        \"django runserver\",\n        \"rails server\",\n        \"cargo run\",        // Might be a server\n        \"serve\",            // serve package\n        \"webpack-dev-server\",\n        \"vite\",\n        \"next dev\",\n    ];\n\n    blocking_patterns.iter().any(|pattern| command.contains(pattern))\n}\n\n#[async_trait]\nimpl Tool for RunCommandTool {\n    fn name(&self) -> &str {\n        \"run_command\"\n    }\n\n    fn description(&self) -> &str {\n        \"Execute a shell command and return the output. \\\n         WARNING: This tool will REJECT commands that start long-running services \\\n         (like http.server, npm dev, etc.) as they would block execution. \\\n         Use this for: building, testing, linting - NOT for starting servers.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"command\": {\n                    \"type\": \"string\",\n                    \"description\": \"Shell command to execute (must not be a blocking service command)\"\n                }\n            },\n            \"required\": [\"command\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let command = args[\"command\"].as_str().unwrap();\n\n        // Check if command would block\n        if is_blocking_service_command(command) {\n            return Ok(json!({\n                \"status\": \"rejected\",\n                \"message\": format!(\n                    \"BLOCKED: This command appears to start a long-running service: '{}'. \\\n                     Starting services would block the agent. \\\n                     If you need to verify the code works, just create the files - don't start servers.\",\n                    command\n                )\n            }));\n        }\n\n        // Execute command with timeout\n        let output = tokio::time::timeout(\n            std::time::Duration::from_secs(30),\n            tokio::process::Command::new(\"sh\")\n                .arg(\"-c\")\n                .arg(command)\n                .current_dir(std::env::current_dir().unwrap()) // Run in current dir\n                .output()\n        )\n        .await;\n\n        match output {\n            Ok(Ok(output)) => {\n                let stdout = String::from_utf8_lossy(&output.stdout).to_string();\n                let stderr = String::from_utf8_lossy(&output.stderr).to_string();\n\n                Ok(json!({\n                    \"status\": if output.status.success() { \"success\" } else { \"failed\" },\n                    \"exit_code\": output.status.code(),\n                    \"stdout\": stdout,\n                    \"stderr\": stderr\n                }))\n            }\n            Ok(Err(e)) => {\n                Ok(json!({\n                    \"status\": \"error\",\n                    \"message\": format!(\"Failed to execute command: {}\", e)\n                }))\n            }\n            Err(_) => {\n                Ok(json!({\n                    \"status\": \"timeout\",\n                    \"message\": \"Command execution timeout (30s limit)\"\n                }))\n            }\n        }\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 43.0,
      "lines_of_code": 488,
      "number_of_classes": 4,
      "number_of_functions": 19
    },
    "dependencies": [
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 3,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 4,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 5,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 6,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 7,
        "name": "std::fs",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 8,
        "name": "std::path",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 9,
        "name": "walkdir",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component provides secure file system operations and command execution capabilities for the Cowork system. It implements security constraints to prevent directory traversal attacks by validating all paths are relative and within the current working directory. The component includes four main tools: ListFilesTool for directory listing (recursive/non-recursive), ReadFileTool for file reading, WriteFileTool for file writing with automatic directory creation, and RunCommandTool for safe command execution with blocking service detection. Security is a core focus, with path validation, hidden file filtering, and command blocking for long-running services.",
    "interfaces": [
      {
        "description": "Tool for listing files in directories with security constraints",
        "interface_type": "struct",
        "name": "ListFilesTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Tool for reading file contents with path validation",
        "interface_type": "struct",
        "name": "ReadFileTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Tool for writing files with automatic directory creation",
        "interface_type": "struct",
        "name": "WriteFileTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Tool for executing commands with blocking service detection",
        "interface_type": "struct",
        "name": "RunCommandTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Validates path security according to security rules",
        "interface_type": "function",
        "name": "validate_path_security",
        "parameters": [
          {
            "description": "Path to validate for security",
            "is_optional": false,
            "name": "path",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<PathBuf, String>",
        "visibility": "private"
      },
      {
        "description": "Determines if a path should be ignored based on patterns",
        "interface_type": "function",
        "name": "should_ignore",
        "parameters": [
          {
            "description": "Path to check against ignore patterns",
            "is_optional": false,
            "name": "path",
            "param_type": "&str"
          }
        ],
        "return_type": "bool",
        "visibility": "private"
      },
      {
        "description": "Detects if a command is a long-running blocking service",
        "interface_type": "function",
        "name": "is_blocking_service_command",
        "parameters": [
          {
            "description": "Command to check for blocking patterns",
            "is_optional": false,
            "name": "command",
            "param_type": "&str"
          }
        ],
        "return_type": "bool",
        "visibility": "private"
      }
    ],
    "responsibilities": [
      "Secure file system operations with path validation and access control",
      "Directory and file listing with recursive capabilities and security constraints",
      "File content reading and writing with automatic directory creation",
      "Safe command execution with blocking service detection and timeout protection",
      "Security policy enforcement including hidden file filtering and path traversal prevention"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": "Validation tools for checking data quality (Session-scoped)",
      "file_path": "crates/cowork-core/src/tools/validation_tools.rs",
      "functions": [
        "check_data_format",
        "check_feature_coverage",
        "check_task_dependencies",
        "validate_requirements_schema",
        "validate_features_schema",
        "validate_design_schema",
        "validate_plan_schema",
        "detect_cycle"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "CheckDataFormatTool",
        "CheckFeatureCoverageTool",
        "CheckTaskDependenciesTool"
      ],
      "name": "validation_tools.rs",
      "source_summary": "// Validation tools for checking data quality (Session-scoped)\nuse crate::storage::*;\nuse adk_core::{Tool, ToolContext};\n\nuse async_trait::async_trait;\nuse serde_json::{json, Value};\nuse std::sync::Arc;\n\n// ============================================================================\n// CheckDataFormatTool\n// ============================================================================\n\npub struct CheckDataFormatTool {\n    session_id: String,\n}\n\nimpl CheckDataFormatTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for CheckDataFormatTool {\n    fn name(&self) -> &str {\n        \"check_data_format\"\n    }\n\n    fn description(&self) -> &str {\n        \"Validate that a JSON data file conforms to its schema. Returns validation errors if any.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"data_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"requirements\", \"features\", \"design\", \"plan\"],\n                    \"description\": \"Which data file to validate\"\n                }\n            },\n            \"required\": [\"data_type\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let data_type = args[\"data_type\"].as_str().unwrap();\n\n        let errors = match data_type {\n            \"requirements\" => self.validate_requirements_schema(),\n            \"features\" => self.validate_features_schema(),\n            \"design\" => self.validate_design_schema(),\n            \"plan\" => self.validate_plan_schema(),\n            _ => return Ok(json!({\"status\": \"error\", \"message\": \"Unknown data type\"})),\n        };\n\n        if errors.is_empty() {\n            Ok(json!({\n                \"status\": \"valid\",\n                \"message\": format!(\"{} data is valid\", data_type)\n            }))\n        } else {\n            Ok(json!({\n                \"status\": \"invalid\",\n                \"errors\": errors\n            }))\n        }\n    }\n}\n\nimpl CheckDataFormatTool {\n    fn validate_requirements_schema(&self) -> Vec<String> {\n        let mut errors = vec![];\n        match load_requirements(&self.session_id) {\n            Ok(requirements) => {\n                for req in &requirements.requirements {\n                    if req.title.is_empty() {\n                        errors.push(format!(\"{}: title is empty\", req.id));\n                    }\n                    if req.acceptance_criteria.is_empty() {\n                        errors.push(format!(\"{}: missing acceptance criteria\", req.id));\n                    }\n                }\n            }\n            Err(e) => errors.push(format!(\"Failed to load requirements: {}\", e)),\n        }\n        errors\n    }\n\n    fn validate_features_schema(&self) -> Vec<String> {\n        let mut errors = vec![];\n        match load_feature_list(&self.session_id) {\n            Ok(features) => {\n                for feat in &features.features {\n                    if feat.name.is_empty() {\n                        errors.push(format!(\"{}: name is empty\", feat.id));\n                    }\n                    if feat.requirement_ids.is_empty() {\n                        errors.push(format!(\"{}: not linked to any requirement\", feat.id));\n                    }\n                }\n            }\n            Err(e) => errors.push(format!(\"Failed to load features: {}\", e)),\n        }\n        errors\n    }\n\n    fn validate_design_schema(&self) -> Vec<String> {\n        let mut errors = vec![];\n        match load_design_spec(&self.session_id) {\n            Ok(design) => {\n                if design.architecture.components.is_empty() {\n                    errors.push(\"No components defined\".to_string());\n                }\n            }\n            Err(e) => errors.push(format!(\"Failed to load design: {}\", e)),\n        }\n        errors\n    }\n\n    fn validate_plan_schema(&self) -> Vec<String> {\n        let mut errors = vec![];\n        match load_implementation_plan(&self.session_id) {\n            Ok(plan) => {\n                if plan.tasks.is_empty() {\n                    errors.push(\"No tasks defined\".to_string());\n                }\n            }\n            Err(e) => errors.push(format!(\"Failed to load plan: {}\", e)),\n        }\n        errors\n    }\n}\n\n// ============================================================================\n// CheckFeatureCoverageTool\n// ============================================================================\n\npub struct CheckFeatureCoverageTool {\n    session_id: String,\n}\n\nimpl CheckFeatureCoverageTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for CheckFeatureCoverageTool {\n    fn name(&self) -> &str {\n        \"check_feature_coverage\"\n    }\n\n    fn description(&self) -> &str {\n        \"Check if all features are covered by design components.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\"type\": \"object\", \"properties\": {}}))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, _args: Value) -> adk_core::Result<Value> {\n        let features = load_feature_list(&self.session_id).map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n        let design = load_design_spec(&self.session_id).map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        let uncovered: Vec<String> = features\n            .features\n            .iter()\n            .filter(|f| {\n                !design\n                    .architecture\n                    .components\n                    .iter()\n                    .any(|c| c.related_features.contains(&f.id))\n            })\n            .map(|f| f.id.clone())\n            .collect();\n\n        if uncovered.is_empty() {\n            Ok(json!({\n                \"status\": \"full_coverage\",\n                \"message\": \"All features are covered by components\"\n            }))\n        } else {\n            Ok(json!({\n                \"status\": \"incomplete_coverage\",\n                \"uncovered_features\": uncovered,\n                \"message\": format!(\"{} features are not covered\", uncovered.len())\n            }))\n        }\n    }\n}\n\n// ============================================================================\n// CheckTaskDependenciesTool\n// ============================================================================\n\npub struct CheckTaskDependenciesTool {\n    session_id: String,\n}\n\nimpl CheckTaskDependenciesTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for CheckTaskDependenciesTool {\n    fn name(&self) -> &str {\n        \"check_task_dependencies\"\n    }\n\n    fn description(&self) -> &str {\n        \"Analyze task dependencies to detect circular dependencies.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\"type\": \"object\", \"properties\": {}}))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, _args: Value) -> adk_core::Result<Value> {\n        let plan = load_implementation_plan(&self.session_id).map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        // Build dependency graph\n        let mut graph: std::collections::HashMap<String, Vec<String>> =\n            std::collections::HashMap::new();\n        for task in &plan.tasks {\n            graph.insert(task.id.clone(), task.dependencies.clone());\n        }\n\n        // Detect cycles using DFS\n        let has_cycles = detect_cycle(&graph);\n\n        if has_cycles {\n            Ok(json!({\n                \"status\": \"invalid\",\n                \"message\": \"Circular dependencies detected in task graph\"\n            }))\n        } else {\n            Ok(json!({\n                \"status\": \"valid\",\n                \"message\": \"No circular dependencies detected\"\n            }))\n        }\n    }\n}\n\n/// Detect cycles in dependency graph using DFS\nfn detect_cycle(graph: &std::collections::HashMap<String, Vec<String>>) -> bool {\n    use std::collections::HashSet;\n\n    let mut visited = HashSet::new();\n    let mut rec_stack = HashSet::new();\n\n    fn dfs(\n        node: &str,\n        graph: &std::collections::HashMap<String, Vec<String>>,\n        visited: &mut HashSet<String>,\n        rec_stack: &mut HashSet<String>,\n    ) -> bool {\n        visited.insert(node.to_string());\n        rec_stack.insert(node.to_string());\n\n        if let Some(neighbors) = graph.get(node) {\n            for neighbor in neighbors {\n                if !visited.contains(neighbor) {\n                    if dfs(neighbor, graph, visited, rec_stack) {\n                        return true;\n                    }\n                } else if rec_stack.contains(neighbor) {\n                    return true; // Cycle detected\n                }\n            }\n        }\n\n        rec_stack.remove(node);\n        false\n    }\n\n    for node in graph.keys() {\n        if !visited.contains(node) {\n            if dfs(node, graph, &mut visited, &mut rec_stack) {\n                return true;\n            }\n        }\n    }\n\n    false\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 32.0,
      "lines_of_code": 292,
      "number_of_classes": 3,
      "number_of_functions": 8
    },
    "dependencies": [
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 2,
        "name": "crate::storage",
        "path": "crates/cowork-core/src/storage",
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 3,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 5,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 6,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 7,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 139,
        "name": "std::collections",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component provides a suite of validation tools for software development data quality assurance. It contains three main tools: 1) CheckDataFormatTool - validates JSON data files against schema requirements for requirements, features, design, and plan data types; 2) CheckFeatureCoverageTool - ensures all features are covered by design components; 3) CheckTaskDependenciesTool - analyzes task dependencies to detect circular dependencies using DFS algorithm. The tools operate within session scope and provide comprehensive validation for software development artifacts.",
    "interfaces": [
      {
        "description": "Tool for validating JSON data files against schema requirements",
        "interface_type": "struct",
        "name": "CheckDataFormatTool",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "session_id",
            "param_type": "String"
          }
        ],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Tool for checking feature coverage by design components",
        "interface_type": "struct",
        "name": "CheckFeatureCoverageTool",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "session_id",
            "param_type": "String"
          }
        ],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Tool for detecting circular dependencies in task graphs",
        "interface_type": "struct",
        "name": "CheckTaskDependenciesTool",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "session_id",
            "param_type": "String"
          }
        ],
        "return_type": null,
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Data format validation for software development artifacts",
      "Feature-to-component coverage analysis",
      "Task dependency graph cycle detection",
      "Session-scoped data quality assurance",
      "Error reporting and validation feedback"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": "HITL (Human-in-the-Loop) content review and editing tools for markdown content interaction",
      "file_path": "crates/cowork-core/src/tools/hitl_content_tools.rs",
      "functions": [
        "review_and_edit_content",
        "review_with_feedback_content"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "ReviewAndEditContentTool",
        "ReviewWithFeedbackContentTool"
      ],
      "name": "hitl_content_tools.rs",
      "source_summary": "// HITL tools (content-based) to avoid hardcoding artifact file paths\nuse adk_core::{Tool, ToolContext};\nuse async_trait::async_trait;\nuse dialoguer::{Editor, Input};\nuse serde_json::{json, Value};\nuse std::sync::Arc;\n\n/// review_and_edit_content\n/// - Takes content as input\n/// - Optionally lets user edit in editor\n/// - Returns edited content\npub struct ReviewAndEditContentTool;\n\n#[async_trait]\nimpl Tool for ReviewAndEditContentTool {\n    fn name(&self) -> &str {\n        \"review_and_edit_content\"\n    }\n\n    fn description(&self) -> &str {\n        \"Let the user review and optionally edit markdown content using their default editor. Returns edited content.\" \n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"title\": {\"type\": \"string\", \"description\": \"Title shown to user\"},\n                \"content\": {\"type\": \"string\", \"description\": \"Content to review/edit\"}\n            },\n            \"required\": [\"title\", \"content\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let title = args[\"title\"].as_str().unwrap();\n        let content = args[\"content\"].as_str().unwrap();\n\n        println!(\"\\nğŸ“ {}\", title);\n        println!(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\");\n        for (i, line) in content.lines().take(12).enumerate() {\n            println!(\"  {}: {}\", i + 1, line);\n        }\n        let line_count = content.lines().count();\n        if line_count > 12 {\n            println!(\"  ... ({} more lines)\", line_count - 12);\n        }\n        println!(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\");\n\n        let input: String = Input::new()\n            .with_prompt(\"è¾“å…¥ 'edit' æ‰“å¼€ç¼–è¾‘å™¨ï¼Œæˆ–ç›´æ¥å›è½¦è·³è¿‡\")\n            .allow_empty(true)\n            .interact_text()\n            .map_err(|e| adk_core::AdkError::Tool(format!(\"Interaction error: {}\", e)))?;\n\n        if input.trim().to_lowercase() != \"edit\" {\n            return Ok(json!({\n                \"action\": \"pass\",\n                \"content\": content,\n                \"message\": \"User skipped editing\"\n            }));\n        }\n\n        println!(\"ğŸ“ Opening editor... (Save and close to submit changes)\");\n        let edited = Editor::new()\n            .require_save(true)\n            .edit(content)\n            .map_err(|e| adk_core::AdkError::Tool(format!(\"Editor error: {}\", e)))?;\n\n        let new_content = edited.unwrap_or_else(|| content.to_string());\n\n        Ok(json!({\n            \"action\": \"edit\",\n            \"content\": new_content,\n            \"message\": \"Content edited\"\n        }))\n    }\n}\n\n/// review_with_feedback_content\n/// - Takes content as input\n/// - Allows edit/pass/feedback\n/// - Returns edited content OR feedback text\npub struct ReviewWithFeedbackContentTool;\n\n#[async_trait]\nimpl Tool for ReviewWithFeedbackContentTool {\n    fn name(&self) -> &str {\n        \"review_with_feedback_content\"\n    }\n\n    fn description(&self) -> &str {\n        \"Review content and allow user to: edit in editor, pass, or provide feedback text.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"title\": {\"type\": \"string\"},\n                \"content\": {\"type\": \"string\"},\n                \"prompt\": {\"type\": \"string\"}\n            },\n            \"required\": [\"title\", \"content\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let title = args[\"title\"].as_str().unwrap();\n        let content = args[\"content\"].as_str().unwrap();\n        let default_prompt = \"è¾“å…¥ 'edit' ç¼–è¾‘ï¼Œ'pass' ç»§ç»­ï¼Œæˆ–ç›´æ¥è¾“å…¥ä¿®æ”¹å»ºè®®\";\n        let prompt = args.get(\"prompt\").and_then(|v| v.as_str()).unwrap_or(default_prompt);\n\n        println!(\"\\nğŸ“ {}\", title);\n        println!(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\");\n        for (i, line) in content.lines().take(15).enumerate() {\n            println!(\"  {}: {}\", i + 1, line);\n        }\n        let line_count = content.lines().count();\n        if line_count > 15 {\n            println!(\"  ... ({} more lines)\", line_count - 15);\n        }\n        println!(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\");\n\n        let user_input: String = Input::new()\n            .with_prompt(prompt)\n            .allow_empty(true)\n            .interact_text()\n            .map_err(|e| adk_core::AdkError::Tool(format!(\"Interaction error: {}\", e)))?;\n\n        let trimmed = user_input.trim();\n\n        match trimmed.to_lowercase().as_str() {\n            \"edit\" => {\n                println!(\"ğŸ“ Opening editor... (Save and close to submit changes)\");\n                let edited = Editor::new()\n                    .require_save(true)\n                    .edit(content)\n                    .map_err(|e| adk_core::AdkError::Tool(format!(\"Editor error: {}\", e)))?;\n\n                let new_content = edited.unwrap_or_else(|| content.to_string());\n                Ok(json!({\n                    \"action\": \"edit\",\n                    \"content\": new_content,\n                    \"message\": \"User edited content\"\n                }))\n            }\n            \"pass\" | \"\" => Ok(json!({\n                \"action\": \"pass\",\n                \"content\": content,\n                \"message\": \"User passed\"\n            })),\n            _ => Ok(json!({\n                \"action\": \"feedback\",\n                \"feedback\": trimmed,\n                \"content\": content,\n                \"message\": \"User provided feedback\"\n            })),\n        }\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 9.0,
      "lines_of_code": 161,
      "number_of_classes": 2,
      "number_of_functions": 2
    },
    "dependencies": [
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 2,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 3,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 4,
        "name": "dialoguer",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 5,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 6,
        "name": "std",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component provides two HITL (Human-in-the-Loop) tools for content review and editing workflows. The ReviewAndEditContentTool allows users to review markdown content and optionally edit it using their default text editor. The ReviewWithFeedbackContentTool extends this functionality by providing three interaction modes: edit content in editor, pass without changes, or provide feedback text. Both tools implement the Tool trait interface and provide interactive command-line interfaces for user interaction.",
    "interfaces": [
      {
        "description": "Tool for reviewing and optionally editing content",
        "interface_type": "struct",
        "name": "ReviewAndEditContentTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Returns tool name",
        "interface_type": "method",
        "name": "name",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns tool description",
        "interface_type": "method",
        "name": "description",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns JSON schema for tool parameters",
        "interface_type": "method",
        "name": "parameters_schema",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "Option<Value>",
        "visibility": "public"
      },
      {
        "description": "Executes the tool with given arguments",
        "interface_type": "method",
        "name": "execute",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          },
          {
            "description": "Tool execution context",
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": "Tool arguments",
            "is_optional": false,
            "name": "args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      },
      {
        "description": "Tool for reviewing content with edit/pass/feedback options",
        "interface_type": "struct",
        "name": "ReviewWithFeedbackContentTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Returns tool name",
        "interface_type": "method",
        "name": "name",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns tool description",
        "interface_type": "method",
        "name": "description",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns JSON schema for tool parameters",
        "interface_type": "method",
        "name": "parameters_schema",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "Option<Value>",
        "visibility": "public"
      },
      {
        "description": "Executes the tool with given arguments",
        "interface_type": "method",
        "name": "execute",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          },
          {
            "description": "Tool execution context",
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": "Tool arguments",
            "is_optional": false,
            "name": "args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Provide interactive content review interface for HITL workflows",
      "Enable content editing through external text editor integration",
      "Support multiple interaction modes (edit/pass/feedback) for content review",
      "Handle content display and user input processing",
      "Manage error handling and user interaction flows"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": "Session-scoped idea artifact tools for saving and loading idea.md files",
      "file_path": "crates/cowork-core/src/tools/idea_tools.rs",
      "functions": [
        "save_idea",
        "load_idea"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "SaveIdeaTool::new",
        "SaveIdeaTool::name",
        "SaveIdeaTool::description",
        "SaveIdeaTool::parameters_schema",
        "SaveIdeaTool::execute",
        "LoadIdeaTool::new",
        "LoadIdeaTool::name",
        "LoadIdeaTool::description",
        "LoadIdeaTool::parameters_schema",
        "LoadIdeaTool::execute"
      ],
      "name": "idea_tools.rs",
      "source_summary": "// Idea artifact tools (Session-scoped)\nuse crate::storage::*;\nuse adk_core::{Tool, ToolContext};\nuse async_trait::async_trait;\nuse serde_json::{json, Value};\nuse std::sync::Arc;\n\npub struct SaveIdeaTool {\n    session_id: String,\n}\n\nimpl SaveIdeaTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for SaveIdeaTool {\n    fn name(&self) -> &str {\n        \"save_idea\"\n    }\n\n    fn description(&self) -> &str {\n        \"Save idea.md as a session-scoped artifact (.cowork/sessions/<id>/artifacts/idea.md).\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"content\": {\n                    \"type\": \"string\",\n                    \"description\": \"Markdown content of idea.md\"\n                }\n            },\n            \"required\": [\"content\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let content = args[\"content\"].as_str().unwrap();\n        save_idea(&self.session_id, content)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"message\": \"Idea saved successfully\"\n        }))\n    }\n}\n\npub struct LoadIdeaTool {\n    session_id: String,\n}\n\nimpl LoadIdeaTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for LoadIdeaTool {\n    fn name(&self) -> &str {\n        \"load_idea\"\n    }\n\n    fn description(&self) -> &str {\n        \"Load idea.md from current session artifacts.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\"type\": \"object\", \"properties\": {}}))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, _args: Value) -> adk_core::Result<Value> {\n        let content = load_idea(&self.session_id)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"content\": content\n        }))\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 3.0,
      "lines_of_code": 86,
      "number_of_classes": 2,
      "number_of_functions": 2
    },
    "dependencies": [
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 2,
        "name": "crate::storage",
        "path": "crates/cowork-core/src/storage",
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 3,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 4,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 5,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 6,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component provides two session-scoped tools for managing idea artifacts: SaveIdeaTool and LoadIdeaTool. The SaveIdeaTool handles saving markdown content as idea.md files within session-specific artifact directories (.cowork/sessions/<id>/artifacts/idea.md). The LoadIdeaTool retrieves previously saved idea content from the same location. Both tools implement the async_trait pattern and follow the Tool interface contract, providing proper parameter schemas and error handling. The component demonstrates clean separation of concerns with dedicated structs for each operation.",
    "interfaces": [
      {
        "description": "Creates a new SaveIdeaTool instance with session context",
        "interface_type": "constructor",
        "name": "SaveIdeaTool::new",
        "parameters": [
          {
            "description": "Session identifier for artifact scoping",
            "is_optional": false,
            "name": "session_id",
            "param_type": "String"
          }
        ],
        "return_type": "SaveIdeaTool",
        "visibility": "public"
      },
      {
        "description": "Returns the tool name identifier",
        "interface_type": "method",
        "name": "SaveIdeaTool::name",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Provides tool functionality description",
        "interface_type": "method",
        "name": "SaveIdeaTool::description",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Defines JSON schema for tool parameters",
        "interface_type": "method",
        "name": "SaveIdeaTool::parameters_schema",
        "parameters": [],
        "return_type": "Option<Value>",
        "visibility": "public"
      },
      {
        "description": "Executes the idea saving operation",
        "interface_type": "async_method",
        "name": "SaveIdeaTool::execute",
        "parameters": [
          {
            "description": "Tool execution context",
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": "JSON arguments containing content",
            "is_optional": false,
            "name": "args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      },
      {
        "description": "Creates a new LoadIdeaTool instance with session context",
        "interface_type": "constructor",
        "name": "LoadIdeaTool::new",
        "parameters": [
          {
            "description": "Session identifier for artifact retrieval",
            "is_optional": false,
            "name": "session_id",
            "param_type": "String"
          }
        ],
        "return_type": "LoadIdeaTool",
        "visibility": "public"
      },
      {
        "description": "Returns the tool name identifier",
        "interface_type": "method",
        "name": "LoadIdeaTool::name",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Provides tool functionality description",
        "interface_type": "method",
        "name": "LoadIdeaTool::description",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Defines JSON schema for tool parameters",
        "interface_type": "method",
        "name": "LoadIdeaTool::parameters_schema",
        "parameters": [],
        "return_type": "Option<Value>",
        "visibility": "public"
      },
      {
        "description": "Executes the idea loading operation",
        "interface_type": "async_method",
        "name": "LoadIdeaTool::execute",
        "parameters": [
          {
            "description": "Tool execution context",
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": "JSON arguments (empty for this tool)",
            "is_optional": false,
            "name": "_args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Session-scoped idea artifact persistence management",
      "Markdown content storage and retrieval operations",
      "Tool interface implementation for external integration",
      "Error handling and conversion between storage and tool errors",
      "Parameter validation and schema definition for tool operations"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": null,
      "file_path": "crates/cowork-core/src/tools/data_tools.rs",
      "functions": [
        "CreateRequirementTool::new",
        "CreateRequirementTool::name",
        "CreateRequirementTool::description",
        "CreateRequirementTool::parameters_schema",
        "CreateRequirementTool::execute",
        "AddFeatureTool::new",
        "AddFeatureTool::name",
        "AddFeatureTool::description",
        "AddFeatureTool::parameters_schema",
        "AddFeatureTool::execute",
        "CreateDesignComponentTool::new",
        "CreateDesignComponentTool::name",
        "CreateDesignComponentTool::description",
        "CreateDesignComponentTool::parameters_schema",
        "CreateDesignComponentTool::execute",
        "CreateTaskTool::new",
        "CreateTaskTool::name",
        "CreateTaskTool::description",
        "CreateTaskTool::parameters_schema",
        "CreateTaskTool::execute",
        "UpdateFeatureStatusTool::new",
        "UpdateFeatureStatusTool::name",
        "UpdateFeatureStatusTool::description",
        "UpdateFeatureStatusTool::parameters_schema",
        "UpdateFeatureStatusTool::execute",
        "UpdateTaskStatusTool::new",
        "UpdateTaskStatusTool::name",
        "UpdateTaskStatusTool::description",
        "UpdateTaskStatusTool::parameters_schema",
        "UpdateTaskStatusTool::execute",
        "UpdateTaskTool::new",
        "UpdateTaskTool::name",
        "UpdateTaskTool::description",
        "UpdateTaskTool::parameters_schema",
        "UpdateTaskTool::execute",
        "DeleteTaskTool::new",
        "DeleteTaskTool::name",
        "DeleteTaskTool::description",
        "DeleteTaskTool::parameters_schema",
        "DeleteTaskTool::execute",
        "GetRequirementsTool::new",
        "GetRequirementsTool::name",
        "GetRequirementsTool::description",
        "GetRequirementsTool::parameters_schema",
        "GetRequirementsTool::execute",
        "GetDesignTool::new",
        "GetDesignTool::name",
        "GetDesignTool::description",
        "GetDesignTool::parameters_schema",
        "GetDesignTool::execute",
        "GetPlanTool::new",
        "GetPlanTool::name",
        "GetPlanTool::description",
        "GetPlanTool::parameters_schema",
        "GetPlanTool::execute"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "Tool"
      ],
      "name": "data_tools.rs",
      "source_summary": "// Data operation tools - Create and modify structured data (Session-scoped)\nuse crate::data::*;\nuse crate::storage::*;\nuse adk_core::{Tool, ToolContext, AdkError};\nuse async_trait::async_trait;\nuse serde_json::{json, Value};\nuse std::sync::Arc;\n\n// ============================================================================\n// CreateRequirementTool\n// ============================================================================\n\npub struct CreateRequirementTool {\n    session_id: String,\n}\n\nimpl CreateRequirementTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for CreateRequirementTool {\n    fn name(&self) -> &str {\n        \"create_requirement\"\n    }\n\n    fn description(&self) -> &str {\n        \"Create a new requirement in requirements.json. Requirements define what \\\n         the system must do. Each requirement should be SMART (Specific, Measurable, \\\n         Achievable, Relevant, Time-bound) with clear acceptance criteria.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"title\": {\n                    \"type\": \"string\",\n                    \"description\": \"Brief requirement title\"\n                },\n                \"description\": {\n                    \"type\": \"string\",\n                    \"description\": \"Detailed description of the requirement\"\n                },\n                \"priority\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"high\", \"medium\", \"low\"],\n                    \"description\": \"Priority level\"\n                },\n                \"category\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"functional\", \"non_functional\"],\n                    \"description\": \"Requirement category\"\n                },\n                \"acceptance_criteria\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"List of acceptance criteria\"\n                }\n            },\n            \"required\": [\"title\", \"description\", \"priority\", \"category\", \"acceptance_criteria\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let mut reqs = load_requirements(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        let req_id = generate_id(\"REQ\", reqs.requirements.len());\n\n        let priority = match args[\"priority\"].as_str().unwrap() {\n            \"high\" => Priority::High,\n            \"medium\" => Priority::Medium,\n            \"low\" => Priority::Low,\n            _ => Priority::Medium,\n        };\n\n        let category = match args[\"category\"].as_str().unwrap() {\n            \"functional\" => RequirementCategory::Functional,\n            \"non_functional\" => RequirementCategory::NonFunctional,\n            _ => RequirementCategory::Functional,\n        };\n\n        let requirement = Requirement {\n            id: req_id.clone(),\n            title: args[\"title\"].as_str().unwrap().to_string(),\n            description: args[\"description\"].as_str().unwrap().to_string(),\n            priority,\n            category,\n            acceptance_criteria: args[\"acceptance_criteria\"]\n                .as_array()\n                .unwrap()\n                .iter()\n                .map(|v| v.as_str().unwrap().to_string())\n                .collect(),\n            related_features: vec![],\n        };\n\n        reqs.requirements.push(requirement.clone());\n        reqs.updated_at = chrono::Utc::now();\n        save_requirements(&self.session_id, &reqs).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        println!(\"âœ… Created: {} - {}\", req_id, requirement.title);\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"requirement_id\": req_id,\n            \"message\": format!(\"Requirement {} created successfully\", req_id)\n        }))\n    }\n}\n\n// ============================================================================\n// AddFeatureTool\n// ============================================================================\n\npub struct AddFeatureTool {\n    session_id: String,\n}\n\nimpl AddFeatureTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for AddFeatureTool {\n    fn name(&self) -> &str {\n        \"add_feature\"\n    }\n\n    fn description(&self) -> &str {\n        \"Add a new feature to feature_list.json. Features are concrete \\\n         functionalities that implement one or more requirements. Each \\\n         feature will later be broken down into implementation tasks.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": {\n                    \"type\": \"string\",\n                    \"description\": \"Feature name\"\n                },\n                \"description\": {\n                    \"type\": \"string\",\n                    \"description\": \"Detailed description\"\n                },\n                \"requirement_ids\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"IDs of requirements this feature implements\"\n                },\n                \"completion_criteria\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"Criteria for feature completion\"\n                }\n            },\n            \"required\": [\"name\", \"description\", \"requirement_ids\", \"completion_criteria\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let mut features = load_feature_list(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        let feat_id = generate_id(\"FEAT\", features.features.len());\n\n        let feature = Feature {\n            id: feat_id.clone(),\n            name: args[\"name\"].as_str().unwrap().to_string(),\n            description: args[\"description\"].as_str().unwrap().to_string(),\n            requirement_ids: args[\"requirement_ids\"]\n                .as_array()\n                .unwrap()\n                .iter()\n                .map(|v| v.as_str().unwrap().to_string())\n                .collect(),\n            status: FeatureStatus::Pending,\n            assigned_to_tasks: vec![],\n            completion_criteria: args[\"completion_criteria\"]\n                .as_array()\n                .unwrap()\n                .iter()\n                .map(|v| v.as_str().unwrap().to_string())\n                .collect(),\n            created_at: chrono::Utc::now(),\n            completed_at: None,\n            metadata: FeatureMetadata::default(),\n        };\n\n        features.features.push(feature);\n        save_feature_list(&self.session_id, &features).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"feature_id\": feat_id,\n            \"message\": format!(\"Feature {} created successfully\", feat_id)\n        }))\n    }\n}\n\n// ============================================================================\n// CreateDesignComponentTool\n// ============================================================================\n\npub struct CreateDesignComponentTool {\n    session_id: String,\n}\n\nimpl CreateDesignComponentTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for CreateDesignComponentTool {\n    fn name(&self) -> &str {\n        \"create_design_component\"\n    }\n\n    fn description(&self) -> &str {\n        \"Create a new component in design_spec.json. Components are the \\\n         architectural building blocks (services, modules, UI components) \\\n         that implement features.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": {\n                    \"type\": \"string\",\n                    \"description\": \"Component name\"\n                },\n                \"component_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"backend_service\", \"frontend_component\", \"database\", \"api_gateway\"],\n                    \"description\": \"Type of component\"\n                },\n                \"responsibilities\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"List of responsibilities\"\n                },\n                \"technology\": {\n                    \"type\": \"string\",\n                    \"description\": \"Technology stack\"\n                },\n                \"related_features\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"Related feature IDs\"\n                }\n            },\n            \"required\": [\"name\", \"component_type\", \"responsibilities\", \"technology\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let mut design = load_design_spec(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        let comp_id = generate_id(\"COMP\", design.architecture.components.len());\n\n        let component_type = args.get(\"component_type\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing or invalid 'component_type' parameter\".to_string()))?;\n        \n        let component_type = match component_type {\n            \"backend_service\" => ComponentType::BackendService,\n            \"frontend_component\" => ComponentType::FrontendComponent,\n            \"database\" => ComponentType::Database,\n            \"api_gateway\" => ComponentType::ApiGateway,\n            other => ComponentType::Other(other.to_string()),\n        };\n\n        let name = args.get(\"name\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing or invalid 'name' parameter\".to_string()))?\n            .to_string();\n\n        let technology = args.get(\"technology\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing or invalid 'technology' parameter\".to_string()))?\n            .to_string();\n\n        let responsibilities = args.get(\"responsibilities\")\n            .and_then(|v| v.as_array())\n            .ok_or_else(|| AdkError::Tool(\"Missing or invalid 'responsibilities' parameter (must be an array)\".to_string()))?\n            .iter()\n            .filter_map(|v| v.as_str().map(|s| s.to_string()))\n            .collect::<Vec<String>>();\n\n        if responsibilities.is_empty() {\n            return Err(AdkError::Tool(\"'responsibilities' array cannot be empty\".to_string()));\n        }\n\n        let related_features = args.get(\"related_features\")\n            .and_then(|v| v.as_array())\n            .map(|arr| arr.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect())\n            .unwrap_or_default();\n\n        let component = DesignComponent {\n            id: comp_id.clone(),\n            name,\n            component_type,\n            responsibilities,\n            technology,\n            interfaces: vec![],\n            related_features,\n        };\n\n        design.architecture.components.push(component.clone());\n        save_design_spec(&self.session_id, &design).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        println!(\"ğŸ—ï¸  Created component: {} - {}\", comp_id, component.name);\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"component_id\": comp_id,\n            \"message\": format!(\"Component {} created successfully\", comp_id)\n        }))\n    }\n}\n\n// ============================================================================\n// CreateTaskTool\n// ============================================================================\n\npub struct CreateTaskTool {\n    session_id: String,\n}\n\nimpl CreateTaskTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for CreateTaskTool {\n    fn name(&self) -> &str {\n        \"create_task\"\n    }\n\n    fn description(&self) -> &str {\n        \"Create an implementation task in implementation_plan.json. Tasks \\\n         are concrete coding work items that implement features.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"title\": {\"type\": \"string\"},\n                \"description\": {\"type\": \"string\"},\n                \"feature_id\": {\"type\": \"string\"},\n                \"component_id\": {\"type\": \"string\"},\n                \"files_to_create\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"}\n                },\n                \"dependencies\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"Task IDs that must be completed first\"\n                },\n                \"acceptance_criteria\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"}\n                }\n            },\n            \"required\": [\"title\", \"description\", \"feature_id\", \"component_id\", \"acceptance_criteria\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let mut plan = load_implementation_plan(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        let task_id = generate_id(\"TASK\", plan.tasks.len());\n\n        let task = Task {\n            id: task_id.clone(),\n            title: args[\"title\"].as_str().unwrap().to_string(),\n            description: args[\"description\"].as_str().unwrap().to_string(),\n            feature_id: args[\"feature_id\"].as_str().unwrap().to_string(),\n            component_id: args[\"component_id\"].as_str().unwrap().to_string(),\n            status: TaskStatus::Pending,\n            dependencies: args.get(\"dependencies\")\n                .and_then(|v| v.as_array())\n                .map(|arr| arr.iter().map(|v| v.as_str().unwrap().to_string()).collect())\n                .unwrap_or_default(),\n            estimated_effort: None,\n            files_to_create: args.get(\"files_to_create\")\n                .and_then(|v| v.as_array())\n                .map(|arr| arr.iter().map(|v| v.as_str().unwrap().to_string()).collect())\n                .unwrap_or_default(),\n            acceptance_criteria: args[\"acceptance_criteria\"]\n                .as_array()\n                .unwrap()\n                .iter()\n                .map(|v| v.as_str().unwrap().to_string())\n                .collect(),\n            created_at: chrono::Utc::now(),\n            started_at: None,\n            completed_at: None,\n        };\n\n        plan.tasks.push(task);\n        save_implementation_plan(&self.session_id, &plan).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"task_id\": task_id,\n            \"message\": format!(\"Task {} created successfully\", task_id)\n        }))\n    }\n}\n\n// ============================================================================\n// Update Status Tools\n// ============================================================================\n\npub struct UpdateFeatureStatusTool {\n    session_id: String,\n}\n\nimpl UpdateFeatureStatusTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for UpdateFeatureStatusTool {\n    fn name(&self) -> &str {\n        \"update_feature_status\"\n    }\n\n    fn description(&self) -> &str {\n        \"Update the status of a feature. Valid transitions: \\\n         pending â†’ in_progress â†’ completed.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"feature_id\": {\"type\": \"string\"},\n                \"new_status\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"pending\", \"in_progress\", \"completed\", \"blocked\"]\n                }\n            },\n            \"required\": [\"feature_id\", \"new_status\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let mut features = load_feature_list(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        let feature_id = args[\"feature_id\"].as_str().unwrap();\n        let new_status_str = args[\"new_status\"].as_str().unwrap();\n\n        let new_status = match new_status_str {\n            \"pending\" => FeatureStatus::Pending,\n            \"in_progress\" => FeatureStatus::InProgress,\n            \"completed\" => FeatureStatus::Completed,\n            \"blocked\" => FeatureStatus::Blocked,\n            _ => FeatureStatus::Pending,\n        };\n\n        if let Some(feature) = features.features.iter_mut().find(|f| f.id == feature_id) {\n            feature.status = new_status;\n            if new_status_str == \"completed\" {\n                feature.completed_at = Some(chrono::Utc::now());\n            }\n            save_feature_list(&self.session_id, &features).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n            Ok(json!({\n                \"status\": \"success\",\n                \"feature_id\": feature_id,\n                \"new_status\": new_status_str,\n                \"message\": format!(\"Feature {} status updated to {}\", feature_id, new_status_str)\n            }))\n        } else {\n            Ok(json!({\n                \"status\": \"error\",\n                \"message\": format!(\"Feature {} not found\", feature_id)\n            }))\n        }\n    }\n}\n\npub struct UpdateTaskStatusTool {\n    session_id: String,\n}\n\nimpl UpdateTaskStatusTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for UpdateTaskStatusTool {\n    fn name(&self) -> &str {\n        \"update_task_status\"\n    }\n\n    fn description(&self) -> &str {\n        \"Update task status. Call this as you start and complete tasks.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"task_id\": {\"type\": \"string\"},\n                \"new_status\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"pending\", \"in_progress\", \"completed\", \"blocked\"]\n                }\n            },\n            \"required\": [\"task_id\", \"new_status\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let mut plan = load_implementation_plan(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        let task_id = args.get(\"task_id\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing or invalid 'task_id' parameter\".to_string()))?;\n        \n        let new_status_str = args.get(\"new_status\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing or invalid 'new_status' parameter\".to_string()))?;\n\n        let new_status = match new_status_str {\n            \"pending\" => TaskStatus::Pending,\n            \"in_progress\" => TaskStatus::InProgress,\n            \"completed\" => TaskStatus::Completed,\n            \"blocked\" => TaskStatus::Blocked,\n            _ => return Err(AdkError::Tool(format!(\"Invalid status: {}. Must be one of: pending, in_progress, completed, blocked\", new_status_str))),\n        };\n\n        if let Some(task) = plan.tasks.iter_mut().find(|t| t.id == task_id) {\n            task.status = new_status;\n            match new_status_str {\n                \"in_progress\" => task.started_at = Some(chrono::Utc::now()),\n                \"completed\" => task.completed_at = Some(chrono::Utc::now()),\n                _ => {}\n            }\n            save_implementation_plan(&self.session_id, &plan).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n            println!(\"âœ“ Task {} â†’ {}\", task_id, new_status_str);\n\n            Ok(json!({\n                \"status\": \"success\",\n                \"task_id\": task_id,\n                \"new_status\": new_status_str\n            }))\n        } else {\n            Ok(json!({\n                \"status\": \"error\",\n                \"message\": format!(\"Task {} not found\", task_id)\n            }))\n        }\n    }\n}\n\n// ============================================================================\n// UpdateTaskTool - Modify task properties\n// ============================================================================\n\npub struct UpdateTaskTool {\n    session_id: String,\n}\n\nimpl UpdateTaskTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for UpdateTaskTool {\n    fn name(&self) -> &str {\n        \"update_task\"\n    }\n\n    fn description(&self) -> &str {\n        \"Update task properties such as title, description, dependencies, or files. \\\n         Use this when you discover that task requirements have changed during implementation.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"task_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of the task to update\"\n                },\n                \"title\": {\n                    \"type\": \"string\",\n                    \"description\": \"New title (optional)\"\n                },\n                \"description\": {\n                    \"type\": \"string\",\n                    \"description\": \"New description (optional)\"\n                },\n                \"dependencies\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"New list of task IDs that must be completed first (optional)\"\n                },\n                \"files_to_create\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"New list of files to create (optional)\"\n                },\n                \"acceptance_criteria\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"New acceptance criteria (optional)\"\n                },\n                \"reason\": {\n                    \"type\": \"string\",\n                    \"description\": \"Reason for this update\"\n                }\n            },\n            \"required\": [\"task_id\", \"reason\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let task_id = args.get(\"task_id\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing 'task_id' parameter\".to_string()))?;\n        \n        let reason = args.get(\"reason\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing 'reason' parameter\".to_string()))?;\n\n        let mut plan = load_implementation_plan(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        // First, find the task index\n        let task_idx = plan.tasks.iter()\n            .position(|t| t.id == task_id)\n            .ok_or_else(|| AdkError::Tool(format!(\"Task {} not found\", task_id)))?;\n\n        let mut updates = Vec::new();\n\n        // Update title if provided\n        if let Some(title) = args.get(\"title\").and_then(|v| v.as_str()) {\n            plan.tasks[task_idx].title = title.to_string();\n            updates.push(format!(\"title â†’ {}\", title));\n        }\n\n        // Update description if provided\n        if let Some(desc) = args.get(\"description\").and_then(|v| v.as_str()) {\n            plan.tasks[task_idx].description = desc.to_string();\n            updates.push(\"description updated\".to_string());\n        }\n\n        // Update dependencies if provided\n        if let Some(deps) = args.get(\"dependencies\").and_then(|v| v.as_array()) {\n            let new_deps: Vec<String> = deps.iter()\n                .filter_map(|v| v.as_str().map(String::from))\n                .collect();\n            \n            // Validate that all dependency task IDs exist\n            for dep_id in &new_deps {\n                if !plan.tasks.iter().any(|t| &t.id == dep_id) {\n                    return Err(AdkError::Tool(format!(\"Dependency task {} not found\", dep_id)));\n                }\n            }\n            \n            plan.tasks[task_idx].dependencies = new_deps.clone();\n            updates.push(format!(\"dependencies â†’ {:?}\", new_deps));\n        }\n\n        // Update files_to_create if provided\n        if let Some(files) = args.get(\"files_to_create\").and_then(|v| v.as_array()) {\n            plan.tasks[task_idx].files_to_create = files.iter()\n                .filter_map(|v| v.as_str().map(String::from))\n                .collect();\n            updates.push(\"files_to_create updated\".to_string());\n        }\n\n        // Update acceptance_criteria if provided\n        if let Some(criteria) = args.get(\"acceptance_criteria\").and_then(|v| v.as_array()) {\n            plan.tasks[task_idx].acceptance_criteria = criteria.iter()\n                .filter_map(|v| v.as_str().map(String::from))\n                .collect();\n            updates.push(\"acceptance_criteria updated\".to_string());\n        }\n\n        save_implementation_plan(&self.session_id, &plan).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        // Log the update with reason\n        println!(\"âœ“ Task {} updated: {}\", task_id, updates.join(\", \"));\n        println!(\"  Reason: {}\", reason);\n\n        // Record to feedback for audit trail\n        let feedback = crate::data::Feedback {\n            feedback_type: crate::data::FeedbackType::Suggestion,\n            severity: crate::data::Severity::Minor,\n            details: format!(\"Task {} updated: {}. Reason: {}\", task_id, updates.join(\", \"), reason),\n            suggested_fix: None,\n            timestamp: chrono::Utc::now(),\n        };\n        let _ = crate::storage::append_feedback(&self.session_id, &feedback);\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"task_id\": task_id,\n            \"updates\": updates,\n            \"reason\": reason\n        }))\n    }\n}\n\n// ============================================================================\n// DeleteTaskTool - Remove task and clean up dependencies\n// ============================================================================\n\npub struct DeleteTaskTool {\n    session_id: String,\n}\n\nimpl DeleteTaskTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for DeleteTaskTool {\n    fn name(&self) -> &str {\n        \"delete_task\"\n    }\n\n    fn description(&self) -> &str {\n        \"Delete a task from the plan. This will also remove references to this task \\\n         from other tasks' dependencies. Use this when a task is no longer needed \\\n         or was incorrectly planned.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"task_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of the task to delete\"\n                },\n                \"reason\": {\n                    \"type\": \"string\",\n                    \"description\": \"Reason for deleting this task\"\n                }\n            },\n            \"required\": [\"task_id\", \"reason\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let task_id = args.get(\"task_id\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing 'task_id' parameter\".to_string()))?;\n        \n        let reason = args.get(\"reason\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| AdkError::Tool(\"Missing 'reason' parameter\".to_string()))?;\n\n        let mut plan = load_implementation_plan(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        // Check if task exists\n        let task_exists = plan.tasks.iter().any(|t| t.id == task_id);\n        if !task_exists {\n            return Err(AdkError::Tool(format!(\"Task {} not found\", task_id)));\n        }\n\n        // Check if this task is in_progress or completed\n        if let Some(task) = plan.tasks.iter().find(|t| t.id == task_id) {\n            if task.status == crate::data::TaskStatus::InProgress {\n                return Err(AdkError::Tool(format!(\n                    \"Cannot delete task {} because it's currently in progress. \\\n                     Set status to pending or blocked first.\", task_id\n                )));\n            }\n            if task.status == crate::data::TaskStatus::Completed {\n                return Err(AdkError::Tool(format!(\n                    \"Cannot delete task {} because it's already completed. \\\n                     Consider keeping it for documentation.\", task_id\n                )));\n            }\n        }\n\n        // Remove the task\n        plan.tasks.retain(|t| t.id != task_id);\n\n        // Clean up dependencies - remove this task_id from other tasks' dependencies\n        let mut affected_tasks = Vec::new();\n        for task in &mut plan.tasks {\n            let before_len = task.dependencies.len();\n            task.dependencies.retain(|dep| dep != task_id);\n            let after_len = task.dependencies.len();\n            \n            if before_len != after_len {\n                affected_tasks.push(task.id.clone());\n            }\n        }\n\n        save_implementation_plan(&self.session_id, &plan).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        println!(\"âœ“ Task {} deleted\", task_id);\n        if !affected_tasks.is_empty() {\n            println!(\"  Cleaned dependencies from: {}\", affected_tasks.join(\", \"));\n        }\n        println!(\"  Reason: {}\", reason);\n\n        // Record to feedback for audit trail\n        let feedback = crate::data::Feedback {\n            feedback_type: crate::data::FeedbackType::Suggestion,\n            severity: crate::data::Severity::Minor,\n            details: format!(\n                \"Task {} deleted. Reason: {}. Affected tasks: {}\", \n                task_id, reason, \n                if affected_tasks.is_empty() { \"none\".to_string() } else { affected_tasks.join(\", \") }\n            ),\n            suggested_fix: None,\n            timestamp: chrono::Utc::now(),\n        };\n        let _ = crate::storage::append_feedback(&self.session_id, &feedback);\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"task_id\": task_id,\n            \"affected_tasks\": affected_tasks,\n            \"reason\": reason,\n            \"message\": format!(\"Task {} deleted successfully\", task_id)\n        }))\n    }\n}\n\n// ============================================================================\n// Get/Read Tools\n// ============================================================================\n\npub struct GetRequirementsTool {\n    session_id: String,\n}\n\nimpl GetRequirementsTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for GetRequirementsTool {\n    fn name(&self) -> &str {\n        \"get_requirements\"\n    }\n\n    fn description(&self) -> &str {\n        \"Retrieve all requirements and features.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {}\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, _args: Value) -> adk_core::Result<Value> {\n        let requirements = load_requirements(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n        let features = load_feature_list(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"requirements\": requirements.requirements,\n            \"features\": features.features\n        }))\n    }\n}\n\npub struct GetDesignTool {\n    session_id: String,\n}\n\nimpl GetDesignTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for GetDesignTool {\n    fn name(&self) -> &str {\n        \"get_design\"\n    }\n\n    fn description(&self) -> &str {\n        \"Retrieve the design specification.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\"type\": \"object\", \"properties\": {}}))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, _args: Value) -> adk_core::Result<Value> {\n        let design = load_design_spec(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n        Ok(serde_json::to_value(design).map_err(|e| AdkError::Tool(e.to_string()))?)\n    }\n}\n\npub struct GetPlanTool {\n    session_id: String,\n}\n\nimpl GetPlanTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for GetPlanTool {\n    fn name(&self) -> &str {\n        \"get_plan\"\n    }\n\n    fn description(&self) -> &str {\n        \"Retrieve the implementation plan with all tasks.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\"type\": \"object\", \"properties\": {}}))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, _args: Value) -> adk_core::Result<Value> {\n        let plan = load_implementation_plan(&self.session_id).map_err(|e| AdkError::Tool(e.to_string()))?;\n        Ok(serde_json::to_value(plan).map_err(|e| AdkError::Tool(e.to_string()))?)\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 50.0,
      "lines_of_code": 953,
      "number_of_classes": 11,
      "number_of_functions": 77
    },
    "dependencies": [
      {
        "dependency_type": "internal_import",
        "is_external": false,
        "line_number": null,
        "name": "crate::data::*",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "internal_import",
        "is_external": false,
        "line_number": null,
        "name": "crate::storage::*",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external_crate",
        "is_external": true,
        "line_number": null,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external_crate",
        "is_external": true,
        "line_number": null,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external_crate",
        "is_external": true,
        "line_number": null,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "std_library",
        "is_external": false,
        "line_number": null,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component provides a suite of tool functions for managing structured data in a software development workflow. It implements 11 distinct tools that enable the creation, modification, retrieval, and deletion of core project artifacts including requirements, features, design components, and implementation tasks. All tools operate within a session-scoped context and interact with persistent JSON storage files (requirements.json, feature_list.json, design_spec.json, implementation_plan.json). The tools follow a consistent pattern: each is an async Tool implementation with a name, description, parameter schema, and execute method that validates input, reads/writes to storage, and returns structured JSON responses. The system enforces data integrity through validation, type conversion, and dependency tracking, particularly in task management where dependencies are maintained and cleaned up during deletions. The component supports a complete development lifecycle from requirement definition to task execution tracking.",
    "interfaces": [
      {
        "description": null,
        "interface_type": "trait",
        "name": "Tool",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Manage requirement lifecycle (create, retrieve)",
      "Manage feature lifecycle (create, update status)",
      "Manage architectural component lifecycle (create)",
      "Manage implementation task lifecycle (create, update status, update properties, delete)",
      "Maintain data consistency and audit trails across related entities"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": "Human-in-the-Loop (HITL) tools providing interactive file review and editing capabilities with multiple user interaction modes",
      "file_path": "crates/cowork-core/src/tools/hitl_tools.rs",
      "functions": [
        "review_and_edit_file",
        "review_with_feedback"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "ReviewAndEditFileTool",
        "ReviewWithFeedbackTool"
      ],
      "name": "hitl_tools.rs",
      "source_summary": "// HITL (Human-in-the-Loop) tools\nuse adk_core::{Tool, ToolContext};\nuse async_trait::async_trait;\nuse dialoguer::{Confirm, Editor, Input};\nuse serde_json::{json, Value};\nuse std::fs;\nuse std::sync::Arc;\n\n/// ReviewAndEditFileTool - Original HITL tool (used in Idea stage)\npub struct ReviewAndEditFileTool;\n\n#[async_trait]\nimpl Tool for ReviewAndEditFileTool {\n    fn name(&self) -> &str {\n        \"review_and_edit_file\"\n    }\n\n    fn description(&self) -> &str {\n        \"Let the user review and optionally edit a file using their default editor. \\\n         User will be prompted: 'Do you want to edit this file? (y/n)'. \\\n         If 'y', opens the file in an editor. If 'n', continues without changes.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"file_path\": {\n                    \"type\": \"string\",\n                    \"description\": \"Path to the file to review and edit\"\n                },\n                \"title\": {\n                    \"type\": \"string\",\n                    \"description\": \"Title/description for the review prompt\"\n                }\n            },\n            \"required\": [\"file_path\", \"title\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let file_path = args[\"file_path\"].as_str().unwrap();\n        let title = args[\"title\"].as_str().unwrap();\n\n        // Read current file content\n        let content = fs::read_to_string(file_path)\n            .map_err(|e| adk_core::AdkError::Tool(format!(\"Failed to read file {}: {}\", file_path, e)))?;\n\n        // Show preview\n        println!(\"\\nğŸ“ {} - {}\", title, file_path);\n        println!(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\");\n        let line_count = content.lines().count();\n        for (i, line) in content.lines().take(10).enumerate() {\n            println!(\"  {}: {}\", i + 1, line);\n        }\n        if line_count > 10 {\n            println!(\"  ... ({} more lines)\", line_count - 10);\n        }\n        println!(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\");\n\n        // Ask user if they want to edit\n        let should_edit = Confirm::new()\n            .with_prompt(\"Do you want to edit this file? (y/n)\")\n            .default(false)\n            .interact()\n            .map_err(|e| adk_core::AdkError::Tool(format!(\"Interaction error: {}\", e)))?;\n\n        if !should_edit {\n            return Ok(json!({\n                \"status\": \"no_changes\",\n                \"message\": \"User chose not to edit the file\"\n            }));\n        }\n\n        // Open editor\n        println!(\"ğŸ“ Opening editor... (Save and close to submit changes)\");\n        let edited = Editor::new()\n            .require_save(true)\n            .edit(&content)\n            .map_err(|e| adk_core::AdkError::Tool(format!(\"Editor error: {}\", e)))?;\n\n        match edited {\n            Some(new_content) if new_content.trim() != content.trim() => {\n                // Save changes\n                fs::write(file_path, &new_content)\n                    .map_err(|e| adk_core::AdkError::Tool(format!(\"Failed to write file: {}\", e)))?;\n\n                println!(\"âœ… File updated successfully\");\n                Ok(json!({\n                    \"status\": \"edited\",\n                    \"message\": \"File was edited and saved\",\n                    \"changes_made\": true\n                }))\n            }\n            _ => {\n                println!(\"â„¹ï¸  No changes made\");\n                Ok(json!({\n                    \"status\": \"no_changes\",\n                    \"message\": \"File was not modified\"\n                }))\n            }\n        }\n    }\n}\n\n/// ReviewWithFeedbackTool - Enhanced HITL tool with three modes:\n/// 1. User types \"edit\" â†’ Opens editor\n/// 2. User types \"pass\" â†’ Continues without changes\n/// 3. User types other text â†’ Returns as feedback for agent to process\npub struct ReviewWithFeedbackTool;\n\n#[async_trait]\nimpl Tool for ReviewWithFeedbackTool {\n    fn name(&self) -> &str {\n        \"review_with_feedback\"\n    }\n\n    fn description(&self) -> &str {\n        \"Show user a file preview and ask for feedback. User can:\\n\\\n         - Type 'edit' to open the file in an editor\\n\\\n         - Type 'pass' to continue without changes\\n\\\n         - Type any other text to provide feedback/suggestions (agent will revise based on feedback)\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"path\": {\n                    \"type\": \"string\",\n                    \"description\": \"Path to the file to review\"\n                },\n                \"title\": {\n                    \"type\": \"string\",\n                    \"description\": \"Title/description for the review prompt\"\n                },\n                \"prompt\": {\n                    \"type\": \"string\",\n                    \"description\": \"Custom prompt to show the user (e.g., 'è¯·å®¡æŸ¥éœ€æ±‚å¤§çº²')\"\n                }\n            },\n            \"required\": [\"path\", \"title\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let file_path = args[\"path\"].as_str().unwrap();\n        let title = args[\"title\"].as_str().unwrap();\n        let default_prompt = \"è¾“å…¥ 'edit' ç¼–è¾‘ï¼Œ'pass' ç»§ç»­ï¼Œæˆ–ç›´æ¥è¾“å…¥ä¿®æ”¹å»ºè®®\";\n        let prompt = args[\"prompt\"].as_str().unwrap_or(default_prompt);\n\n        // Read current file content\n        let content = fs::read_to_string(file_path)\n            .map_err(|e| adk_core::AdkError::Tool(format!(\"Failed to read file {}: {}\", file_path, e)))?;\n\n        // Show preview\n        println!(\"\\nğŸ“ {} - {}\", title, file_path);\n        println!(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\");\n        let line_count = content.lines().count();\n        for (i, line) in content.lines().take(15).enumerate() {\n            println!(\"  {}: {}\", i + 1, line);\n        }\n        if line_count > 15 {\n            println!(\"  ... ({} more lines)\", line_count - 15);\n        }\n        println!(\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\");\n\n        // Ask user for input\n        let user_input: String = Input::new()\n            .with_prompt(prompt)\n            .allow_empty(true)\n            .interact_text()\n            .map_err(|e| adk_core::AdkError::Tool(format!(\"Interaction error: {}\", e)))?;\n\n        let user_input = user_input.trim();\n\n        // Handle different input modes\n        match user_input.to_lowercase().as_str() {\n            \"edit\" => {\n                // Mode 1: Open editor\n                println!(\"ğŸ“ Opening editor... (Save and close to submit changes)\");\n                let edited = Editor::new()\n                    .require_save(true)\n                    .edit(&content)\n                    .map_err(|e| adk_core::AdkError::Tool(format!(\"Editor error: {}\", e)))?;\n\n                match edited {\n                    Some(new_content) if new_content.trim() != content.trim() => {\n                        fs::write(file_path, &new_content)\n                            .map_err(|e| adk_core::AdkError::Tool(format!(\"Failed to write file: {}\", e)))?;\n\n                        println!(\"âœ… File updated successfully\");\n                        Ok(json!({\n                            \"action\": \"edit\",\n                            \"status\": \"edited\",\n                            \"message\": \"User edited the file in editor\",\n                            \"changes_made\": true\n                        }))\n                    }\n                    _ => {\n                        println!(\"â„¹ï¸  No changes made in editor\");\n                        Ok(json!({\n                            \"action\": \"edit\",\n                            \"status\": \"no_changes\",\n                            \"message\": \"User opened editor but made no changes\"\n                        }))\n                    }\n                }\n            }\n            \"pass\" | \"\" => {\n                // Mode 2: Pass/Continue\n                println!(\"â¡ï¸  Continuing without changes...\");\n                Ok(json!({\n                    \"action\": \"pass\",\n                    \"status\": \"passed\",\n                    \"message\": \"User chose to continue without changes\"\n                }))\n            }\n            _ => {\n                // Mode 3: Feedback text\n                println!(\"ğŸ’¬ Feedback received: {}\", user_input);\n                println!(\"ğŸ”„ Agent will revise based on your feedback...\");\n                Ok(json!({\n                    \"action\": \"feedback\",\n                    \"status\": \"feedback_provided\",\n                    \"feedback\": user_input,\n                    \"message\": format!(\"User provided feedback: {}\", user_input)\n                }))\n            }\n        }\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 19.0,
      "lines_of_code": 232,
      "number_of_classes": 2,
      "number_of_functions": 2
    },
    "dependencies": [
      {
        "dependency_type": "framework",
        "is_external": true,
        "line_number": 2,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "macro",
        "is_external": true,
        "line_number": 3,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 4,
        "name": "dialoguer",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "serialization",
        "is_external": true,
        "line_number": 5,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 6,
        "name": "std::fs",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 7,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component implements two HITL (Human-in-the-Loop) tools that enable user interaction during file review processes. The ReviewAndEditFileTool provides basic file review with simple yes/no editing option, while ReviewWithFeedbackTool offers enhanced functionality with three interaction modes: edit mode (opens editor), pass mode (continues without changes), and feedback mode (provides text feedback for agent processing). Both tools implement the Tool trait from adk_core framework and provide file preview, user interaction, and file modification capabilities.",
    "interfaces": [
      {
        "description": "Basic HITL tool for file review with simple edit option",
        "interface_type": "struct",
        "name": "ReviewAndEditFileTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Enhanced HITL tool with multiple interaction modes",
        "interface_type": "struct",
        "name": "ReviewWithFeedbackTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Returns tool identifier name",
        "interface_type": "method",
        "name": "name",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns tool description",
        "interface_type": "method",
        "name": "description",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns JSON schema for tool parameters",
        "interface_type": "method",
        "name": "parameters_schema",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "Option<Value>",
        "visibility": "public"
      },
      {
        "description": "Executes the tool with provided arguments",
        "interface_type": "method",
        "name": "execute",
        "parameters": [
          {
            "description": "Tool instance",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          },
          {
            "description": "Tool execution context",
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": "Tool arguments as JSON value",
            "is_optional": false,
            "name": "args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Provide interactive file review capabilities with user preview",
      "Handle file editing operations through external editors",
      "Manage multiple user interaction modes (edit/pass/feedback)",
      "Implement error handling for file operations and user interactions",
      "Return structured execution results for agent processing"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": "Goto Stage tool for Check Agent (Session-scoped) - allows restarting pipeline from specific stages",
      "file_path": "crates/cowork-core/src/tools/goto_stage_tool.rs",
      "functions": [
        "new",
        "name",
        "description",
        "parameters_schema",
        "execute"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "GotoStageTool::new",
        "GotoStageTool::name",
        "GotoStageTool::description",
        "GotoStageTool::parameters_schema",
        "GotoStageTool::execute"
      ],
      "name": "goto_stage_tool.rs",
      "source_summary": "// Goto Stage tool for Check Agent (Session-scoped)\nuse crate::data::*;\nuse crate::storage::*;\nuse adk_core::{Tool, ToolContext};\nuse async_trait::async_trait;\nuse serde_json::{json, Value};\nuse std::sync::Arc;\n\npub struct GotoStageTool {\n    session_id: String,\n}\n\nimpl GotoStageTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for GotoStageTool {\n    fn name(&self) -> &str {\n        \"goto_stage\"\n    }\n\n    fn description(&self) -> &str {\n        \"Restart pipeline from a specific stage. Use this when critical issues \\\n         require going back to an earlier phase. Valid stages: prd, design, plan, coding.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"stage\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"prd\", \"design\", \"plan\", \"coding\"],\n                    \"description\": \"Which stage to restart from\"\n                },\n                \"reason\": {\n                    \"type\": \"string\",\n                    \"description\": \"Why the restart is needed\"\n                }\n            },\n            \"required\": [\"stage\", \"reason\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let stage_str = args[\"stage\"].as_str().unwrap();\n        let reason = args[\"reason\"].as_str().unwrap();\n\n        // Parse stage\n        let stage = match stage_str {\n            \"prd\" => Stage::Prd,\n            \"design\" => Stage::Design,\n            \"plan\" => Stage::Plan,\n            \"coding\" => Stage::Coding,\n            _ => {\n                return Ok(json!({\n                    \"status\": \"error\",\n                    \"message\": format!(\"Invalid stage: {}\", stage_str)\n                }));\n            }\n        };\n\n        // Load or create session meta\n        let mut meta = load_session_meta(&self.session_id)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?\n            .unwrap_or_else(|| SessionMeta {\n                session_id: self.session_id.clone(),\n                created_at: chrono::Utc::now(),\n                current_stage: Some(Stage::Check),\n                restart_reason: None,\n            });\n\n        // Set restart information by updating current_stage and reason\n        meta.current_stage = Some(stage);\n        meta.restart_reason = Some(reason.to_string());\n\n        // Save session meta\n        save_session_meta(&self.session_id, &meta)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"restart_scheduled\",\n            \"stage\": stage_str,\n            \"reason\": reason,\n            \"message\": format!(\"Pipeline will restart from {} stage. User should re-run with 'cowork revert --from {}' command.\", stage_str, stage_str)\n        }))\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 4.0,
      "lines_of_code": 91,
      "number_of_classes": 1,
      "number_of_functions": 5
    },
    "dependencies": [
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 2,
        "name": "crate::data",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 3,
        "name": "crate::storage",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 4,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 5,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 6,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 7,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component implements a session-scoped tool that enables restarting a pipeline workflow from specific stages (prd, design, plan, coding). It handles stage validation, session metadata loading/creation, updating restart information, and saving the updated metadata. The tool is designed for critical situations where workflow needs to revert to earlier phases.",
    "interfaces": [
      {
        "description": "Creates new GotoStageTool instance with session context",
        "interface_type": "constructor",
        "name": "new",
        "parameters": [
          {
            "description": "Session identifier for tool instantiation",
            "is_optional": false,
            "name": "session_id",
            "param_type": "String"
          }
        ],
        "return_type": "GotoStageTool",
        "visibility": "public"
      },
      {
        "description": "Returns tool identifier name",
        "interface_type": "method",
        "name": "name",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns detailed tool functionality description",
        "interface_type": "method",
        "name": "description",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Defines JSON schema for tool parameters",
        "interface_type": "method",
        "name": "parameters_schema",
        "parameters": [],
        "return_type": "Option<Value>",
        "visibility": "public"
      },
      {
        "description": "Main execution logic for stage restart functionality",
        "interface_type": "method",
        "name": "execute",
        "parameters": [
          {
            "description": "Tool execution context",
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": "Input arguments as JSON value",
            "is_optional": false,
            "name": "args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Validate and parse stage input parameters",
      "Load or create session metadata",
      "Update session stage and restart reason",
      "Persist session metadata changes",
      "Provide clear restart status and user instructions"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": "Tools for modify workflow - Save/Load ChangeRequest and PatchMetadata",
      "file_path": "crates/cowork-core/src/tools/modify_tools.rs",
      "functions": [
        "SaveChangeRequestTool::new",
        "SaveChangeRequestTool::name",
        "SaveChangeRequestTool::description",
        "SaveChangeRequestTool::parameters_schema",
        "SaveChangeRequestTool::execute",
        "LoadChangeRequestTool::new",
        "LoadChangeRequestTool::name",
        "LoadChangeRequestTool::description",
        "LoadChangeRequestTool::parameters_schema",
        "LoadChangeRequestTool::execute"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "SaveChangeRequestTool",
        "LoadChangeRequestTool"
      ],
      "name": "modify_tools.rs",
      "source_summary": "// Tools for modify workflow - Save/Load ChangeRequest and PatchMetadata\nuse crate::data::*;\nuse crate::storage::*;\nuse adk_core::{Tool, ToolContext, AdkError};\nuse async_trait::async_trait;\nuse serde_json::{json, Value};\nuse std::sync::Arc;\n\n// ============================================================================\n// SaveChangeRequestTool\n// ============================================================================\n\npub struct SaveChangeRequestTool {\n    session_id: String,\n}\n\nimpl SaveChangeRequestTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for SaveChangeRequestTool {\n    fn name(&self) -> &str {\n        \"save_change_request\"\n    }\n\n    fn description(&self) -> &str {\n        \"Save the analyzed ChangeRequest. This is the output of the Change Triage Agent.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"requires_prd_update\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Does PRD need updating?\"\n                },\n                \"requires_design_update\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Does design need updating?\"\n                },\n                \"requires_plan_update\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Does plan need updating?\"\n                },\n                \"requires_code_change\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Does code need changing?\"\n                },\n                \"affected_components\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"List of component IDs affected\"\n                },\n                \"affected_features\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"List of feature IDs affected\"\n                },\n                \"risk_level\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"low\", \"medium\", \"high\"],\n                    \"description\": \"Risk assessment\"\n                },\n                \"estimated_effort\": {\n                    \"type\": \"string\",\n                    \"description\": \"Brief effort estimate\"\n                },\n                \"acceptance_criteria\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"What defines 'done'\"\n                },\n                \"constraints\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"Things to preserve\"\n                }\n            },\n            \"required\": [\"requires_prd_update\", \"requires_design_update\", \"requires_plan_update\", \"requires_code_change\", \"risk_level\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        // Load existing change request\n        let mut change_request = load_change_request(&self.session_id)\n            .map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        // Update scope\n        change_request.scope.requires_prd_update = args[\"requires_prd_update\"].as_bool().unwrap_or(false);\n        change_request.scope.requires_design_update = args[\"requires_design_update\"].as_bool().unwrap_or(false);\n        change_request.scope.requires_plan_update = args[\"requires_plan_update\"].as_bool().unwrap_or(false);\n        change_request.scope.requires_code_change = args[\"requires_code_change\"].as_bool().unwrap_or(true);\n\n        // Update analysis\n        let risk_level = match args[\"risk_level\"].as_str().unwrap_or(\"medium\") {\n            \"low\" => RiskLevel::Low,\n            \"high\" => RiskLevel::High,\n            _ => RiskLevel::Medium,\n        };\n\n        let analysis = ChangeAnalysis {\n            affected_components: args.get(\"affected_components\")\n                .and_then(|v| v.as_array())\n                .map(|arr| arr.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect())\n                .unwrap_or_default(),\n            affected_features: args.get(\"affected_features\")\n                .and_then(|v| v.as_array())\n                .map(|arr| arr.iter().filter_map(|v| v.as_str().map(|s| s.to_string())).collect())\n                .unwrap_or_default(),\n            risk_level,\n            estimated_effort: args.get(\"estimated_effort\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown\")\n                .to_string(),\n        };\n\n        change_request.analysis = Some(analysis);\n\n        // Update acceptance criteria\n        if let Some(criteria) = args.get(\"acceptance_criteria\").and_then(|v| v.as_array()) {\n            change_request.acceptance_criteria = criteria.iter()\n                .filter_map(|v| v.as_str().map(|s| s.to_string()))\n                .collect();\n        }\n\n        // Update constraints\n        if let Some(constraints) = args.get(\"constraints\").and_then(|v| v.as_array()) {\n            change_request.constraints = constraints.iter()\n                .filter_map(|v| v.as_str().map(|s| s.to_string()))\n                .collect();\n        }\n\n        // Save\n        save_change_request(&self.session_id, &change_request)\n            .map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        println!(\"âœ… Change request analyzed and saved\");\n        println!(\"   Scope: PRD={}, Design={}, Plan={}, Code={}\",\n            change_request.scope.requires_prd_update,\n            change_request.scope.requires_design_update,\n            change_request.scope.requires_plan_update,\n            change_request.scope.requires_code_change);\n        println!(\"   Risk: {:?}\", change_request.analysis.as_ref().unwrap().risk_level);\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"message\": \"Change request saved successfully\"\n        }))\n    }\n}\n\n// ============================================================================\n// LoadChangeRequestTool\n// ============================================================================\n\npub struct LoadChangeRequestTool {\n    session_id: String,\n}\n\nimpl LoadChangeRequestTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for LoadChangeRequestTool {\n    fn name(&self) -> &str {\n        \"load_change_request\"\n    }\n\n    fn description(&self) -> &str {\n        \"Load the ChangeRequest for this session. Use this to understand what needs to be implemented.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\"type\": \"object\", \"properties\": {}}))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, _args: Value) -> adk_core::Result<Value> {\n        let change_request = load_change_request(&self.session_id)\n            .map_err(|e| AdkError::Tool(e.to_string()))?;\n\n        Ok(serde_json::to_value(change_request)\n            .map_err(|e| AdkError::Tool(e.to_string()))?)\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 8.0,
      "lines_of_code": 191,
      "number_of_classes": 2,
      "number_of_functions": 10
    },
    "dependencies": [
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": 2,
        "name": "crate::data::*",
        "path": "crate::data",
        "version": null
      },
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": 3,
        "name": "crate::storage::*",
        "path": "crate::storage",
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": 4,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": 5,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": 6,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 7,
        "name": "std::sync::Arc",
        "path": "std::sync",
        "version": null
      }
    ],
    "detailed_description": "This component provides specialized tools for managing change requests in a workflow system. It contains two main tools: SaveChangeRequestTool for persisting analyzed change requests with comprehensive scope analysis, and LoadChangeRequestTool for retrieving stored change requests. The SaveChangeRequestTool handles updating change request scope (PRD, design, plan, code changes), risk analysis, affected components/features, effort estimation, acceptance criteria, and constraints. Both tools operate within a session context and integrate with storage systems to persist and retrieve change request data.",
    "interfaces": [
      {
        "description": "Tool for saving analyzed change requests with comprehensive scope and risk analysis",
        "interface_type": "struct",
        "name": "SaveChangeRequestTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Constructor for SaveChangeRequestTool",
        "interface_type": "method",
        "name": "SaveChangeRequestTool::new",
        "parameters": [
          {
            "description": "Session identifier for change request context",
            "is_optional": false,
            "name": "session_id",
            "param_type": "String"
          }
        ],
        "return_type": "SaveChangeRequestTool",
        "visibility": "public"
      },
      {
        "description": "Returns tool name identifier",
        "interface_type": "method",
        "name": "SaveChangeRequestTool::name",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns tool description",
        "interface_type": "method",
        "name": "SaveChangeRequestTool::description",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Defines JSON schema for tool parameters",
        "interface_type": "method",
        "name": "SaveChangeRequestTool::parameters_schema",
        "parameters": [],
        "return_type": "Option<Value>",
        "visibility": "public"
      },
      {
        "description": "Executes the change request saving operation",
        "interface_type": "method",
        "name": "SaveChangeRequestTool::execute",
        "parameters": [
          {
            "description": "Tool execution context",
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": "JSON arguments for tool execution",
            "is_optional": false,
            "name": "args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      },
      {
        "description": "Tool for loading previously saved change requests",
        "interface_type": "struct",
        "name": "LoadChangeRequestTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Constructor for LoadChangeRequestTool",
        "interface_type": "method",
        "name": "LoadChangeRequestTool::new",
        "parameters": [
          {
            "description": "Session identifier for change request context",
            "is_optional": false,
            "name": "session_id",
            "param_type": "String"
          }
        ],
        "return_type": "LoadChangeRequestTool",
        "visibility": "public"
      },
      {
        "description": "Returns tool name identifier",
        "interface_type": "method",
        "name": "LoadChangeRequestTool::name",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns tool description",
        "interface_type": "method",
        "name": "LoadChangeRequestTool::description",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Defines JSON schema for tool parameters (empty)",
        "interface_type": "method",
        "name": "LoadChangeRequestTool::parameters_schema",
        "parameters": [],
        "return_type": "Option<Value>",
        "visibility": "public"
      },
      {
        "description": "Executes the change request loading operation",
        "interface_type": "method",
        "name": "LoadChangeRequestTool::execute",
        "parameters": [
          {
            "description": "Tool execution context",
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": "JSON arguments for tool execution",
            "is_optional": false,
            "name": "_args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Change request persistence management",
      "Change request scope analysis and updating",
      "Risk assessment and analysis data handling",
      "Session-based change request lifecycle management",
      "Tool interface implementation for workflow integration"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": null,
      "file_path": "crates/cowork-core/src/tools/control_tools.rs",
      "functions": [
        "ProvideFeedbackTool::new",
        "RequestReplanningTool::new",
        "RequestReplanningTool::name",
        "RequestReplanningTool::description",
        "RequestReplanningTool::parameters_schema",
        "RequestReplanningTool::execute",
        "ProvideFeedbackTool::name",
        "ProvideFeedbackTool::description",
        "ProvideFeedbackTool::parameters_schema",
        "ProvideFeedbackTool::execute",
        "AskUserTool::name",
        "AskUserTool::description",
        "AskUserTool::parameters_schema",
        "AskUserTool::execute"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "Tool"
      ],
      "name": "control_tools.rs",
      "source_summary": "// Control tools - provide_feedback, ask_user, etc. (Session-scoped)\nuse crate::data::*;\nuse crate::storage::*;\nuse adk_core::{Tool, ToolContext};\n\nuse async_trait::async_trait;\nuse dialoguer::{Confirm, Input};\nuse serde_json::{json, Value};\nuse std::sync::Arc;\n\n// ============================================================================\n// ProvideFeedbackTool\n// ============================================================================\n\npub struct ProvideFeedbackTool {\n    session_id: String,\n}\n\nimpl ProvideFeedbackTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n// ============================================================================\n// RequestReplanningTool\n// ============================================================================\n\npub struct RequestReplanningTool {\n    session_id: String,\n}\n\nimpl RequestReplanningTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for RequestReplanningTool {\n    fn name(&self) -> &str {\n        \"request_replanning\"\n    }\n\n    fn description(&self) -> &str {\n        \"Request replanning when you discover fundamental issues with the current plan \\\n         during implementation. This records the request and provides guidance to revisit \\\n         the planning phase. Use this for major architectural issues, not minor task adjustments.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"issue_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"design_flaw\", \"missing_dependency\", \"architecture_conflict\", \"requirement_mismatch\"],\n                    \"description\": \"Type of issue requiring replanning\"\n                },\n                \"severity\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"critical\", \"major\", \"moderate\"],\n                    \"description\": \"How severe is this issue\"\n                },\n                \"details\": {\n                    \"type\": \"string\",\n                    \"description\": \"Detailed description of the problem\"\n                },\n                \"affected_features\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"Feature IDs affected by this issue\"\n                },\n                \"suggested_approach\": {\n                    \"type\": \"string\",\n                    \"description\": \"Your suggested approach to resolve this (optional)\"\n                }\n            },\n            \"required\": [\"issue_type\", \"severity\", \"details\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        use crate::data::{Feedback, FeedbackType, Severity};\n        use crate::storage::append_feedback;\n\n        let issue_type = args.get(\"issue_type\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| adk_core::AdkError::Tool(\"Missing 'issue_type'\".to_string()))?;\n\n        let severity_str = args.get(\"severity\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| adk_core::AdkError::Tool(\"Missing 'severity'\".to_string()))?;\n\n        let details = args.get(\"details\")\n            .and_then(|v| v.as_str())\n            .ok_or_else(|| adk_core::AdkError::Tool(\"Missing 'details'\".to_string()))?;\n\n        let severity = match severity_str {\n            \"critical\" => Severity::Critical,\n            \"major\" => Severity::Major,\n            _ => Severity::Minor,\n        };\n\n        let affected_features: Vec<String> = args.get(\"affected_features\")\n            .and_then(|v| v.as_array())\n            .map(|arr| arr.iter()\n                .filter_map(|v| v.as_str().map(String::from))\n                .collect())\n            .unwrap_or_default();\n\n        let suggested_approach = args.get(\"suggested_approach\")\n            .and_then(|v| v.as_str());\n\n        // Compose detailed feedback message\n        let mut feedback_details = format!(\n            \"REPLANNING REQUEST\\n\\\n             Issue Type: {}\\n\\\n             Severity: {}\\n\\\n             Details: {}\\n\",\n            issue_type, severity_str, details\n        );\n\n        if !affected_features.is_empty() {\n            feedback_details.push_str(&format!(\"Affected Features: {}\\n\", affected_features.join(\", \")));\n        }\n\n        if let Some(approach) = suggested_approach {\n            feedback_details.push_str(&format!(\"Suggested Approach: {}\\n\", approach));\n        }\n\n        // Record as critical feedback\n        let feedback = Feedback {\n            feedback_type: FeedbackType::MissingRequirement, // Use this to indicate planning issue\n            severity,\n            details: feedback_details.clone(),\n            suggested_fix: suggested_approach.map(String::from),\n            timestamp: chrono::Utc::now(),\n        };\n\n        append_feedback(&self.session_id, &feedback)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        // Print warning to console\n        println!(\"\\nâš ï¸  REPLANNING REQUESTED âš ï¸\");\n        println!(\"Type: {} | Severity: {}\", issue_type, severity_str);\n        println!(\"Details: {}\", details);\n        if !affected_features.is_empty() {\n            println!(\"Affected: {}\", affected_features.join(\", \"));\n        }\n        println!();\n\n        let message = format!(\n            \"Replanning request recorded with {} severity. \\\n             The coding loop will continue, but this issue should be addressed. \\\n             Consider using 'goto_stage' in the check phase if fundamental changes are needed.\",\n            severity_str\n        );\n\n        Ok(json!({\n            \"status\": \"replanning_requested\",\n            \"issue_type\": issue_type,\n            \"severity\": severity_str,\n            \"affected_features\": affected_features,\n            \"message\": message,\n            \"guidance\": \"Continue with current implementation if possible, or mark tasks as blocked. \\\n                        The Check Agent will review this request and may trigger goto_stage if needed.\"\n        }))\n    }\n}\n\n\n#[async_trait]\nimpl Tool for ProvideFeedbackTool {\n    fn name(&self) -> &str {\n        \"provide_feedback\"\n    }\n\n    fn description(&self) -> &str {\n        \"Provide structured feedback to the Actor agent. \\\n         This feedback will be visible to the Actor in the next iteration.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"feedback_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"build_error\", \"quality_issue\", \"missing_requirement\", \"suggestion\"],\n                },\n                \"severity\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"critical\", \"major\", \"minor\"],\n                },\n                \"details\": {\"type\": \"string\"},\n                \"suggested_fix\": {\"type\": \"string\"}\n            },\n            \"required\": [\"feedback_type\", \"severity\", \"details\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let feedback_type = match args[\"feedback_type\"].as_str().unwrap() {\n            \"build_error\" => FeedbackType::BuildError,\n            \"quality_issue\" => FeedbackType::QualityIssue,\n            \"missing_requirement\" => FeedbackType::MissingRequirement,\n            _ => FeedbackType::Suggestion,\n        };\n\n        let severity = match args[\"severity\"].as_str().unwrap() {\n            \"critical\" => Severity::Critical,\n            \"major\" => Severity::Major,\n            _ => Severity::Minor,\n        };\n\n        let feedback = Feedback {\n            feedback_type,\n            severity,\n            details: args[\"details\"].as_str().unwrap().to_string(),\n            suggested_fix: args\n                .get(\"suggested_fix\")\n                .and_then(|v| v.as_str())\n                .map(String::from),\n            timestamp: chrono::Utc::now(),\n        };\n\n        append_feedback(&self.session_id, &feedback).map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"feedback_recorded\",\n            \"message\": \"Feedback will be available to Actor in next iteration\"\n        }))\n    }\n}\n\n// ============================================================================\n// AskUserTool\n// ============================================================================\n\npub struct AskUserTool;\n\n#[async_trait]\nimpl Tool for AskUserTool {\n    fn name(&self) -> &str {\n        \"ask_user\"\n    }\n\n    fn description(&self) -> &str {\n        \"Ask the user for confirmation or input via CLI interface.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"question\": {\n                    \"type\": \"string\",\n                    \"description\": \"The question to ask the user\"\n                },\n                \"question_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"yes_no\", \"text_input\"],\n                    \"description\": \"Type of question\"\n                }\n            },\n            \"required\": [\"question\", \"question_type\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let question = args[\"question\"].as_str().unwrap();\n        let question_type = args[\"question_type\"].as_str().unwrap();\n\n        match question_type {\n            \"yes_no\" => {\n                let answer = Confirm::new()\n                    .with_prompt(question)\n                    .default(false)\n                    .interact()\n                    .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n                Ok(json!({\n                    \"answer\": answer,\n                    \"answer_type\": \"boolean\"\n                }))\n            }\n            \"text_input\" => {\n                let answer: String = Input::new()\n                    .with_prompt(question)\n                    .interact_text()\n                    .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n                Ok(json!({\n                    \"answer\": answer,\n                    \"answer_type\": \"text\"\n                }))\n            }\n            _ => Ok(json!({\"error\": \"Invalid question type\"})),\n        }\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 16.0,
      "lines_of_code": 302,
      "number_of_classes": 3,
      "number_of_functions": 14
    },
    "dependencies": [
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": null,
        "name": "crate::data",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": null,
        "name": "crate::storage",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "dialoguer",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "chrono",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "adk_core::AdkError",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component implements three CLI-based interactive tools for a session-aware AI agent system: ProvideFeedbackTool, RequestReplanningTool, and AskUserTool. These tools enable the agent to communicate structured feedback, request replanning due to architectural issues, and interact with the human user via command-line prompts. Each tool implements the Tool trait from adk_core, allowing them to be invoked as part of an agent's execution loop. The tools operate within the context of a session_id, persisting feedback to storage and providing structured JSON responses to the calling agent. The implementation uses serde_json for response formatting, dialoguer for interactive input, and chrono for timestamping feedback records.",
    "interfaces": [
      {
        "description": null,
        "interface_type": "trait",
        "name": "Tool",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "_ctx",
            "param_type": "Arc<dyn ToolContext>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "args",
            "param_type": "Value"
          }
        ],
        "return_type": "adk_core::Result<Value>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Provide structured feedback to the Actor agent for next iteration",
      "Request replanning for critical architectural issues during implementation",
      "Interact with human user via CLI for confirmation or input",
      "Persist feedback and replanning requests to storage with session context",
      "Validate and sanitize input parameters before processing"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "tool",
      "description": "Artifact operation tools for Delivery Agent (Session-scoped)",
      "file_path": "crates/cowork-core/src/tools/artifact_tools.rs",
      "functions": [
        "SaveDeliveryReportTool::new",
        "SaveDeliveryReportTool::execute",
        "SavePrdDocTool::new",
        "SavePrdDocTool::execute",
        "SaveDesignDocTool::new",
        "SaveDesignDocTool::execute",
        "LoadFeedbackHistoryTool::new",
        "LoadFeedbackHistoryTool::execute"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "SaveDeliveryReportTool",
        "SavePrdDocTool",
        "SaveDesignDocTool",
        "LoadFeedbackHistoryTool"
      ],
      "name": "artifact_tools.rs",
      "source_summary": "// Artifact operation tools for Delivery Agent (Session-scoped)\nuse crate::storage::*;\nuse adk_core::{Tool, ToolContext};\nuse async_trait::async_trait;\nuse serde_json::{json, Value};\nuse std::sync::Arc;\n\n// ============================================================================\n// SaveDeliveryReportTool\n// ============================================================================\n\npub struct SaveDeliveryReportTool {\n    session_id: String,\n}\n\nimpl SaveDeliveryReportTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for SaveDeliveryReportTool {\n    fn name(&self) -> &str {\n        \"save_delivery_report\"\n    }\n\n    fn description(&self) -> &str {\n        \"Save the delivery report markdown document.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"content\": {\n                    \"type\": \"string\",\n                    \"description\": \"Markdown content of the delivery report\"\n                }\n            },\n            \"required\": [\"content\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let content = args[\"content\"].as_str()\n            .or_else(|| args[\" content\"].as_str()) // Handle LLM adding space before key\n            .ok_or_else(|| adk_core::AdkError::Tool(\"Missing 'content' parameter\".to_string()))?;\n        \n        save_delivery_report(&self.session_id, content)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"message\": \"Delivery report saved successfully\"\n        }))\n    }\n}\n\n// ============================================================================\n// SavePrdDocTool\n// ============================================================================\n\npub struct SavePrdDocTool {\n    session_id: String,\n}\n\nimpl SavePrdDocTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for SavePrdDocTool {\n    fn name(&self) -> &str {\n        \"save_prd_doc\"\n    }\n\n    fn description(&self) -> &str {\n        \"Save the PRD (Product Requirements Document) markdown file.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"content\": {\n                    \"type\": \"string\",\n                    \"description\": \"Markdown content of the PRD document\"\n                }\n            },\n            \"required\": [\"content\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let content = args[\"content\"].as_str()\n            .or_else(|| args[\" content\"].as_str()) // Handle LLM adding space before key\n            .ok_or_else(|| adk_core::AdkError::Tool(\"Missing 'content' parameter\".to_string()))?;\n        \n        save_prd_doc(&self.session_id, content)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"message\": \"PRD document saved successfully\"\n        }))\n    }\n}\n\n// ============================================================================\n// SaveDesignDocTool\n// ============================================================================\n\npub struct SaveDesignDocTool {\n    session_id: String,\n}\n\nimpl SaveDesignDocTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for SaveDesignDocTool {\n    fn name(&self) -> &str {\n        \"save_design_doc\"\n    }\n\n    fn description(&self) -> &str {\n        \"Save the Design Document markdown file.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {\n                \"content\": {\n                    \"type\": \"string\",\n                    \"description\": \"Markdown content of the design document\"\n                }\n            },\n            \"required\": [\"content\"]\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, args: Value) -> adk_core::Result<Value> {\n        let content = args[\"content\"].as_str()\n            .or_else(|| args[\" content\"].as_str()) // Handle LLM adding space before key\n            .ok_or_else(|| adk_core::AdkError::Tool(\"Missing 'content' parameter\".to_string()))?;\n        \n        save_design_doc(&self.session_id, content)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        Ok(json!({\n            \"status\": \"success\",\n            \"message\": \"Design document saved successfully\"\n        }))\n    }\n}\n\n// ============================================================================\n// LoadFeedbackHistoryTool\n// ============================================================================\n\npub struct LoadFeedbackHistoryTool {\n    session_id: String,\n}\n\nimpl LoadFeedbackHistoryTool {\n    pub fn new(session_id: String) -> Self {\n        Self { session_id }\n    }\n}\n\n#[async_trait]\nimpl Tool for LoadFeedbackHistoryTool {\n    fn name(&self) -> &str {\n        \"load_feedback_history\"\n    }\n\n    fn description(&self) -> &str {\n        \"Load the feedback history from all development stages.\"\n    }\n\n    fn parameters_schema(&self) -> Option<Value> {\n        Some(json!({\n            \"type\": \"object\",\n            \"properties\": {}\n        }))\n    }\n\n    async fn execute(&self, _ctx: Arc<dyn ToolContext>, _args: Value) -> adk_core::Result<Value> {\n        let history = load_feedback_history(&self.session_id)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?;\n\n        Ok(serde_json::to_value(history)\n            .map_err(|e| adk_core::AdkError::Tool(e.to_string()))?)\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 6.0,
      "lines_of_code": 202,
      "number_of_classes": 4,
      "number_of_functions": 8
    },
    "dependencies": [
      {
        "dependency_type": "internal_module",
        "is_external": false,
        "line_number": 2,
        "name": "crate::storage",
        "path": "crate::storage::*",
        "version": null
      },
      {
        "dependency_type": "external_library",
        "is_external": true,
        "line_number": 3,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external_library",
        "is_external": true,
        "line_number": 4,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external_library",
        "is_external": true,
        "line_number": 5,
        "name": "serde_json",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 6,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component provides session-scoped artifact operation tools for a Delivery Agent system. It contains four main tools: SaveDeliveryReportTool for saving delivery reports, SavePrdDocTool for saving Product Requirements Documents, SaveDesignDocTool for saving design documents, and LoadFeedbackHistoryTool for loading feedback history. Each tool implements the Tool trait with async execution capabilities and follows a consistent pattern of accepting markdown content parameters for saving operations.",
    "interfaces": [
      {
        "description": "Tool for saving delivery report markdown documents",
        "interface_type": "struct",
        "name": "SaveDeliveryReportTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Tool for saving Product Requirements Document markdown files",
        "interface_type": "struct",
        "name": "SavePrdDocTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Tool for saving Design Document markdown files",
        "interface_type": "struct",
        "name": "SaveDesignDocTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Tool for loading feedback history from development stages",
        "interface_type": "struct",
        "name": "LoadFeedbackHistoryTool",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Provide artifact storage operations for delivery reports",
      "Handle PRD document persistence",
      "Manage design document storage operations",
      "Load and retrieve feedback history data",
      "Implement Tool interface for agent integration"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "middleware",
      "description": "Rate-limited LLM wrapper middleware that introduces delays before API calls",
      "file_path": "crates/cowork-core/src/llm/rate_limiter.rs",
      "functions": [
        "new",
        "with_default_delay",
        "name",
        "generate_content"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "RateLimitedLlm::new",
        "RateLimitedLlm::with_default_delay",
        "RateLimitedLlm::name",
        "RateLimitedLlm::generate_content",
        "Llm::name",
        "Llm::generate_content"
      ],
      "name": "rate_limiter.rs",
      "source_summary": "// Rate-limited LLM wrapper\nuse adk_core::{Llm, LlmRequest, LlmResponseStream};\nuse async_trait::async_trait;\nuse std::sync::Arc;\nuse tokio::time::{sleep, Duration};\n\n/// A wrapper around any Llm implementation that adds rate limiting\n/// by introducing a delay before each API call.\npub struct RateLimitedLlm {\n    inner: Arc<dyn Llm>,\n    delay_ms: u64,\n}\n\nimpl RateLimitedLlm {\n    /// Create a new rate-limited LLM wrapper\n    ///\n    /// # Arguments\n    /// * `inner` - The underlying LLM implementation\n    /// * `delay_ms` - Delay in milliseconds before each API call\n    pub fn new(inner: Arc<dyn Llm>, delay_ms: u64) -> Self {\n        Self { inner, delay_ms }\n    }\n\n    /// Create with 2-second delay (for <30 calls per minute limit)\n    pub fn with_default_delay(inner: Arc<dyn Llm>) -> Self {\n        Self::new(inner, 2000) // 2 seconds = 2000ms\n    }\n}\n\n#[async_trait]\nimpl Llm for RateLimitedLlm {\n    fn name(&self) -> &str {\n        self.inner.name()\n    }\n\n    async fn generate_content(\n        &self,\n        req: LlmRequest,\n        stream: bool,\n    ) -> adk_core::Result<LlmResponseStream> {\n        // Wait before making the API call\n        sleep(Duration::from_millis(self.delay_ms)).await;\n        \n        // Delegate to the inner LLM\n        self.inner.generate_content(req, stream).await\n    }\n}\n\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 3.0,
      "lines_of_code": 48,
      "number_of_classes": 1,
      "number_of_functions": 4
    },
    "dependencies": [
      {
        "dependency_type": "crate",
        "is_external": true,
        "line_number": 2,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "crate",
        "is_external": true,
        "line_number": 3,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 4,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "crate",
        "is_external": true,
        "line_number": 5,
        "name": "tokio::time",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component implements a rate limiting middleware wrapper for LLM (Large Language Model) implementations. It wraps any LLM implementation and adds a configurable delay before each API call to enforce rate limiting. The component provides two constructors: one with custom delay configuration and another with a default 2-second delay suitable for <30 calls per minute rate limits. The middleware implements the Llm trait, delegating actual LLM operations to the wrapped implementation while enforcing rate limiting through pre-call delays.",
    "interfaces": [
      {
        "description": "Create a new rate-limited LLM wrapper with custom delay",
        "interface_type": "constructor",
        "name": "new",
        "parameters": [
          {
            "description": "The underlying LLM implementation",
            "is_optional": false,
            "name": "inner",
            "param_type": "Arc<dyn Llm>"
          },
          {
            "description": "Delay in milliseconds before each API call",
            "is_optional": false,
            "name": "delay_ms",
            "param_type": "u64"
          }
        ],
        "return_type": "Self",
        "visibility": "public"
      },
      {
        "description": "Create with 2-second delay (for <30 calls per minute limit)",
        "interface_type": "constructor",
        "name": "with_default_delay",
        "parameters": [
          {
            "description": "The underlying LLM implementation",
            "is_optional": false,
            "name": "inner",
            "param_type": "Arc<dyn Llm>"
          }
        ],
        "return_type": "Self",
        "visibility": "public"
      },
      {
        "description": "Get the name of the wrapped LLM implementation",
        "interface_type": "method",
        "name": "name",
        "parameters": [
          {
            "description": "Reference to self",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          }
        ],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Generate content with rate limiting delay",
        "interface_type": "method",
        "name": "generate_content",
        "parameters": [
          {
            "description": "Reference to self",
            "is_optional": false,
            "name": "self",
            "param_type": "&Self"
          },
          {
            "description": "LLM request object",
            "is_optional": false,
            "name": "req",
            "param_type": "LlmRequest"
          },
          {
            "description": "Whether to stream the response",
            "is_optional": false,
            "name": "stream",
            "param_type": "bool"
          }
        ],
        "return_type": "adk_core::Result<LlmResponseStream>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Enforce rate limiting on LLM API calls by introducing configurable delays",
      "Wrap and delegate to underlying LLM implementations transparently",
      "Provide rate limiting configuration flexibility through multiple constructors",
      "Maintain compatibility with Llm trait interface while adding rate limiting functionality",
      "Ensure thread-safe operation through Arc-based shared ownership"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Human-in-the-Loop (HITL) resilient agent wrapper that provides error recovery and user intervention capabilities",
      "file_path": "crates/cowork-core/src/agents/hitl.rs",
      "functions": [
        "new",
        "name",
        "description",
        "sub_agents",
        "run",
        "handle_error",
        "start_retry"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "ResilientAgent::new",
        "ResilientAgent::name",
        "ResilientAgent::description",
        "ResilientAgent::sub_agents",
        "ResilientAgent::run",
        "ResilientAgent::handle_error",
        "ResilientStream::new",
        "ResilientStream::start_retry",
        "ResilientStream::poll_next"
      ],
      "name": "hitl.rs",
      "source_summary": "use adk_core::{Agent, Event, AdkError, InvocationContext};\nuse async_trait::async_trait;\nuse std::sync::Arc;\nuse std::pin::Pin;\nuse std::task::{Context as TaskContext, Poll};\nuse futures::{Stream, Future};\nuse dialoguer::{Select, Input, theme::ColorfulTheme};\n\npub struct ResilientAgent {\n    inner: Arc<dyn Agent>,\n    subs: Vec<Arc<dyn Agent>>,\n}\n\nimpl ResilientAgent {\n    pub fn new(inner: Arc<dyn Agent>) -> Self {\n        Self {\n            inner: inner.clone(),\n            subs: vec![inner],\n        }\n    }\n}\n\ntype AgentOutput = Pin<Box<dyn Stream<Item = Result<Event, AdkError>> + Send>>;\n\n#[async_trait]\nimpl Agent for ResilientAgent {\n    fn name(&self) -> &str {\n        self.inner.name()\n    }\n\n    fn description(&self) -> &str {\n        self.inner.description()\n    }\n\n    fn sub_agents(&self) -> &[Arc<dyn Agent>] {\n        &self.subs\n    }\n\n    async fn run(&self, context: Arc<dyn InvocationContext>) -> Result<AgentOutput, AdkError> {\n        // Initial run\n        match self.inner.run(context.clone()).await {\n            Ok(stream) => {\n                // Wrap the stream to handle errors during iteration\n                Ok(Box::pin(ResilientStream::new(\n                    self.inner.clone(),\n                    context,\n                    stream\n                )))\n            },\n            Err(e) => {\n                // Handle immediate errors (same logic as before, but adapted for consistency)\n                // We can't use the Stream wrapper here easily without a stream.\n                // But we can just use the sync logic here since we are in async fn.\n                let err_msg = e.to_string();\n                if err_msg.contains(\"Max iterations\") {\n                     return self.handle_error(context, e).await;\n                }\n                Err(e)\n            }\n        }\n    }\n}\n\nimpl ResilientAgent {\n    // Helper for immediate errors (recursion in async fn)\n    async fn handle_error(&self, context: Arc<dyn InvocationContext>, e: AdkError) -> Result<AgentOutput, AdkError> {\n         println!(\"\\nâš ï¸  Agent '{}' encountered error: {}\", self.name(), e);\n         println!(\"The agent loop limit has been exceeded.\");\n         \n         let selections = &[\"Retry (reset counter)\", \"Provide Guidance & Retry\", \"Abort\"];\n         let selection = Select::with_theme(&ColorfulTheme::default())\n            .with_prompt(\"How would you like to proceed?\")\n            .default(0)\n            .items(&selections[..])\n            .interact()\n            .unwrap_or(2);\n\n         match selection {\n            0 => {\n                println!(\"ğŸ”„ Retrying agent execution...\");\n                return self.run(context).await;\n            },\n            1 => {\n                let input: String = Input::with_theme(&ColorfulTheme::default())\n                    .with_prompt(\"Please provide guidance for the agent\")\n                    .interact_text()\n                    .unwrap_or_default();\n                \n                if !input.is_empty() {\n                    println!(\"(Note: User guidance provided: '{}' - but context injection is not implemented. Retrying anyway.)\", input);\n                }\n                println!(\"ğŸ”„ Retrying with new guidance...\");\n                return self.run(context).await;\n            },\n            _ => return Err(e),\n         }\n    }\n}\n\n// ============================================================================\n// ResilientStream Implementation\n// ============================================================================\n\nenum StreamState {\n    Streaming(AgentOutput),\n    Retrying(Pin<Box<dyn Future<Output = Result<AgentOutput, AdkError>> + Send>>),\n}\n\nstruct ResilientStream {\n    inner_agent: Arc<dyn Agent>,\n    context: Arc<dyn InvocationContext>,\n    state: StreamState,\n    agent_name: String, // Cached for logging\n}\n\nimpl ResilientStream {\n    fn new(\n        inner_agent: Arc<dyn Agent>,\n        context: Arc<dyn InvocationContext>,\n        stream: AgentOutput,\n    ) -> Self {\n        let agent_name = inner_agent.name().to_string();\n        Self {\n            inner_agent,\n            context,\n            state: StreamState::Streaming(stream),\n            agent_name,\n        }\n    }\n\n    fn start_retry(&mut self) {\n        let agent = self.inner_agent.clone();\n        let ctx = self.context.clone();\n        // Create the future for running the agent again\n        let fut = Box::pin(async move {\n            agent.run(ctx).await\n        });\n        self.state = StreamState::Retrying(fut);\n    }\n}\n\nimpl Stream for ResilientStream {\n    type Item = Result<Event, AdkError>;\n\n    fn poll_next(mut self: Pin<&mut Self>, cx: &mut TaskContext<'_>) -> Poll<Option<Self::Item>> {\n        loop {\n            match &mut self.state {\n                StreamState::Streaming(stream) => {\n                    match stream.as_mut().poll_next(cx) {\n                        Poll::Ready(Some(Err(e))) => {\n                            // Intercept error\n                            let err_msg = e.to_string();\n                            if err_msg.contains(\"Max iterations\") {\n                                println!(\"\\nâš ï¸  Agent '{}' encountered error during stream: {}\", self.agent_name, err_msg);\n                                println!(\"The agent loop limit has been exceeded.\");\n                                \n                                // Blocking interaction\n                                let selections = &[\"Retry (reset counter)\", \"Provide Guidance & Retry\", \"Abort\"];\n                                let selection = Select::with_theme(&ColorfulTheme::default())\n                                    .with_prompt(\"How would you like to proceed?\")\n                                    .default(0)\n                                    .items(&selections[..])\n                                    .interact()\n                                    .unwrap_or(2);\n\n                                match selection {\n                                    0 => {\n                                        println!(\"ğŸ”„ Retrying agent execution...\");\n                                        self.start_retry();\n                                        continue; // Loop to poll the new state\n                                    },\n                                    1 => {\n                                        let input: String = Input::with_theme(&ColorfulTheme::default())\n                                            .with_prompt(\"Please provide guidance for the agent\")\n                                            .interact_text()\n                                            .unwrap_or_default();\n                                        if !input.is_empty() {\n                                            println!(\"(Note: User guidance provided: '{}' - but context injection is not implemented. Retrying anyway.)\", input);\n                                        }\n                                        println!(\"ğŸ”„ Retrying with new guidance...\");\n                                        self.start_retry();\n                                        continue;\n                                    },\n                                    _ => return Poll::Ready(Some(Err(e))),\n                                }\n                            }\n                            return Poll::Ready(Some(Err(e)));\n                        },\n                        Poll::Ready(other) => return Poll::Ready(other),\n                        Poll::Pending => return Poll::Pending,\n                    }\n                },\n                StreamState::Retrying(fut) => {\n                    match fut.as_mut().poll(cx) {\n                        Poll::Ready(Ok(new_stream)) => {\n                            // Retry successful, got new stream\n                            // Wrap it recursively? No, just replace current stream\n                            // But wait, the new stream might also fail later.\n                            // So we just go back to Streaming state with the new stream.\n                            self.state = StreamState::Streaming(new_stream);\n                            continue; // Loop to poll the new stream\n                        },\n                        Poll::Ready(Err(e)) => {\n                            // Retry failed immediately\n                            // We could offer HITL again here, but let's just error out for now to avoid infinite loops of immediate errors\n                            // Or better: recurse logic?\n                            // For simplicity, return the error.\n                            return Poll::Ready(Some(Err(e)));\n                        },\n                        Poll::Pending => return Poll::Pending,\n                    }\n                }\n            }\n        }\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 20.0,
      "lines_of_code": 216,
      "number_of_classes": 2,
      "number_of_functions": 7
    },
    "dependencies": [
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 1,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 2,
        "name": "async_trait",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 3,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 4,
        "name": "std::pin::Pin",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 5,
        "name": "std::task",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 6,
        "name": "futures",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 7,
        "name": "dialoguer",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "The hitl.rs component implements a resilient agent wrapper that provides Human-in-the-Loop (HITL) capabilities for error recovery. It wraps an existing agent and intercepts errors during execution, particularly 'Max iterations' errors, to allow human intervention. The component provides three recovery options: retry with reset counter, provide guidance and retry, or abort. It implements a custom stream wrapper (ResilientStream) that can handle errors during stream processing and restart execution with user guidance.",
    "interfaces": [
      {
        "description": "Creates a new ResilientAgent wrapper",
        "interface_type": "constructor",
        "name": "new",
        "parameters": [
          {
            "description": "The inner agent to wrap with HITL capabilities",
            "is_optional": false,
            "name": "inner",
            "param_type": "Arc<dyn Agent>"
          }
        ],
        "return_type": "Self",
        "visibility": "public"
      },
      {
        "description": "Returns the name of the wrapped agent",
        "interface_type": "method",
        "name": "name",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns the description of the wrapped agent",
        "interface_type": "method",
        "name": "description",
        "parameters": [],
        "return_type": "&str",
        "visibility": "public"
      },
      {
        "description": "Returns the list of sub-agents",
        "interface_type": "method",
        "name": "sub_agents",
        "parameters": [],
        "return_type": "&[Arc<dyn Agent>]",
        "visibility": "public"
      },
      {
        "description": "Executes the agent with error recovery capabilities",
        "interface_type": "method",
        "name": "run",
        "parameters": [
          {
            "description": "The invocation context for agent execution",
            "is_optional": false,
            "name": "context",
            "param_type": "Arc<dyn InvocationContext>"
          }
        ],
        "return_type": "Result<AgentOutput, AdkError>",
        "visibility": "public"
      },
      {
        "description": "Handles immediate execution errors with user interaction",
        "interface_type": "method",
        "name": "handle_error",
        "parameters": [
          {
            "description": "The invocation context",
            "is_optional": false,
            "name": "context",
            "param_type": "Arc<dyn InvocationContext>"
          },
          {
            "description": "The error that occurred",
            "is_optional": false,
            "name": "e",
            "param_type": "AdkError"
          }
        ],
        "return_type": "Result<AgentOutput, AdkError>",
        "visibility": "private"
      }
    ],
    "responsibilities": [
      "Error interception and handling for agent execution failures",
      "Human-in-the-Loop interaction for error recovery decisions",
      "Stream resilience with retry mechanisms during asynchronous processing",
      "Agent lifecycle management with recovery capabilities",
      "User guidance integration for improved agent performance"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": null,
      "file_path": "crates/cowork-core/src/agents/mod.rs",
      "functions": [
        "create_idea_agent",
        "create_prd_loop",
        "create_design_loop",
        "create_plan_loop",
        "create_coding_loop",
        "create_check_agent",
        "create_delivery_agent"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "ResilientAgent"
      ],
      "name": "mod.rs",
      "source_summary": "// Agents module - Agent builders using adk-rust\n// \n// IMPORTANT: This file solves a CRITICAL bug where SequentialAgent stops after\n// the first LoopAgent completes. \n//\n// PROBLEM: When a sub-agent in LoopAgent calls exit_loop(), it terminates the\n// ENTIRE SequentialAgent, not just the LoopAgent. This is adk-rust's design.\n//\n// SOLUTION: Remove exit_loop tools and use max_iterations=1 to let LoopAgent\n// complete naturally, allowing SequentialAgent to continue to next agent.\n\nuse crate::instructions::*;\nuse crate::tools::*;\nuse adk_agent::{LlmAgentBuilder, LoopAgent};\nuse adk_core::{Llm, IncludeContents};\nuse anyhow::Result;\nuse std::sync::Arc;\n\nmod hitl;\nuse hitl::ResilientAgent;\n\n// ============================================================================\n// IdeaAgent - Simple agent to capture initial idea\n// ============================================================================\n\npub fn create_idea_agent(model: Arc<dyn Llm>, session_id: &str) -> Result<Arc<dyn adk_core::Agent>> {\n    let agent = LlmAgentBuilder::new(\"idea_agent\")\n        .instruction(IDEA_AGENT_INSTRUCTION)\n        .model(model)\n        .tool(Arc::new(SaveIdeaTool::new(session_id.to_string())))\n        .tool(Arc::new(LoadIdeaTool::new(session_id.to_string())))\n        .tool(Arc::new(ReviewAndEditContentTool))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    Ok(Arc::new(agent))\n}\n\n// ============================================================================\n// PRD Loop - Actor + Critic with LoopAgent\n// ============================================================================\n\npub fn create_prd_loop(model: Arc<dyn Llm>, session_id: &str) -> Result<Arc<dyn adk_core::Agent>> {\n    let session = session_id.to_string();\n    \n    let prd_actor = LlmAgentBuilder::new(\"prd_actor\")\n        .instruction(PRD_ACTOR_INSTRUCTION)\n        .model(model.clone())\n        .tool(Arc::new(LoadIdeaTool::new(session.clone())))\n        .tool(Arc::new(ReviewWithFeedbackContentTool))\n        .tool(Arc::new(CreateRequirementTool::new(session.clone())))\n        .tool(Arc::new(AddFeatureTool::new(session.clone())))\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(SavePrdDocTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    let prd_critic = LlmAgentBuilder::new(\"prd_critic\")\n        .instruction(PRD_CRITIC_INSTRUCTION)\n        .model(model)\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(ProvideFeedbackTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    let mut loop_agent = LoopAgent::new(\n        \"prd_loop\",\n        vec![Arc::new(prd_actor), Arc::new(prd_critic)],\n    );\n    loop_agent = loop_agent.with_max_iterations(3); // Allow up to 3 attempts for Actor to fix issues\n\n    Ok(Arc::new(ResilientAgent::new(Arc::new(loop_agent))))\n}\n\n// ============================================================================\n// Design Loop - Actor + Critic\n// ============================================================================\n\npub fn create_design_loop(model: Arc<dyn Llm>, session_id: &str) -> Result<Arc<dyn adk_core::Agent>> {\n    let session = session_id.to_string();\n    \n    let design_actor = LlmAgentBuilder::new(\"design_actor\")\n        .instruction(DESIGN_ACTOR_INSTRUCTION)\n        .model(model.clone())\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(GetDesignTool::new(session.clone())))\n        .tool(Arc::new(ReviewWithFeedbackContentTool))\n        .tool(Arc::new(CreateDesignComponentTool::new(session.clone())))\n        .tool(Arc::new(SaveDesignDocTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    let design_critic = LlmAgentBuilder::new(\"design_critic\")\n        .instruction(DESIGN_CRITIC_INSTRUCTION)\n        .model(model)\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(GetDesignTool::new(session.clone())))\n        .tool(Arc::new(CheckFeatureCoverageTool::new(session.clone())))\n        .tool(Arc::new(ProvideFeedbackTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    let mut loop_agent = LoopAgent::new(\"design_loop\", vec![Arc::new(design_actor), Arc::new(design_critic)]);\n    loop_agent = loop_agent.with_max_iterations(3); // Allow up to 3 attempts\n\n    Ok(Arc::new(ResilientAgent::new(Arc::new(loop_agent))))\n}\n\n// ============================================================================\n// Plan Loop - Actor + Critic\n// ============================================================================\n\npub fn create_plan_loop(model: Arc<dyn Llm>, session_id: &str) -> Result<Arc<dyn adk_core::Agent>> {\n    let session = session_id.to_string();\n    \n    let plan_actor = LlmAgentBuilder::new(\"plan_actor\")\n        .instruction(PLAN_ACTOR_INSTRUCTION)\n        .model(model.clone())\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(GetDesignTool::new(session.clone())))\n        .tool(Arc::new(GetPlanTool::new(session.clone())))\n        .tool(Arc::new(ReviewWithFeedbackContentTool))\n        .tool(Arc::new(CreateTaskTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    let plan_critic = LlmAgentBuilder::new(\"plan_critic\")\n        .instruction(PLAN_CRITIC_INSTRUCTION)\n        .model(model)\n        .tool(Arc::new(GetPlanTool::new(session.clone())))\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(GetDesignTool::new(session.clone())))\n        .tool(Arc::new(CheckTaskDependenciesTool::new(session.clone())))\n        .tool(Arc::new(ProvideFeedbackTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    let mut loop_agent = LoopAgent::new(\"plan_loop\", vec![Arc::new(plan_actor), Arc::new(plan_critic)]);\n    loop_agent = loop_agent.with_max_iterations(3); // Allow up to 3 attempts\n\n    Ok(Arc::new(ResilientAgent::new(Arc::new(loop_agent))))\n}\n\n// ============================================================================\n// Coding Loop - Actor + Critic\n// ============================================================================\n\npub fn create_coding_loop(model: Arc<dyn Llm>, session_id: &str) -> Result<Arc<dyn adk_core::Agent>> {\n    let session = session_id.to_string();\n    \n    let coding_actor = LlmAgentBuilder::new(\"coding_actor\")\n        .instruction(CODING_ACTOR_INSTRUCTION)\n        .model(model.clone())\n        .tool(Arc::new(GetPlanTool::new(session.clone())))\n        .tool(Arc::new(UpdateTaskStatusTool::new(session.clone())))\n        .tool(Arc::new(UpdateFeatureStatusTool::new(session.clone())))\n        // Task management tools - NEW\n        .tool(Arc::new(CreateTaskTool::new(session.clone())))\n        .tool(Arc::new(UpdateTaskTool::new(session.clone())))\n        .tool(Arc::new(DeleteTaskTool::new(session.clone())))\n        // File operations\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(WriteFileTool))\n        .tool(Arc::new(ListFilesTool))\n        .tool(Arc::new(RunCommandTool))\n        .tool(Arc::new(CheckTestsTool))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    let coding_critic = LlmAgentBuilder::new(\"coding_critic\")\n        .instruction(CODING_CRITIC_INSTRUCTION)\n        .model(model)\n        .tool(Arc::new(GetPlanTool::new(session.clone())))\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(ListFilesTool))\n        .tool(Arc::new(RunCommandTool))\n        .tool(Arc::new(ProvideFeedbackTool::new(session.clone())))\n        // Replanning request - NEW\n        .tool(Arc::new(RequestReplanningTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    let mut loop_agent = LoopAgent::new(\"coding_loop\", vec![Arc::new(coding_actor), Arc::new(coding_critic)]);\n    loop_agent = loop_agent.with_max_iterations(5);\n\n    Ok(Arc::new(ResilientAgent::new(Arc::new(loop_agent))))\n}\n\n// ============================================================================\n// Check Agent - Quality assurance\n// ============================================================================\n\npub fn create_check_agent(model: Arc<dyn Llm>, session_id: &str) -> Result<Arc<dyn adk_core::Agent>> {\n    let session = session_id.to_string();\n    \n    let agent = LlmAgentBuilder::new(\"check_agent\")\n        .instruction(CHECK_AGENT_INSTRUCTION)\n        .model(model)\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(GetDesignTool::new(session.clone())))\n        .tool(Arc::new(GetPlanTool::new(session.clone())))\n        .tool(Arc::new(CheckDataFormatTool::new(session.clone())))\n        .tool(Arc::new(CheckFeatureCoverageTool::new(session.clone())))\n        .tool(Arc::new(CheckTaskDependenciesTool::new(session.clone())))\n        .tool(Arc::new(RunCommandTool))\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(ListFilesTool))\n        .tool(Arc::new(CheckTestsTool))\n        .tool(Arc::new(CheckLintTool))\n        .tool(Arc::new(ProvideFeedbackTool::new(session.clone())))\n        .tool(Arc::new(GotoStageTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    Ok(Arc::new(agent))\n}\n\n// ============================================================================\n// Delivery Agent - Final report generation\n// ============================================================================\n\npub fn create_delivery_agent(model: Arc<dyn Llm>, session_id: &str) -> Result<Arc<dyn adk_core::Agent>> {\n    let session = session_id.to_string();\n    \n    let agent = LlmAgentBuilder::new(\"delivery_agent\")\n        .instruction(DELIVERY_AGENT_INSTRUCTION)\n        .model(model)\n        .tool(Arc::new(GetRequirementsTool::new(session.clone())))\n        .tool(Arc::new(GetDesignTool::new(session.clone())))\n        .tool(Arc::new(GetPlanTool::new(session.clone())))\n        .tool(Arc::new(LoadFeedbackHistoryTool::new(session.clone())))\n        .tool(Arc::new(ListFilesTool))\n        .tool(Arc::new(ReadFileTool))\n        .tool(Arc::new(SaveDeliveryReportTool::new(session.clone())))\n        .tool(Arc::new(SavePrdDocTool::new(session.clone())))\n        .tool(Arc::new(SaveDesignDocTool::new(session.clone())))\n        .include_contents(IncludeContents::None)\n        .build()?;\n\n    Ok(Arc::new(agent))\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 2.0,
      "lines_of_code": 243,
      "number_of_classes": 1,
      "number_of_functions": 7
    },
    "dependencies": [
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": null,
        "name": "crate::instructions",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": null,
        "name": "crate::tools",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "adk_agent",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "adk_core",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "anyhow",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "std::sync::Arc",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": null,
        "name": "hitl",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": null,
        "name": "async_trait",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component implements a suite of intelligent agent builders for a collaborative AI workflow system. It defines seven high-level agent creation functions that construct LLM-based agents using the adk-rust framework. Each agent serves a distinct phase in a multi-stage development lifecycle: Idea capture, PRD generation, Design, Planning, Coding, Quality Check, and Delivery. The agents are structured as either simple LLM agents or LoopAgents (actor-critic pairs) with max_iterations=3 or 5 to enable iterative refinement. A critical bug fix is implemented by replacing exit_loop() calls with max_iterations limits to prevent premature termination of parent SequentialAgents. The ResilientAgent wrapper from the hitl module provides human-in-the-loop (HITL) recovery for loop iteration failures, allowing user intervention via CLI prompts to retry, provide guidance, or abort.",
    "interfaces": [
      {
        "description": "A wrapper agent that provides human-in-the-loop recovery for agent execution failures, particularly when LoopAgent exceeds max_iterations. It intercepts errors, presents CLI options to the user, and allows retrying with or without guidance.",
        "interface_type": "struct",
        "name": "ResilientAgent",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "inner",
            "param_type": "Arc<dyn Agent>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "subs",
            "param_type": "Vec<Arc<dyn Agent>>"
          }
        ],
        "return_type": null,
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Construct LLM-based agents for each phase of the software development lifecycle",
      "Implement iterative actor-critic loops using LoopAgent with max_iterations to avoid premature termination",
      "Provide resilient agent execution via HITL recovery mechanisms",
      "Encapsulate domain-specific tools and instructions for each agent type",
      "Maintain session state consistency across agent invocations using session_id"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "database",
      "description": "Storage layer for .cowork/ directory implementing session-scoped architecture",
      "file_path": "crates/cowork-core/src/storage/mod.rs",
      "functions": [
        "get_cowork_dir",
        "get_session_dir",
        "get_project_root",
        "cowork_dir_exists",
        "is_project_initialized",
        "load_project_index",
        "save_project_index",
        "init_project_index",
        "save_session_input",
        "load_session_input",
        "save_change_request",
        "load_change_request",
        "save_idea",
        "load_idea",
        "save_prd_doc",
        "save_design_doc",
        "save_delivery_report",
        "state_file_exists",
        "has_requirements",
        "has_design_spec",
        "has_implementation_plan",
        "has_code_metadata",
        "has_code_files",
        "save_requirements",
        "load_requirements",
        "save_feature_list",
        "load_feature_list",
        "save_design_spec",
        "load_design_spec",
        "save_implementation_plan",
        "load_implementation_plan",
        "save_code_metadata",
        "load_code_metadata",
        "save_session_meta",
        "load_session_meta",
        "save_feedback_history",
        "load_feedback_history",
        "append_feedback",
        "save_patch_metadata",
        "load_patch_metadata",
        "init_session_from_base",
        "generate_id",
        "get_latest_successful_session",
        "mark_session_completed",
        "mark_session_failed"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "SessionInput",
        "artifact_path",
        "state_path"
      ],
      "name": "mod.rs",
      "source_summary": "// Storage layer for .cowork/ directory - Session-scoped architecture\nuse crate::data::*;\nuse anyhow::{Context, Result};\nuse std::fs;\nuse std::path::{Path, PathBuf};\n\n#[cfg(test)]\nmod storage_test;\n\nconst COWORK_DIR: &str = \".cowork\";\nconst INDEX_FILE: &str = \"index.json\";\nconst SESSIONS_DIR: &str = \"sessions\";\n\n// ============================================================================\n// Core Directory Structure\n// ============================================================================\n\n/// Get the .cowork directory path, create if not exists\npub fn get_cowork_dir() -> Result<PathBuf> {\n    let path = PathBuf::from(COWORK_DIR);\n    \n    // Create main directory and subdirectories\n    fs::create_dir_all(&path)\n        .with_context(|| format!(\"Failed to create .cowork directory at {:?}\", path))?;\n    fs::create_dir_all(path.join(SESSIONS_DIR))?;\n    \n    Ok(path)\n}\n\n/// Get path for a specific session directory\npub fn get_session_dir(session_id: &str) -> Result<PathBuf> {\n    let cowork_dir = get_cowork_dir()?;\n    let session_path = cowork_dir.join(SESSIONS_DIR).join(session_id);\n    \n    // Create session subdirectories\n    fs::create_dir_all(&session_path)?;\n    fs::create_dir_all(session_path.join(\"artifacts\"))?;\n    fs::create_dir_all(session_path.join(\"state\"))?;\n    fs::create_dir_all(session_path.join(\"patch\"))?;\n    fs::create_dir_all(session_path.join(\"logs\"))?;\n    \n    Ok(session_path)\n}\n\n/// Get the project root directory (where .cowork/ is located)\n/// This is the actual workspace where code files are written\npub fn get_project_root() -> Result<PathBuf> {\n    let current_dir = std::env::current_dir()\n        .with_context(|| \"Failed to get current directory\")?;\n    Ok(current_dir)\n}\n\n/// Check if .cowork directory exists\npub fn cowork_dir_exists() -> bool {\n    Path::new(COWORK_DIR).exists()\n}\n\n/// Check if project has been initialized (has index.json)\npub fn is_project_initialized() -> bool {\n    Path::new(COWORK_DIR).join(INDEX_FILE).exists()\n}\n\n// ============================================================================\n// Project Index (index.json at root of .cowork/)\n// ============================================================================\n\npub fn load_project_index() -> Result<ProjectIndex> {\n    let path = PathBuf::from(COWORK_DIR).join(INDEX_FILE);\n    if !path.exists() {\n        anyhow::bail!(\"Project not initialized. Run 'cowork new' first.\");\n    }\n    let content = fs::read_to_string(&path)\n        .with_context(|| format!(\"Failed to read {:?}\", path))?;\n    let index: ProjectIndex = serde_json::from_str(&content)\n        .with_context(|| \"Failed to parse index.json\")?;\n    Ok(index)\n}\n\npub fn save_project_index(index: &ProjectIndex) -> Result<()> {\n    let cowork_dir = get_cowork_dir()?;\n    let path = cowork_dir.join(INDEX_FILE);\n    let content = serde_json::to_string_pretty(index)?;\n    fs::write(&path, content)\n        .with_context(|| format!(\"Failed to write {:?}\", path))?;\n    Ok(())\n}\n\npub fn init_project_index(project_name: String) -> Result<ProjectIndex> {\n    if is_project_initialized() {\n        anyhow::bail!(\".cowork directory already initialized\");\n    }\n    let index = ProjectIndex::new(project_name);\n    save_project_index(&index)?;\n    Ok(index)\n}\n\n// ============================================================================\n// Session Input (sessions/<id>/input.json)\n// ============================================================================\n\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct SessionInput {\n    pub session_id: String,\n    pub session_type: SessionType,\n    pub description: String,\n    pub base_session_id: Option<String>,\n    pub created_at: chrono::DateTime<chrono::Utc>,\n}\n\npub fn save_session_input(session_id: &str, input: &SessionInput) -> Result<()> {\n    let session_dir = get_session_dir(session_id)?;\n    let path = session_dir.join(\"input.json\");\n    let content = serde_json::to_string_pretty(input)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_session_input(session_id: &str) -> Result<SessionInput> {\n    let session_dir = get_session_dir(session_id)?;\n    let path = session_dir.join(\"input.json\");\n    if !path.exists() {\n        anyhow::bail!(\"Session input not found for session {}\", session_id);\n    }\n    let content = fs::read_to_string(&path)?;\n    let input: SessionInput = serde_json::from_str(&content)?;\n    Ok(input)\n}\n\n// ============================================================================\n// Change Request (sessions/<id>/change_request.json - only for modify sessions)\n// ============================================================================\n\npub fn save_change_request(session_id: &str, change_request: &ChangeRequest) -> Result<()> {\n    let session_dir = get_session_dir(session_id)?;\n    let path = session_dir.join(\"change_request.json\");\n    let content = serde_json::to_string_pretty(change_request)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_change_request(session_id: &str) -> Result<ChangeRequest> {\n    let session_dir = get_session_dir(session_id)?;\n    let path = session_dir.join(\"change_request.json\");\n    if !path.exists() {\n        anyhow::bail!(\"Change request not found for session {}\", session_id);\n    }\n    let content = fs::read_to_string(&path)?;\n    let cr: ChangeRequest = serde_json::from_str(&content)?;\n    Ok(cr)\n}\n\n// ============================================================================\n// Session-scoped Artifacts (sessions/<id>/artifacts/)\n// ============================================================================\n\nfn artifact_path(session_id: &str, filename: &str) -> Result<PathBuf> {\n    let session_dir = get_session_dir(session_id)?;\n    Ok(session_dir.join(\"artifacts\").join(filename))\n}\n\npub fn save_idea(session_id: &str, content: &str) -> Result<()> {\n    let path = artifact_path(session_id, \"idea.md\")?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_idea(session_id: &str) -> Result<String> {\n    let path = artifact_path(session_id, \"idea.md\")?;\n    if !path.exists() {\n        return Ok(String::new());\n    }\n    let content = fs::read_to_string(&path)?;\n    Ok(content)\n}\n\npub fn save_prd_doc(session_id: &str, content: &str) -> Result<()> {\n    let path = artifact_path(session_id, \"prd.md\")?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn save_design_doc(session_id: &str, content: &str) -> Result<()> {\n    let path = artifact_path(session_id, \"design.md\")?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn save_delivery_report(session_id: &str, content: &str) -> Result<()> {\n    let path = artifact_path(session_id, \"delivery_report.md\")?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\n// ============================================================================\n// Session-scoped State (sessions/<id>/state/)\n// ============================================================================\n\nfn state_path(session_id: &str, filename: &str) -> Result<PathBuf> {\n    let session_dir = get_session_dir(session_id)?;\n    Ok(session_dir.join(\"state\").join(filename))\n}\n\npub fn state_file_exists(session_id: &str, filename: &str) -> Result<bool> {\n    Ok(state_path(session_id, filename)?.exists())\n}\n\npub fn has_requirements(session_id: &str) -> Result<bool> {\n    state_file_exists(session_id, \"requirements.json\")\n}\n\npub fn has_design_spec(session_id: &str) -> Result<bool> {\n    state_file_exists(session_id, \"design_spec.json\")\n}\n\npub fn has_implementation_plan(session_id: &str) -> Result<bool> {\n    state_file_exists(session_id, \"implementation_plan.json\")\n}\n\npub fn has_code_metadata(session_id: &str) -> Result<bool> {\n    state_file_exists(session_id, \"code_metadata.json\")\n}\n\n/// Check if coding stage has made progress (has written files)\npub fn has_code_files(session_id: &str) -> Result<bool> {\n    if !has_code_metadata(session_id)? {\n        return Ok(false);\n    }\n    \n    let metadata = load_code_metadata(session_id)?;\n    Ok(!metadata.files.is_empty())\n}\n\npub fn save_requirements(session_id: &str, requirements: &Requirements) -> Result<()> {\n    let path = state_path(session_id, \"requirements.json\")?;\n    let content = serde_json::to_string_pretty(requirements)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_requirements(session_id: &str) -> Result<Requirements> {\n    let path = state_path(session_id, \"requirements.json\")?;\n    if !path.exists() {\n        return Ok(Requirements::new());\n    }\n    let content = fs::read_to_string(&path)?;\n    let requirements: Requirements = serde_json::from_str(&content)?;\n    Ok(requirements)\n}\n\npub fn save_feature_list(session_id: &str, features: &FeatureList) -> Result<()> {\n    let path = state_path(session_id, \"feature_list.json\")?;\n    let content = serde_json::to_string_pretty(features)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_feature_list(session_id: &str) -> Result<FeatureList> {\n    let path = state_path(session_id, \"feature_list.json\")?;\n    if !path.exists() {\n        return Ok(FeatureList::new());\n    }\n    let content = fs::read_to_string(&path)?;\n    let features: FeatureList = serde_json::from_str(&content)?;\n    Ok(features)\n}\n\npub fn save_design_spec(session_id: &str, design: &DesignSpec) -> Result<()> {\n    let path = state_path(session_id, \"design_spec.json\")?;\n    let content = serde_json::to_string_pretty(design)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_design_spec(session_id: &str) -> Result<DesignSpec> {\n    let path = state_path(session_id, \"design_spec.json\")?;\n    if !path.exists() {\n        return Ok(DesignSpec::new());\n    }\n    let content = fs::read_to_string(&path)?;\n    let design: DesignSpec = serde_json::from_str(&content)?;\n    Ok(design)\n}\n\npub fn save_implementation_plan(session_id: &str, plan: &ImplementationPlan) -> Result<()> {\n    let path = state_path(session_id, \"implementation_plan.json\")?;\n    let content = serde_json::to_string_pretty(plan)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_implementation_plan(session_id: &str) -> Result<ImplementationPlan> {\n    let path = state_path(session_id, \"implementation_plan.json\")?;\n    if !path.exists() {\n        return Ok(ImplementationPlan::new());\n    }\n    let content = fs::read_to_string(&path)?;\n    let plan: ImplementationPlan = serde_json::from_str(&content)?;\n    Ok(plan)\n}\n\npub fn save_code_metadata(session_id: &str, metadata: &CodeMetadata) -> Result<()> {\n    let path = state_path(session_id, \"code_metadata.json\")?;\n    let content = serde_json::to_string_pretty(metadata)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_code_metadata(session_id: &str) -> Result<CodeMetadata> {\n    let path = state_path(session_id, \"code_metadata.json\")?;\n    if !path.exists() {\n        return Ok(CodeMetadata::new());\n    }\n    let content = fs::read_to_string(&path)?;\n    let metadata: CodeMetadata = serde_json::from_str(&content)?;\n    Ok(metadata)\n}\n\n// ============================================================================\n// Session Metadata (sessions/<id>/state/meta.json)\n// ============================================================================\n\npub fn save_session_meta(session_id: &str, meta: &SessionMeta) -> Result<()> {\n    let path = state_path(session_id, \"meta.json\")?;\n    let content = serde_json::to_string_pretty(meta)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_session_meta(session_id: &str) -> Result<Option<SessionMeta>> {\n    let path = state_path(session_id, \"meta.json\")?;\n    if !path.exists() {\n        return Ok(None);\n    }\n    let content = fs::read_to_string(&path)?;\n    let meta: SessionMeta = serde_json::from_str(&content)?;\n    Ok(Some(meta))\n}\n\n// ============================================================================\n// Feedback History (sessions/<id>/state/feedback.json)\n// ============================================================================\n\npub fn save_feedback_history(session_id: &str, history: &FeedbackHistory) -> Result<()> {\n    let path = state_path(session_id, \"feedback.json\")?;\n    let content = serde_json::to_string_pretty(history)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_feedback_history(session_id: &str) -> Result<FeedbackHistory> {\n    let path = state_path(session_id, \"feedback.json\")?;\n    if !path.exists() {\n        return Ok(FeedbackHistory::new());\n    }\n    let content = fs::read_to_string(&path)?;\n    let history: FeedbackHistory = serde_json::from_str(&content)?;\n    Ok(history)\n}\n\npub fn append_feedback(session_id: &str, feedback: &Feedback) -> Result<()> {\n    let mut history = load_feedback_history(session_id)?;\n    history.feedbacks.push(feedback.clone());\n    save_feedback_history(session_id, &history)?;\n    Ok(())\n}\n\n// ============================================================================\n// Patch Metadata (sessions/<id>/patch/metadata.json - for modify sessions)\n// ============================================================================\n\npub fn save_patch_metadata(session_id: &str, patch: &PatchMetadata) -> Result<()> {\n    let session_dir = get_session_dir(session_id)?;\n    let path = session_dir.join(\"patch\").join(\"metadata.json\");\n    let content = serde_json::to_string_pretty(patch)?;\n    fs::write(&path, content)?;\n    Ok(())\n}\n\npub fn load_patch_metadata(session_id: &str) -> Result<PatchMetadata> {\n    let session_dir = get_session_dir(session_id)?;\n    let path = session_dir.join(\"patch\").join(\"metadata.json\");\n    if !path.exists() {\n        anyhow::bail!(\"Patch metadata not found for session {}\", session_id);\n    }\n    let content = fs::read_to_string(&path)?;\n    let patch: PatchMetadata = serde_json::from_str(&content)?;\n    Ok(patch)\n}\n\n// ============================================================================\n// Session Inheritance / Bootstrap\n// ============================================================================\n\n/// Initialize a new session by copying state/artifacts from a base session.\n///\n/// This is critical for `modify` / `revert` / `resume` flows: a fresh session directory\n/// should not start with empty state, otherwise agents will see empty requirements/design/plan.\n///\n/// What we copy:\n/// - state/*.json (requirements, feature_list, design_spec, implementation_plan, code_metadata, feedback, meta)\n/// - artifacts/*.md (idea, prd, design, delivery_report) if present\n///\n/// Notes:\n/// - This function does NOT copy code files in the project root.\n/// - Missing files are skipped.\npub fn init_session_from_base(new_session_id: &str, base_session_id: &str) -> Result<()> {\n    let base_dir = get_session_dir(base_session_id)?;\n    let new_dir = get_session_dir(new_session_id)?;\n\n    // helper to copy a file if it exists\n    fn copy_if_exists(src: &Path, dst: &Path) -> Result<()> {\n        if !src.exists() {\n            return Ok(());\n        }\n        if let Some(parent) = dst.parent() {\n            fs::create_dir_all(parent)?;\n        }\n        fs::copy(src, dst).with_context(|| format!(\"Failed to copy {:?} -> {:?}\", src, dst))?;\n        Ok(())\n    }\n\n    // state files\n    let state_files = [\n        \"requirements.json\",\n        \"feature_list.json\",\n        \"design_spec.json\",\n        \"implementation_plan.json\",\n        \"code_metadata.json\",\n        \"feedback.json\",\n        \"meta.json\",\n    ];\n\n    for name in state_files {\n        let src = base_dir.join(\"state\").join(name);\n        let dst = new_dir.join(\"state\").join(name);\n        copy_if_exists(&src, &dst)?;\n    }\n\n    // artifact files\n    let artifact_files = [\"idea.md\", \"prd.md\", \"design.md\", \"delivery_report.md\"]; \n    for name in artifact_files {\n        let src = base_dir.join(\"artifacts\").join(name);\n        let dst = new_dir.join(\"artifacts\").join(name);\n        copy_if_exists(&src, &dst)?;\n    }\n\n    Ok(())\n}\n\n// ============================================================================\n// Helper utilities\n// ============================================================================\n\n/// Generate ID with prefix and counter\npub fn generate_id(prefix: &str, counter: usize) -> String {\n    format!(\"{}-{:03}\", prefix, counter + 1)\n}\n\n/// Get the latest successful session ID from index\npub fn get_latest_successful_session() -> Result<Option<String>> {\n    if !is_project_initialized() {\n        return Ok(None);\n    }\n    let index = load_project_index()?;\n    Ok(index.latest_successful_session)\n}\n\n/// Mark a session as completed successfully\npub fn mark_session_completed(session_id: &str) -> Result<()> {\n    let mut index = load_project_index()?;\n    \n    // Update session record\n    for session in &mut index.sessions {\n        if session.session_id == session_id {\n            session.status = SessionStatus::Completed;\n            session.completed_at = Some(chrono::Utc::now());\n            break;\n        }\n    }\n    \n    // Update latest successful session\n    index.update_latest_successful(session_id.to_string());\n    save_project_index(&index)?;\n    Ok(())\n}\n\n/// Mark a session as failed\npub fn mark_session_failed(session_id: &str) -> Result<()> {\n    let mut index = load_project_index()?;\n    \n    for session in &mut index.sessions {\n        if session.session_id == session_id {\n            session.status = SessionStatus::Failed;\n            session.completed_at = Some(chrono::Utc::now());\n            break;\n        }\n    }\n    \n    save_project_index(&index)?;\n    Ok(())\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 38.0,
      "lines_of_code": 501,
      "number_of_classes": 1,
      "number_of_functions": 49
    },
    "dependencies": [
      {
        "dependency_type": "internal",
        "is_external": false,
        "line_number": 2,
        "name": "crate::data",
        "path": "crates/cowork-core/src/data",
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": 3,
        "name": "anyhow",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 4,
        "name": "std::fs",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "standard_library",
        "is_external": false,
        "line_number": 5,
        "name": "std::path",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "external",
        "is_external": true,
        "line_number": 72,
        "name": "serde",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This is a comprehensive storage component for the cowork system that manages the file-based persistence layer. It implements a session-scoped architecture where each development session has its own isolated storage directory. The component handles creation and management of the .cowork directory structure, persistence of project metadata, session data, artifacts, state files, and patch metadata. It supports session inheritance for modify/revert/resume flows by copying state between sessions. The implementation uses JSON serialization with proper error handling and directory creation.",
    "interfaces": [
      {
        "description": "Get the .cowork directory path, create if not exists",
        "interface_type": "function",
        "name": "get_cowork_dir",
        "parameters": [],
        "return_type": "Result<PathBuf>",
        "visibility": "public"
      },
      {
        "description": "Get path for a specific session directory",
        "interface_type": "function",
        "name": "get_session_dir",
        "parameters": [
          {
            "description": "Session identifier",
            "is_optional": false,
            "name": "session_id",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<PathBuf>",
        "visibility": "public"
      },
      {
        "description": "Save requirements to session state",
        "interface_type": "function",
        "name": "save_requirements",
        "parameters": [
          {
            "description": "Session identifier",
            "is_optional": false,
            "name": "session_id",
            "param_type": "&str"
          },
          {
            "description": "Requirements data to save",
            "is_optional": false,
            "name": "requirements",
            "param_type": "&Requirements"
          }
        ],
        "return_type": "Result<()>",
        "visibility": "public"
      },
      {
        "description": "Load requirements from session state",
        "interface_type": "function",
        "name": "load_requirements",
        "parameters": [
          {
            "description": "Session identifier",
            "is_optional": false,
            "name": "session_id",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<Requirements>",
        "visibility": "public"
      },
      {
        "description": "Initialize new session by copying state from base session",
        "interface_type": "function",
        "name": "init_session_from_base",
        "parameters": [
          {
            "description": "New session identifier",
            "is_optional": false,
            "name": "new_session_id",
            "param_type": "&str"
          },
          {
            "description": "Base session identifier",
            "is_optional": false,
            "name": "base_session_id",
            "param_type": "&str"
          }
        ],
        "return_type": "Result<()>",
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Manage .cowork directory structure and session-specific subdirectories",
      "Serialize and deserialize project metadata, session data, and artifacts to/from JSON files",
      "Provide session-scoped state management for requirements, design specs, implementation plans, and code metadata",
      "Handle session inheritance and state copying for modify/revert/resume workflows",
      "Maintain feedback history and session completion tracking"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "model",
      "description": "Core data models for Cowork Forge project management system",
      "file_path": "crates/cowork-core/src/data/models.rs",
      "functions": [
        "Requirements::new",
        "FeatureList::new",
        "DesignSpec::new",
        "ImplementationPlan::new",
        "CodeMetadata::new",
        "FeedbackHistory::new",
        "ProjectIndex::new",
        "ProjectIndex::add_session",
        "ProjectIndex::update_latest_successful",
        "ChangeRequest::new",
        "PatchMetadata::new"
      ],
      "importance_score": 0.8,
      "interfaces": [
        "Requirements",
        "Requirement",
        "Priority",
        "RequirementCategory",
        "FeatureList",
        "Feature",
        "FeatureStatus",
        "FeatureMetadata",
        "DesignSpec",
        "Architecture",
        "DesignComponent",
        "ComponentType",
        "ComponentInterface",
        "DataModel",
        "DataField",
        "TechnologyStack",
        "DeploymentInfo",
        "ImplementationPlan",
        "Milestone",
        "Task",
        "TaskStatus",
        "CodeMetadata",
        "FileMetadata",
        "BuildStatus",
        "TestStatus",
        "TestDetail",
        "SessionMeta",
        "Stage",
        "FeedbackHistory",
        "Feedback",
        "FeedbackType",
        "Severity",
        "ProjectIndex",
        "SessionRecord",
        "SessionType",
        "SessionStatus",
        "ChangeRequest",
        "ChangeScope",
        "ChangeAnalysis",
        "RiskLevel",
        "PatchMetadata",
        "ArtifactUpdate",
        "ArtifactType",
        "ChangeType"
      ],
      "name": "models.rs",
      "source_summary": "// Structured data models for Cowork Forge\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\n\n// ============================================================================\n// Requirements (requirements.json)\n// ============================================================================\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Requirements {\n    pub schema_version: String,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n    pub requirements: Vec<Requirement>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Requirement {\n    pub id: String,  // REQ-001, REQ-002, etc.\n    pub title: String,\n    pub description: String,\n    pub priority: Priority,\n    pub category: RequirementCategory,\n    pub acceptance_criteria: Vec<String>,\n    pub related_features: Vec<String>,  // Feature IDs\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"lowercase\")]\npub enum Priority {\n    High,\n    Medium,\n    Low,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum RequirementCategory {\n    Functional,\n    NonFunctional,\n}\n\n// ============================================================================\n// Feature List (feature_list.json)\n// ============================================================================\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FeatureList {\n    pub schema_version: String,\n    pub features: Vec<Feature>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Feature {\n    pub id: String,  // FEAT-001, FEAT-002, etc.\n    pub name: String,\n    pub description: String,\n    pub requirement_ids: Vec<String>,\n    pub status: FeatureStatus,\n    pub assigned_to_tasks: Vec<String>,  // Task IDs\n    pub completion_criteria: Vec<String>,\n    pub created_at: DateTime<Utc>,\n    pub completed_at: Option<DateTime<Utc>>,\n    #[serde(default)]\n    pub metadata: FeatureMetadata,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum FeatureStatus {\n    Pending,\n    InProgress,\n    Completed,\n    Blocked,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\npub struct FeatureMetadata {\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub estimated_effort: Option<String>,\n    #[serde(default)]\n    pub dependencies: Vec<String>,\n}\n\n// ============================================================================\n// Design Spec (design_spec.json)\n// ============================================================================\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DesignSpec {\n    pub schema_version: String,\n    pub architecture: Architecture,\n    pub technology_stack: TechnologyStack,\n    pub deployment: DeploymentInfo,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Architecture {\n    pub style: String,  // \"microservices\", \"monolith\", etc.\n    pub components: Vec<DesignComponent>,\n    pub data_models: Vec<DataModel>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DesignComponent {\n    pub id: String,  // COMP-001, COMP-002, etc.\n    pub name: String,\n    #[serde(rename = \"type\")]\n    pub component_type: ComponentType,\n    pub responsibilities: Vec<String>,\n    pub technology: String,\n    pub interfaces: Vec<ComponentInterface>,\n    pub related_features: Vec<String>,  // Feature IDs\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum ComponentType {\n    BackendService,\n    FrontendComponent,\n    Database,\n    ApiGateway,\n    MessageQueue,\n    Other(String),\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ComponentInterface {\n    pub name: String,\n    pub inputs: Vec<String>,\n    pub outputs: Vec<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DataModel {\n    pub name: String,\n    pub fields: Vec<DataField>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DataField {\n    pub name: String,\n    #[serde(rename = \"type\")]\n    pub field_type: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TechnologyStack {\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub backend: Option<String>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub frontend: Option<String>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub database: Option<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DeploymentInfo {\n    pub architecture: String,\n}\n\n// ============================================================================\n// Implementation Plan (implementation_plan.json)\n// ============================================================================\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ImplementationPlan {\n    pub schema_version: String,\n    pub milestones: Vec<Milestone>,\n    pub tasks: Vec<Task>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Milestone {\n    pub id: String,  // M1, M2, etc.\n    pub name: String,\n    pub features: Vec<String>,  // Feature IDs\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub deadline: Option<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Task {\n    pub id: String,  // TASK-001, TASK-002, etc.\n    pub title: String,\n    pub description: String,\n    pub feature_id: String,\n    pub component_id: String,\n    pub status: TaskStatus,\n    pub dependencies: Vec<String>,  // Task IDs\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub estimated_effort: Option<String>,\n    pub files_to_create: Vec<String>,\n    pub acceptance_criteria: Vec<String>,\n    pub created_at: DateTime<Utc>,\n    pub started_at: Option<DateTime<Utc>>,\n    pub completed_at: Option<DateTime<Utc>>,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum TaskStatus {\n    Pending,\n    InProgress,\n    Completed,\n    Blocked,\n}\n\n// ============================================================================\n// Code Metadata (code_metadata.json)\n// ============================================================================\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CodeMetadata {\n    pub schema_version: String,\n    pub files: Vec<FileMetadata>,\n    pub build_status: BuildStatus,\n    pub test_status: TestStatus,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FileMetadata {\n    pub path: String,\n    pub task_id: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub feature_id: Option<String>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub component_id: Option<String>,\n    pub created_at: DateTime<Utc>,\n    pub last_modified: DateTime<Utc>,\n    pub lines_of_code: usize,\n    pub test_coverage: f32,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct BuildStatus {\n    pub last_build: DateTime<Utc>,\n    pub success: bool,\n    pub errors: Vec<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TestStatus {\n    pub last_run: DateTime<Utc>,\n    pub total: usize,\n    pub passed: usize,\n    pub failed: usize,\n    pub details: Vec<TestDetail>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TestDetail {\n    pub test_name: String,\n    pub status: String,  // \"passed\" or \"failed\"\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub message: Option<String>,\n}\n\n// ============================================================================\n// Session Meta (session/meta.json)\n// ============================================================================\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SessionMeta {\n    pub session_id: String,\n    pub created_at: DateTime<Utc>,\n    pub current_stage: Option<Stage>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub restart_reason: Option<String>,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum Stage {\n    Idea,\n    Prd,\n    Design,\n    Plan,\n    Coding,\n    Check,\n    Delivery,\n}\n\n// ============================================================================\n// Feedback (session/feedback.json)\n// ============================================================================\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FeedbackHistory {\n    pub feedbacks: Vec<Feedback>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Feedback {\n    pub feedback_type: FeedbackType,\n    pub severity: Severity,\n    pub details: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub suggested_fix: Option<String>,\n    pub timestamp: DateTime<Utc>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum FeedbackType {\n    BuildError,\n    QualityIssue,\n    MissingRequirement,\n    Suggestion,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord)]\n#[serde(rename_all = \"lowercase\")]\npub enum Severity {\n    Critical,\n    Major,\n    Minor,\n}\n\n// ============================================================================\n// Session-scoped Models (for session isolation)\n// ============================================================================\n\n/// Project index - tracks all sessions and current state\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProjectIndex {\n    pub schema_version: String,\n    pub project_name: String,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n    /// The latest successful session (for modify to use as base)\n    pub latest_successful_session: Option<String>,\n    /// All session records\n    pub sessions: Vec<SessionRecord>,\n}\n\n/// Record of a single session (new/modify/revert execution)\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SessionRecord {\n    pub session_id: String,\n    pub session_type: SessionType,\n    pub created_at: DateTime<Utc>,\n    pub completed_at: Option<DateTime<Utc>>,\n    pub status: SessionStatus,\n    /// For modify sessions: which session is the base\n    pub base_session_id: Option<String>,\n    /// Input description (idea for new, change request for modify)\n    pub input_description: String,\n    /// Change request (only for modify sessions)\n    pub change_request_id: Option<String>,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum SessionType {\n    New,      // Full project creation (new command)\n    Modify,   // Incremental change (modify command)\n    Revert,   // Revert and rerun (revert command)\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum SessionStatus {\n    InProgress,\n    Completed,\n    Failed,\n}\n\n/// Change request - describes an incremental modification\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ChangeRequest {\n    pub id: String,\n    pub session_id: String,\n    pub created_at: DateTime<Utc>,\n    /// User's idea/description of the change\n    pub idea: String,\n    /// Which session to use as baseline\n    pub base_session_id: String,\n    /// Automatically determined scope (which artifacts need update)\n    pub scope: ChangeScope,\n    /// Acceptance criteria extracted from idea\n    pub acceptance_criteria: Vec<String>,\n    /// Constraints (e.g., don't break existing features)\n    pub constraints: Vec<String>,\n    /// Analysis result from triage agent\n    pub analysis: Option<ChangeAnalysis>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ChangeScope {\n    pub requires_prd_update: bool,\n    pub requires_design_update: bool,\n    pub requires_plan_update: bool,\n    pub requires_code_change: bool,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ChangeAnalysis {\n    /// Affected components\n    pub affected_components: Vec<String>,\n    /// Affected features\n    pub affected_features: Vec<String>,\n    /// Risk assessment\n    pub risk_level: RiskLevel,\n    /// Estimated effort\n    pub estimated_effort: String,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"lowercase\")]\npub enum RiskLevel {\n    Low,\n    Medium,\n    High,\n}\n\n/// Patch metadata - tracks what changed in a modify session\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PatchMetadata {\n    pub session_id: String,\n    pub base_session_id: String,\n    pub created_at: DateTime<Utc>,\n    /// Files added\n    pub added_files: Vec<String>,\n    /// Files modified\n    pub modified_files: Vec<String>,\n    /// Files deleted\n    pub deleted_files: Vec<String>,\n    /// Artifact updates\n    pub artifact_updates: Vec<ArtifactUpdate>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ArtifactUpdate {\n    pub artifact_type: ArtifactType,\n    pub change_type: ChangeType,\n    pub summary: String,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum ArtifactType {\n    Requirements,\n    Features,\n    Design,\n    Plan,\n    Code,\n}\n\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n#[serde(rename_all = \"snake_case\")]\npub enum ChangeType {\n    Added,\n    Modified,\n    Deleted,\n}\n\n// ============================================================================\n// Helper implementations\n// ============================================================================\n\nimpl ProjectIndex {\n    pub fn new(project_name: String) -> Self {\n        Self {\n            schema_version: \"2.0\".to_string(),\n            project_name,\n            created_at: Utc::now(),\n            updated_at: Utc::now(),\n            latest_successful_session: None,\n            sessions: Vec::new(),\n        }\n    }\n\n    pub fn add_session(&mut self, record: SessionRecord) {\n        self.sessions.push(record);\n        self.updated_at = Utc::now();\n    }\n\n    pub fn update_latest_successful(&mut self, session_id: String) {\n        self.latest_successful_session = Some(session_id);\n        self.updated_at = Utc::now();\n    }\n}\n\nimpl ChangeRequest {\n    pub fn new(\n        session_id: String,\n        idea: String,\n        base_session_id: String,\n    ) -> Self {\n        Self {\n            id: format!(\"CR-{}\", Utc::now().timestamp()),\n            session_id,\n            created_at: Utc::now(),\n            idea,\n            base_session_id,\n            scope: ChangeScope::default(),\n            acceptance_criteria: Vec::new(),\n            constraints: Vec::new(),\n            analysis: None,\n        }\n    }\n}\n\nimpl Default for ChangeScope {\n    fn default() -> Self {\n        Self {\n            requires_prd_update: false,\n            requires_design_update: false,\n            requires_plan_update: false,\n            requires_code_change: true, // Default to code-only change\n        }\n    }\n}\n\nimpl PatchMetadata {\n    pub fn new(session_id: String, base_session_id: String) -> Self {\n        Self {\n            session_id,\n            base_session_id,\n            created_at: Utc::now(),\n            added_files: Vec::new(),\n            modified_files: Vec::new(),\n            deleted_files: Vec::new(),\n            artifact_updates: Vec::new(),\n        }\n    }\n}\n\nimpl Requirements {\n    pub fn new() -> Self {\n        Self {\n            schema_version: \"1.0\".to_string(),\n            created_at: Utc::now(),\n            updated_at: Utc::now(),\n            requirements: Vec::new(),\n        }\n    }\n}\n\nimpl FeatureList {\n    pub fn new() -> Self {\n        Self {\n            schema_version: \"1.0\".to_string(),\n            features: Vec::new(),\n        }\n    }\n}\n\nimpl DesignSpec {\n    pub fn new() -> Self {\n        Self {\n            schema_version: \"1.0\".to_string(),\n            architecture: Architecture {\n                style: String::new(),\n                components: Vec::new(),\n                data_models: Vec::new(),\n            },\n            technology_stack: TechnologyStack {\n                backend: None,\n                frontend: None,\n                database: None,\n            },\n            deployment: DeploymentInfo {\n                architecture: String::new(),\n            },\n        }\n    }\n}\n\nimpl ImplementationPlan {\n    pub fn new() -> Self {\n        Self {\n            schema_version: \"1.0\".to_string(),\n            milestones: Vec::new(),\n            tasks: Vec::new(),\n        }\n    }\n}\n\nimpl CodeMetadata {\n    pub fn new() -> Self {\n        Self {\n            schema_version: \"1.0\".to_string(),\n            files: Vec::new(),\n            build_status: BuildStatus {\n                last_build: Utc::now(),\n                success: false,\n                errors: Vec::new(),\n            },\n            test_status: TestStatus {\n                last_run: Utc::now(),\n                total: 0,\n                passed: 0,\n                failed: 0,\n                details: Vec::new(),\n            },\n        }\n    }\n}\n\nimpl FeedbackHistory {\n    pub fn new() -> Self {\n        Self {\n            feedbacks: Vec::new(),\n        }\n    }\n}\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 19.0,
      "lines_of_code": 608,
      "number_of_classes": 65,
      "number_of_functions": 11
    },
    "dependencies": [
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 2,
        "name": "chrono",
        "path": null,
        "version": null
      },
      {
        "dependency_type": "library",
        "is_external": true,
        "line_number": 3,
        "name": "serde",
        "path": null,
        "version": null
      }
    ],
    "detailed_description": "This component serves as the comprehensive data model foundation for Cowork Forge, a project management system that orchestrates software development lifecycle from requirements gathering to delivery. It defines structured data models for requirements management, feature tracking, design specifications, implementation planning, code metadata, session management, and feedback handling. The models support serialization/deserialization via Serde and include timestamp tracking with Chrono for audit purposes. The component implements a session-based architecture that supports project creation, modification, and reversion workflows with proper isolation and change tracking.",
    "interfaces": [
      {
        "description": "Container for project requirements with versioning and timestamps",
        "interface_type": "struct",
        "name": "Requirements",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "schema_version",
            "param_type": "String"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "created_at",
            "param_type": "DateTime<Utc>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "updated_at",
            "param_type": "DateTime<Utc>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "requirements",
            "param_type": "Vec<Requirement>"
          }
        ],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Individual requirement with categorization and tracking",
        "interface_type": "struct",
        "name": "Requirement",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "id",
            "param_type": "String"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "title",
            "param_type": "String"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "description",
            "param_type": "String"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "priority",
            "param_type": "Priority"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "category",
            "param_type": "RequirementCategory"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "acceptance_criteria",
            "param_type": "Vec<String>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "related_features",
            "param_type": "Vec<String>"
          }
        ],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Master index tracking all project sessions and current state",
        "interface_type": "struct",
        "name": "ProjectIndex",
        "parameters": [
          {
            "description": null,
            "is_optional": false,
            "name": "schema_version",
            "param_type": "String"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "project_name",
            "param_type": "String"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "created_at",
            "param_type": "DateTime<Utc>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "updated_at",
            "param_type": "DateTime<Utc>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "latest_successful_session",
            "param_type": "Option<String>"
          },
          {
            "description": null,
            "is_optional": false,
            "name": "sessions",
            "param_type": "Vec<SessionRecord>"
          }
        ],
        "return_type": null,
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Define and maintain structured data models for project artifacts (requirements, features, design, plan, code metadata)",
      "Provide session management capabilities for project lifecycle tracking and isolation",
      "Implement change tracking and version control mechanisms for incremental modifications",
      "Support serialization/deserialization for data persistence and interchange",
      "Establish relationships between different project artifacts through reference IDs"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "agent",
      "description": "Central module file for exporting all agent instruction modules",
      "file_path": "crates/cowork-core/src/instructions/mod.rs",
      "functions": [
        "module_reexport",
        "dependency_management"
      ],
      "importance_score": 0.6,
      "interfaces": [
        "public_module_interface"
      ],
      "name": "mod.rs",
      "source_summary": "// Agent instructions - Prompt templates for each agent\n\npub mod idea;\npub mod prd;\npub mod design;\npub mod plan;\npub mod coding;\npub mod check;\npub mod delivery;\npub mod modify;\npub mod code_patch;\npub mod modify_delivery;\n\npub use idea::*;\npub use prd::*;\npub use design::*;\npub use plan::*;\npub use coding::*;\npub use check::*;\npub use delivery::*;\npub use modify::*;\npub use code_patch::*;\npub use modify_delivery::*;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 2.0,
      "lines_of_code": 23,
      "number_of_classes": 0,
      "number_of_functions": 0
    },
    "dependencies": [
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 4,
        "name": "idea",
        "path": "crates/cowork-core/src/instructions/idea.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 5,
        "name": "prd",
        "path": "crates/cowork-core/src/instructions/prd.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 6,
        "name": "design",
        "path": "crates/cowork-core/src/instructions/design.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 7,
        "name": "plan",
        "path": "crates/cowork-core/src/instructions/plan.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 8,
        "name": "coding",
        "path": "crates/cowork-core/src/instructions/coding.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 9,
        "name": "check",
        "path": "crates/cowork-core/src/instructions/check.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 10,
        "name": "delivery",
        "path": "crates/cowork-core/src/instructions/delivery.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 11,
        "name": "modify",
        "path": "crates/cowork-core/src/instructions/modify.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 12,
        "name": "code_patch",
        "path": "crates/cowork-core/src/instructions/code_patch.rs",
        "version": null
      },
      {
        "dependency_type": "module",
        "is_external": false,
        "line_number": 13,
        "name": "modify_delivery",
        "path": "crates/cowork-core/src/instructions/modify_delivery.rs",
        "version": null
      }
    ],
    "detailed_description": "This mod.rs file serves as a central module aggregator and re-exporter for agent instruction prompt templates in the cowork-core crate. It doesn't contain any business logic itself but acts as a facade pattern to provide unified access to all instruction modules. The component re-exports 10 different instruction modules covering the complete agent workflow from idea generation to code modification and delivery.",
    "interfaces": [
      {
        "description": "Provides unified public access to all instruction modules",
        "interface_type": "module_export",
        "name": "public_module_interface",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      }
    ],
    "responsibilities": [
      "Module aggregation and centralized access point management",
      "Public API surface definition through re-export patterns",
      "Dependency organization and module structure maintenance",
      "Workflow orchestration interface provision"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "module",
      "description": "Tools module - adk-rust Tool implementations",
      "file_path": "crates/cowork-core/src/tools/mod.rs",
      "functions": [],
      "importance_score": 0.6,
      "interfaces": [],
      "name": "mod.rs",
      "source_summary": "// Tools module - adk-rust Tool implementations\npub mod data_tools;\npub mod validation_tools;\npub mod control_tools;\npub mod file_tools;\npub mod artifact_tools;\npub mod goto_stage_tool;\npub mod test_lint_tools;\npub mod hitl_tools;\npub mod hitl_content_tools;\npub mod modify_tools;\npub mod idea_tools;\n\npub use data_tools::*;\npub use validation_tools::*;\npub use control_tools::*;\npub use file_tools::*;\npub use artifact_tools::*;\npub use goto_stage_tool::*;\npub use test_lint_tools::*;\npub use hitl_tools::*;\npub use hitl_content_tools::*;\npub use modify_tools::*;\npub use idea_tools::*;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 1.0,
      "lines_of_code": 24,
      "number_of_classes": 0,
      "number_of_functions": 0
    },
    "dependencies": [],
    "detailed_description": "This is a module declaration file that serves as a central hub for organizing and exporting various tool implementations in the cowork-core crate. The module aggregates 11 different tool submodules including data tools, validation tools, control tools, file tools, artifact tools, stage navigation tools, testing/linting tools, HITL (Human-in-the-Loop) tools, content tools, modification tools, and idea tools. It acts as a facade pattern providing unified access to all tool functionality through re-exports.",
    "interfaces": [],
    "responsibilities": [
      "Module organization and namespace management",
      "Tool functionality aggregation and export",
      "Dependency re-export for external consumers",
      "Module structure definition and visibility control"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "module",
      "description": "LLM module - Using adk-rust's built-in OpenAI client with custom base URL",
      "file_path": "crates/cowork-core/src/llm/mod.rs",
      "functions": [],
      "importance_score": 0.6,
      "interfaces": [],
      "name": "mod.rs",
      "source_summary": "// LLM module - Using adk-rust's built-in OpenAI client with custom base URL\npub mod config;\npub mod rate_limiter;\n\npub use config::*;\npub use rate_limiter::*;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 1.0,
      "lines_of_code": 6,
      "number_of_classes": 0,
      "number_of_functions": 0
    },
    "dependencies": [],
    "detailed_description": "This is a Rust module file that serves as the entry point for the LLM (Large Language Model) module within the cowork-core crate. The module primarily organizes and re-exports functionality from two submodules: config and rate_limiter. It acts as a facade that provides centralized access to LLM-related configuration and rate limiting capabilities while leveraging adk-rust's built-in OpenAI client with custom base URL configuration. The component serves as a modularization boundary for LLM functionality within the system.",
    "interfaces": [],
    "responsibilities": [
      "Module organization and namespace management",
      "Public API exposure through re-exports",
      "Integration point for LLM-related submodules",
      "Dependency management for LLM functionality"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "lib",
      "description": "Cowork Forge core library providing foundational modules for AI agent collaboration system",
      "file_path": "crates/cowork-core/src/lib.rs",
      "functions": [],
      "importance_score": 0.6,
      "interfaces": [],
      "name": "lib.rs",
      "source_summary": "// Cowork Forge - Core Library\n// Built with adk-rust 0.2.1\n\npub mod data;\npub mod storage;\npub mod llm;\npub mod tools;\npub mod agents;\npub mod pipeline;\npub mod instructions;\n\n// Re-exports for convenience\npub use data::*;\npub use storage::*;\npub use llm::*;\n\n// Version info\npub const VERSION: &str = env!(\"CARGO_PKG_VERSION\");\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 2.0,
      "lines_of_code": 18,
      "number_of_classes": 0,
      "number_of_functions": 0
    },
    "dependencies": [
      {
        "dependency_type": "build_dependency",
        "is_external": true,
        "line_number": 2,
        "name": "adk-rust",
        "path": null,
        "version": "0.2.1"
      }
    ],
    "detailed_description": "This is the root library file for the Cowork Forge core library, serving as the main entry point and module organization structure. The component acts as a facade and module aggregator for the core functionality of an AI agent collaboration system. It organizes related modules including data handling, storage, LLM integration, tools, agents, pipelines, and instructions. The library provides convenient re-exports for downstream consumers and includes version information.",
    "interfaces": [],
    "responsibilities": [
      "Module organization and namespace management",
      "Public API exposure through re-exports",
      "Version information provision",
      "Library entry point definition",
      "Dependency aggregation for core functionality"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "model",
      "description": "Validation utilities for data schemas",
      "file_path": "crates/cowork-core/src/data/schemas/validation.rs",
      "functions": [],
      "importance_score": 0.6,
      "interfaces": [],
      "name": "validation.rs",
      "source_summary": "// Validation utilities for data schemas\n// This module provides validation logic for structured data\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 3.0,
      "lines_of_code": 2,
      "number_of_classes": 0,
      "number_of_functions": 0
    },
    "dependencies": [],
    "detailed_description": "This is a placeholder validation module with only a comment indicating it's intended to provide validation logic for structured data. The component is currently unimplemented with only 2 lines of code (a comment). Based on the file path and naming, it appears to be part of a schema validation system within a coworking/core data module, likely intended to validate data structures or schemas in a coworking application.",
    "interfaces": [],
    "responsibilities": [
      "Provide validation logic for structured data schemas",
      "Define validation rules and constraints for data models",
      "Handle schema validation errors and reporting",
      "Ensure data integrity through validation checks"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "model",
      "description": null,
      "file_path": "crates/cowork-core/src/data/mod.rs",
      "functions": [
        "module_re-export",
        "conditional_testing_module"
      ],
      "importance_score": 0.6,
      "interfaces": [
        "pub mod models",
        "pub mod schemas",
        "pub use models::*",
        "pub use schemas::*"
      ],
      "name": "mod.rs",
      "source_summary": "// Data models module\npub mod models;\npub mod schemas;\n\n#[cfg(test)]\nmod models_test;\n\npub use models::*;\npub use schemas::*;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 1.0,
      "lines_of_code": 9,
      "number_of_classes": 0,
      "number_of_functions": 2
    },
    "dependencies": [
      {
        "dependency_type": "test_module",
        "is_external": false,
        "line_number": 4,
        "name": "models_test",
        "path": "./crates/cowork-core/src/data/models_test.rs",
        "version": null
      }
    ],
    "detailed_description": "This is a Rust module file that serves as the entry point for the data models module in the cowork-core crate. It acts as a module aggregator and re-exporter for data-related functionality. The module conditionally includes test modules only during test compilation, demonstrating proper separation of test and production code. It provides unified access to both models and schemas through re-export statements.",
    "interfaces": [
      {
        "description": "Public module exposing data models",
        "interface_type": "module",
        "name": "models",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Public module exposing data schemas",
        "interface_type": "module",
        "name": "schemas",
        "parameters": [],
        "return_type": null,
        "visibility": "public"
      },
      {
        "description": "Conditional test module for data models",
        "interface_type": "module",
        "name": "models_test",
        "parameters": [],
        "return_type": null,
        "visibility": "private"
      }
    ],
    "responsibilities": [
      "Module organization and aggregation for data-related components",
      "Public interface exposure through re-export patterns",
      "Conditional test module inclusion for testing environment",
      "Namespace management for data models and schemas",
      "Entry point configuration for data module hierarchy"
    ]
  },
  {
    "code_dossier": {
      "code_purpose": "model",
      "description": "Schema definitions module for validation purposes",
      "file_path": "crates/cowork-core/src/data/schemas.rs",
      "functions": [],
      "importance_score": 0.6,
      "interfaces": [],
      "name": "schemas.rs",
      "source_summary": "// JSON Schema definitions (for validation)\npub mod validation;\n"
    },
    "complexity_metrics": {
      "cyclomatic_complexity": 2.0,
      "lines_of_code": 2,
      "number_of_classes": 0,
      "number_of_functions": 0
    },
    "dependencies": [],
    "detailed_description": "This is a minimal Rust module that serves as an entry point for JSON Schema definitions used for validation. The component currently only contains a single module declaration for 'validation', indicating it's designed to organize validation-related schemas. Given its location in the data layer of a coworking core system, it likely defines data structures and validation rules for the domain model. The extremely minimal implementation suggests this is either a stub/placeholder for future development or a simple module organization structure.",
    "interfaces": [],
    "responsibilities": [
      "Module organization and namespace management for validation schemas",
      "Provide entry point to validation-related schema definitions",
      "Structure validation logic separation within the data layer",
      "Serve as foundation for future schema expansion",
      "Maintain architectural separation between data models and validation rules"
    ]
  }
]
```

## Memory Storage Statistics

**Total Storage Size**: 609269 bytes

- **studies_research**: 88837 bytes (14.6%)
- **preprocess**: 403395 bytes (66.2%)
- **documentation**: 117000 bytes (19.2%)
- **timing**: 37 bytes (0.0%)

## Generated Documents Statistics

Number of Generated Documents: 11

- Key Modules and Components Research Report_æŒä¹…åŒ–å­˜å‚¨åŸŸ
- Key Modules and Components Research Report_æ™ºèƒ½ä½“æ‰§è¡ŒåŸŸ
- Key Modules and Components Research Report_LLMé›†æˆåŸŸ
- Key Modules and Components Research Report_æ™ºèƒ½ä½“æŒ‡ä»¤åŸŸ
- Key Modules and Components Research Report_å·¥å…·æ‰§è¡ŒåŸŸ
- Core Workflows
- Architecture Description
- Key Modules and Components Research Report_æ¨¡å—èšåˆåŸŸ
- Project Overview
- Key Modules and Components Research Report_å…¥å£ä¸ç¼–æ’åŸŸ
- Boundary Interfaces
